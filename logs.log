2024-09-05 18:26:00,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 18:26:00,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 18:26:00,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 18:26:00,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 18:27:54,467:INFO:PyCaret ClassificationExperiment
2024-09-05 18:27:54,467:INFO:Logging name: clf-default-name
2024-09-05 18:27:54,467:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-05 18:27:54,467:INFO:version 3.3.2
2024-09-05 18:27:54,468:INFO:Initializing setup()
2024-09-05 18:27:54,468:INFO:self.USI: 6cee
2024-09-05 18:27:54,468:INFO:self._variable_keys: {'_ml_usecase', 'fold_shuffle_param', 'y_train', 'data', 'pipeline', 'X_test', 'fold_groups_param', 'exp_id', 'gpu_n_jobs_param', 'seed', 'fix_imbalance', 'idx', 'is_multiclass', 'exp_name_log', 'log_plots_param', 'USI', 'target_param', 'y_test', 'fold_generator', '_available_plots', 'X', 'gpu_param', 'html_param', 'logging_param', 'n_jobs_param', 'y', 'X_train', 'memory'}
2024-09-05 18:27:54,468:INFO:Checking environment
2024-09-05 18:27:54,468:INFO:python_version: 3.10.11
2024-09-05 18:27:54,468:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-05 18:27:54,468:INFO:machine: AMD64
2024-09-05 18:27:54,468:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-05 18:27:54,468:INFO:Memory: svmem(total=17128263680, available=6480961536, percent=62.2, used=10647302144, free=6480961536)
2024-09-05 18:27:54,468:INFO:Physical Core: 6
2024-09-05 18:27:54,468:INFO:Logical Core: 12
2024-09-05 18:27:54,468:INFO:Checking libraries
2024-09-05 18:27:54,468:INFO:System:
2024-09-05 18:27:54,468:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-05 18:27:54,468:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-05 18:27:54,468:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-05 18:27:54,468:INFO:PyCaret required dependencies:
2024-09-05 18:27:54,498:INFO:                 pip: 24.2
2024-09-05 18:27:54,498:INFO:          setuptools: 72.1.0
2024-09-05 18:27:54,498:INFO:             pycaret: 3.3.2
2024-09-05 18:27:54,498:INFO:             IPython: 8.27.0
2024-09-05 18:27:54,498:INFO:          ipywidgets: 8.1.5
2024-09-05 18:27:54,498:INFO:                tqdm: 4.66.5
2024-09-05 18:27:54,498:INFO:               numpy: 1.26.4
2024-09-05 18:27:54,499:INFO:              pandas: 2.2.2
2024-09-05 18:27:54,499:INFO:              jinja2: 3.1.4
2024-09-05 18:27:54,499:INFO:               scipy: 1.11.4
2024-09-05 18:27:54,499:INFO:              joblib: 1.3.2
2024-09-05 18:27:54,499:INFO:             sklearn: 1.4.2
2024-09-05 18:27:54,499:INFO:                pyod: 2.0.1
2024-09-05 18:27:54,499:INFO:            imblearn: 0.12.3
2024-09-05 18:27:54,499:INFO:   category_encoders: 2.6.3
2024-09-05 18:27:54,499:INFO:            lightgbm: 4.5.0
2024-09-05 18:27:54,499:INFO:               numba: 0.60.0
2024-09-05 18:27:54,499:INFO:            requests: 2.32.3
2024-09-05 18:27:54,499:INFO:          matplotlib: 3.7.5
2024-09-05 18:27:54,499:INFO:          scikitplot: 0.3.7
2024-09-05 18:27:54,499:INFO:         yellowbrick: 1.5
2024-09-05 18:27:54,499:INFO:              plotly: 5.24.0
2024-09-05 18:27:54,499:INFO:    plotly-resampler: Not installed
2024-09-05 18:27:54,499:INFO:             kaleido: 0.2.1
2024-09-05 18:27:54,499:INFO:           schemdraw: 0.15
2024-09-05 18:27:54,499:INFO:         statsmodels: 0.14.2
2024-09-05 18:27:54,499:INFO:              sktime: 0.26.0
2024-09-05 18:27:54,499:INFO:               tbats: 1.1.3
2024-09-05 18:27:54,499:INFO:            pmdarima: 2.0.4
2024-09-05 18:27:54,499:INFO:              psutil: 6.0.0
2024-09-05 18:27:54,499:INFO:          markupsafe: 2.1.5
2024-09-05 18:27:54,500:INFO:             pickle5: Not installed
2024-09-05 18:27:54,500:INFO:         cloudpickle: 3.0.0
2024-09-05 18:27:54,500:INFO:         deprecation: 2.1.0
2024-09-05 18:27:54,500:INFO:              xxhash: 3.5.0
2024-09-05 18:27:54,500:INFO:           wurlitzer: Not installed
2024-09-05 18:27:54,500:INFO:PyCaret optional dependencies:
2024-09-05 18:27:54,501:INFO:                shap: Not installed
2024-09-05 18:27:54,501:INFO:           interpret: Not installed
2024-09-05 18:27:54,501:INFO:                umap: Not installed
2024-09-05 18:27:54,501:INFO:     ydata_profiling: Not installed
2024-09-05 18:27:54,501:INFO:  explainerdashboard: Not installed
2024-09-05 18:27:54,501:INFO:             autoviz: Not installed
2024-09-05 18:27:54,501:INFO:           fairlearn: Not installed
2024-09-05 18:27:54,501:INFO:          deepchecks: Not installed
2024-09-05 18:27:54,501:INFO:             xgboost: 2.1.1
2024-09-05 18:27:54,501:INFO:            catboost: Not installed
2024-09-05 18:27:54,501:INFO:              kmodes: Not installed
2024-09-05 18:27:54,501:INFO:             mlxtend: Not installed
2024-09-05 18:27:54,501:INFO:       statsforecast: Not installed
2024-09-05 18:27:54,501:INFO:        tune_sklearn: Not installed
2024-09-05 18:27:54,501:INFO:                 ray: Not installed
2024-09-05 18:27:54,501:INFO:            hyperopt: 0.2.7
2024-09-05 18:27:54,501:INFO:              optuna: 4.0.0
2024-09-05 18:27:54,501:INFO:               skopt: 0.10.2
2024-09-05 18:27:54,501:INFO:              mlflow: Not installed
2024-09-05 18:27:54,501:INFO:              gradio: Not installed
2024-09-05 18:27:54,501:INFO:             fastapi: Not installed
2024-09-05 18:27:54,501:INFO:             uvicorn: Not installed
2024-09-05 18:27:54,501:INFO:              m2cgen: Not installed
2024-09-05 18:27:54,501:INFO:           evidently: Not installed
2024-09-05 18:27:54,501:INFO:               fugue: Not installed
2024-09-05 18:27:54,501:INFO:           streamlit: Not installed
2024-09-05 18:27:54,501:INFO:             prophet: Not installed
2024-09-05 18:27:54,501:INFO:None
2024-09-05 18:27:54,501:INFO:Set up data.
2024-09-05 18:27:55,087:INFO:Set up folding strategy.
2024-09-05 18:27:55,087:INFO:Set up train/test split.
2024-09-05 18:27:55,788:INFO:Set up index.
2024-09-05 18:27:55,813:INFO:Assigning column types.
2024-09-05 18:27:56,599:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-05 18:27:56,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,661:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,693:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:56,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:56,739:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,771:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:56,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:56,771:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-05 18:27:56,828:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,859:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:56,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:56,906:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,937:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:56,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:56,937:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-05 18:27:57,016:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:57,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:57,109:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:57,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:57,109:INFO:Preparing preprocessing pipeline...
2024-09-05 18:27:57,234:INFO:Set up simple imputation.
2024-09-05 18:27:57,234:INFO:Set up imbalanced handling.
2024-09-05 18:27:58,961:INFO:Finished creating preprocessing pipeline.
2024-09-05 18:27:58,977:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-05 18:27:58,977:INFO:Creating final display dataframe.
2024-09-05 18:28:09,454:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 535)
4        Transformed data shape      (99147, 535)
5   Transformed train set shape      (76191, 535)
6    Transformed test set shape      (22956, 535)
7              Numeric features               534
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              6cee
2024-09-05 18:28:09,549:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:28:09,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:28:09,619:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:28:09,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:28:09,634:INFO:setup() successfully completed in 15.17s...............
2024-09-05 18:28:09,652:INFO:Initializing create_model()
2024-09-05 18:28:09,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 18:28:09,652:INFO:Checking exceptions
2024-09-05 18:28:09,670:INFO:Importing libraries
2024-09-05 18:28:09,670:INFO:Copying training dataset
2024-09-05 18:28:10,617:INFO:Defining folds
2024-09-05 18:28:10,617:INFO:Declaring metric variables
2024-09-05 18:28:10,621:INFO:Importing untrained model
2024-09-05 18:28:10,625:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 18:28:10,631:INFO:Starting cross validation
2024-09-05 18:28:10,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 18:31:24,475:INFO:Calculating mean and std
2024-09-05 18:31:24,506:INFO:Creating metrics dataframe
2024-09-05 18:31:24,549:INFO:Finalizing model
2024-09-05 18:31:30,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174011 seconds.
2024-09-05 18:31:30,265:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:31:42,244:INFO:Uploading results into container
2024-09-05 18:31:42,246:INFO:Uploading model into container now
2024-09-05 18:31:42,267:INFO:_master_model_container: 1
2024-09-05 18:31:42,267:INFO:_display_container: 2
2024-09-05 18:31:42,268:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 18:31:42,268:INFO:create_model() successfully completed......................................
2024-09-05 18:33:35,434:INFO:Initializing tune_model()
2024-09-05 18:33:35,434:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'min_child_samples': [50, 150, 200]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>)
2024-09-05 18:33:35,434:INFO:Checking exceptions
2024-09-05 18:33:35,435:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-05 18:33:36,039:INFO:Copying training dataset
2024-09-05 18:33:36,549:INFO:Checking base model
2024-09-05 18:33:36,549:INFO:Base model : Light Gradient Boosting Machine
2024-09-05 18:33:36,556:INFO:Declaring metric variables
2024-09-05 18:33:36,556:INFO:Defining Hyperparameters
2024-09-05 18:33:36,639:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[50, 150, 200])}
2024-09-05 18:33:36,639:INFO:Tuning with n_jobs=-1
2024-09-05 18:33:36,641:INFO:Initializing skopt.BayesSearchCV
2024-09-05 18:44:32,902:INFO:best_params: OrderedDict([('actual_estimator__max_depth', 5), ('actual_estimator__min_child_samples', 150), ('actual_estimator__n_estimators', 100)])
2024-09-05 18:44:32,902:INFO:Hyperparameter search completed
2024-09-05 18:44:32,902:INFO:SubProcess create_model() called ==================================
2024-09-05 18:44:32,918:INFO:Initializing create_model()
2024-09-05 18:44:32,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C6BE6D9600>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'max_depth': 5, 'min_child_samples': 150, 'n_estimators': 100})
2024-09-05 18:44:32,918:INFO:Checking exceptions
2024-09-05 18:44:32,918:INFO:Importing libraries
2024-09-05 18:44:32,918:INFO:Copying training dataset
2024-09-05 18:44:33,989:INFO:Defining folds
2024-09-05 18:44:33,989:INFO:Declaring metric variables
2024-09-05 18:44:33,989:INFO:Importing untrained model
2024-09-05 18:44:33,989:INFO:Declaring custom model
2024-09-05 18:44:34,007:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 18:44:34,017:INFO:Starting cross validation
2024-09-05 18:44:34,030:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 18:45:34,994:INFO:Calculating mean and std
2024-09-05 18:45:34,994:INFO:Creating metrics dataframe
2024-09-05 18:45:34,994:INFO:Finalizing model
2024-09-05 18:45:40,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163606 seconds.
2024-09-05 18:45:40,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 18:45:40,371:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 18:45:40,371:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 18:45:40,371:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:45:40,371:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:45:40,386:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:45:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,432:INFO:Uploading results into container
2024-09-05 18:45:47,432:INFO:Uploading model into container now
2024-09-05 18:45:47,448:INFO:_master_model_container: 2
2024-09-05 18:45:47,448:INFO:_display_container: 3
2024-09-05 18:45:47,448:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-09-05 18:45:47,448:INFO:create_model() successfully completed......................................
2024-09-05 18:45:47,661:INFO:SubProcess create_model() end ==================================
2024-09-05 18:45:47,661:INFO:choose_better activated
2024-09-05 18:45:47,661:INFO:SubProcess create_model() called ==================================
2024-09-05 18:45:47,661:INFO:Initializing create_model()
2024-09-05 18:45:47,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 18:45:47,661:INFO:Checking exceptions
2024-09-05 18:45:47,677:INFO:Importing libraries
2024-09-05 18:45:47,677:INFO:Copying training dataset
2024-09-05 18:45:48,569:INFO:Defining folds
2024-09-05 18:45:48,569:INFO:Declaring metric variables
2024-09-05 18:45:48,569:INFO:Importing untrained model
2024-09-05 18:45:48,569:INFO:Declaring custom model
2024-09-05 18:45:48,569:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 18:45:48,569:INFO:Starting cross validation
2024-09-05 18:45:48,569:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 18:47:31,765:INFO:Calculating mean and std
2024-09-05 18:47:31,765:INFO:Creating metrics dataframe
2024-09-05 18:47:31,765:INFO:Finalizing model
2024-09-05 18:47:37,138:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187903 seconds.
2024-09-05 18:47:37,138:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:47:48,169:INFO:Uploading results into container
2024-09-05 18:47:48,169:INFO:Uploading model into container now
2024-09-05 18:47:48,169:INFO:_master_model_container: 3
2024-09-05 18:47:48,169:INFO:_display_container: 4
2024-09-05 18:47:48,169:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 18:47:48,169:INFO:create_model() successfully completed......................................
2024-09-05 18:47:48,263:INFO:SubProcess create_model() end ==================================
2024-09-05 18:47:48,263:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8294
2024-09-05 18:47:48,263:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8284
2024-09-05 18:47:48,263:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-05 18:47:48,263:INFO:choose_better completed
2024-09-05 18:47:48,263:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-05 18:47:48,279:INFO:_master_model_container: 3
2024-09-05 18:47:48,279:INFO:_display_container: 3
2024-09-05 18:47:48,280:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 18:47:48,280:INFO:tune_model() successfully completed......................................
2024-09-05 18:47:48,393:INFO:Initializing plot_model()
2024-09-05 18:47:48,393:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>, system=True)
2024-09-05 18:47:48,393:INFO:Checking exceptions
2024-09-05 18:47:48,732:INFO:Preloading libraries
2024-09-05 18:47:48,759:INFO:Copying training dataset
2024-09-05 18:47:48,759:INFO:Plot type: confusion_matrix
2024-09-05 18:47:51,451:INFO:Fitting Model
2024-09-05 18:47:51,451:INFO:Scoring test/hold-out set
2024-09-05 18:47:51,796:INFO:Visual Rendered Successfully
2024-09-05 18:47:51,878:INFO:plot_model() successfully completed......................................
2024-09-05 20:50:43,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 20:50:43,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 20:50:43,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 20:50:43,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 20:51:49,316:INFO:PyCaret ClassificationExperiment
2024-09-05 20:51:49,316:INFO:Logging name: clf-default-name
2024-09-05 20:51:49,316:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-05 20:51:49,316:INFO:version 3.3.2
2024-09-05 20:51:49,316:INFO:Initializing setup()
2024-09-05 20:51:49,316:INFO:self.USI: 692b
2024-09-05 20:51:49,316:INFO:self._variable_keys: {'USI', 'html_param', 'log_plots_param', '_available_plots', '_ml_usecase', 'seed', 'gpu_n_jobs_param', 'n_jobs_param', 'X', 'X_train', 'y', 'exp_name_log', 'X_test', 'logging_param', 'fold_groups_param', 'memory', 'gpu_param', 'idx', 'fix_imbalance', 'fold_generator', 'exp_id', 'target_param', 'fold_shuffle_param', 'data', 'pipeline', 'y_train', 'is_multiclass', 'y_test'}
2024-09-05 20:51:49,316:INFO:Checking environment
2024-09-05 20:51:49,316:INFO:python_version: 3.10.11
2024-09-05 20:51:49,316:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-05 20:51:49,316:INFO:machine: AMD64
2024-09-05 20:51:49,317:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-05 20:51:49,317:INFO:Memory: svmem(total=17128263680, available=5885304832, percent=65.6, used=11242958848, free=5885304832)
2024-09-05 20:51:49,317:INFO:Physical Core: 6
2024-09-05 20:51:49,317:INFO:Logical Core: 12
2024-09-05 20:51:49,317:INFO:Checking libraries
2024-09-05 20:51:49,317:INFO:System:
2024-09-05 20:51:49,317:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-05 20:51:49,317:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-05 20:51:49,317:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-05 20:51:49,317:INFO:PyCaret required dependencies:
2024-09-05 20:51:49,352:INFO:                 pip: 24.2
2024-09-05 20:51:49,352:INFO:          setuptools: 72.1.0
2024-09-05 20:51:49,353:INFO:             pycaret: 3.3.2
2024-09-05 20:51:49,353:INFO:             IPython: 8.27.0
2024-09-05 20:51:49,353:INFO:          ipywidgets: 8.1.5
2024-09-05 20:51:49,353:INFO:                tqdm: 4.66.5
2024-09-05 20:51:49,353:INFO:               numpy: 1.26.4
2024-09-05 20:51:49,353:INFO:              pandas: 2.2.2
2024-09-05 20:51:49,353:INFO:              jinja2: 3.1.4
2024-09-05 20:51:49,353:INFO:               scipy: 1.11.4
2024-09-05 20:51:49,353:INFO:              joblib: 1.3.2
2024-09-05 20:51:49,353:INFO:             sklearn: 1.4.2
2024-09-05 20:51:49,353:INFO:                pyod: 2.0.1
2024-09-05 20:51:49,353:INFO:            imblearn: 0.12.3
2024-09-05 20:51:49,353:INFO:   category_encoders: 2.6.3
2024-09-05 20:51:49,353:INFO:            lightgbm: 4.5.0
2024-09-05 20:51:49,353:INFO:               numba: 0.60.0
2024-09-05 20:51:49,353:INFO:            requests: 2.32.3
2024-09-05 20:51:49,353:INFO:          matplotlib: 3.7.5
2024-09-05 20:51:49,353:INFO:          scikitplot: 0.3.7
2024-09-05 20:51:49,353:INFO:         yellowbrick: 1.5
2024-09-05 20:51:49,353:INFO:              plotly: 5.24.0
2024-09-05 20:51:49,353:INFO:    plotly-resampler: Not installed
2024-09-05 20:51:49,353:INFO:             kaleido: 0.2.1
2024-09-05 20:51:49,353:INFO:           schemdraw: 0.15
2024-09-05 20:51:49,354:INFO:         statsmodels: 0.14.2
2024-09-05 20:51:49,354:INFO:              sktime: 0.26.0
2024-09-05 20:51:49,354:INFO:               tbats: 1.1.3
2024-09-05 20:51:49,354:INFO:            pmdarima: 2.0.4
2024-09-05 20:51:49,354:INFO:              psutil: 6.0.0
2024-09-05 20:51:49,354:INFO:          markupsafe: 2.1.5
2024-09-05 20:51:49,354:INFO:             pickle5: Not installed
2024-09-05 20:51:49,354:INFO:         cloudpickle: 3.0.0
2024-09-05 20:51:49,354:INFO:         deprecation: 2.1.0
2024-09-05 20:51:49,354:INFO:              xxhash: 3.5.0
2024-09-05 20:51:49,354:INFO:           wurlitzer: Not installed
2024-09-05 20:51:49,354:INFO:PyCaret optional dependencies:
2024-09-05 20:51:49,372:INFO:                shap: Not installed
2024-09-05 20:51:49,372:INFO:           interpret: Not installed
2024-09-05 20:51:49,372:INFO:                umap: Not installed
2024-09-05 20:51:49,372:INFO:     ydata_profiling: Not installed
2024-09-05 20:51:49,372:INFO:  explainerdashboard: Not installed
2024-09-05 20:51:49,372:INFO:             autoviz: Not installed
2024-09-05 20:51:49,372:INFO:           fairlearn: Not installed
2024-09-05 20:51:49,372:INFO:          deepchecks: Not installed
2024-09-05 20:51:49,372:INFO:             xgboost: 2.1.1
2024-09-05 20:51:49,372:INFO:            catboost: Not installed
2024-09-05 20:51:49,372:INFO:              kmodes: Not installed
2024-09-05 20:51:49,373:INFO:             mlxtend: Not installed
2024-09-05 20:51:49,373:INFO:       statsforecast: Not installed
2024-09-05 20:51:49,373:INFO:        tune_sklearn: Not installed
2024-09-05 20:51:49,373:INFO:                 ray: Not installed
2024-09-05 20:51:49,373:INFO:            hyperopt: 0.2.7
2024-09-05 20:51:49,373:INFO:              optuna: 4.0.0
2024-09-05 20:51:49,373:INFO:               skopt: 0.10.2
2024-09-05 20:51:49,373:INFO:              mlflow: Not installed
2024-09-05 20:51:49,373:INFO:              gradio: Not installed
2024-09-05 20:51:49,373:INFO:             fastapi: Not installed
2024-09-05 20:51:49,374:INFO:             uvicorn: Not installed
2024-09-05 20:51:49,374:INFO:              m2cgen: Not installed
2024-09-05 20:51:49,374:INFO:           evidently: Not installed
2024-09-05 20:51:49,374:INFO:               fugue: Not installed
2024-09-05 20:51:49,374:INFO:           streamlit: Not installed
2024-09-05 20:51:49,374:INFO:             prophet: Not installed
2024-09-05 20:51:49,374:INFO:None
2024-09-05 20:51:49,374:INFO:Set up data.
2024-09-05 20:51:50,049:INFO:Set up folding strategy.
2024-09-05 20:51:50,049:INFO:Set up train/test split.
2024-09-05 20:51:51,051:INFO:Set up index.
2024-09-05 20:51:51,077:INFO:Assigning column types.
2024-09-05 20:51:51,984:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-05 20:51:52,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,096:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,154:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,186:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,190:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-05 20:51:52,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,285:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,340:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,380:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,384:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-05 20:51:52,476:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,563:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,569:INFO:Preparing preprocessing pipeline...
2024-09-05 20:51:52,750:INFO:Set up simple imputation.
2024-09-05 20:51:52,750:INFO:Set up imbalanced handling.
2024-09-05 20:51:53,999:INFO:Finished creating preprocessing pipeline.
2024-09-05 20:51:54,017:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-05 20:51:54,017:INFO:Creating final display dataframe.
2024-09-05 20:51:58,411:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 535)
4        Transformed data shape      (99147, 535)
5   Transformed train set shape      (76191, 535)
6    Transformed test set shape      (22956, 535)
7              Numeric features               534
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              692b
2024-09-05 20:51:58,510:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:58,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:58,607:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:58,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:58,612:INFO:setup() successfully completed in 9.3s...............
2024-09-05 20:51:58,620:INFO:Initializing compare_models()
2024-09-05 20:51:58,620:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-05 20:51:58,620:INFO:Checking exceptions
2024-09-05 20:51:59,411:INFO:Preparing display monitor
2024-09-05 20:51:59,445:INFO:Initializing Logistic Regression
2024-09-05 20:51:59,445:INFO:Total runtime is 0.0 minutes
2024-09-05 20:51:59,451:INFO:SubProcess create_model() called ==================================
2024-09-05 20:51:59,452:INFO:Initializing create_model()
2024-09-05 20:51:59,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 20:51:59,452:INFO:Checking exceptions
2024-09-05 20:51:59,452:INFO:Importing libraries
2024-09-05 20:51:59,452:INFO:Copying training dataset
2024-09-05 20:52:00,579:INFO:Defining folds
2024-09-05 20:52:00,580:INFO:Declaring metric variables
2024-09-05 20:52:00,584:INFO:Importing untrained model
2024-09-05 20:52:00,589:INFO:Logistic Regression Imported successfully
2024-09-05 20:52:00,598:INFO:Starting cross validation
2024-09-05 20:52:00,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 20:56:35,256:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:56:55,862:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:56:56,902:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:56:57,058:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:02,414:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:09,214:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:10,393:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:17,422:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:27,032:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:30,200:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:30,275:INFO:Calculating mean and std
2024-09-05 20:57:30,284:INFO:Creating metrics dataframe
2024-09-05 20:57:30,298:INFO:Uploading results into container
2024-09-05 20:57:30,300:INFO:Uploading model into container now
2024-09-05 20:57:30,303:INFO:_master_model_container: 1
2024-09-05 20:57:30,303:INFO:_display_container: 2
2024-09-05 20:57:30,306:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-05 20:57:30,307:INFO:create_model() successfully completed......................................
2024-09-05 20:57:30,518:INFO:SubProcess create_model() end ==================================
2024-09-05 20:57:30,518:INFO:Creating metrics dataframe
2024-09-05 20:57:30,527:INFO:Initializing K Neighbors Classifier
2024-09-05 20:57:30,528:INFO:Total runtime is 5.51804279088974 minutes
2024-09-05 20:57:30,531:INFO:SubProcess create_model() called ==================================
2024-09-05 20:57:30,531:INFO:Initializing create_model()
2024-09-05 20:57:30,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 20:57:30,532:INFO:Checking exceptions
2024-09-05 20:57:30,532:INFO:Importing libraries
2024-09-05 20:57:30,532:INFO:Copying training dataset
2024-09-05 20:57:31,475:INFO:Defining folds
2024-09-05 20:57:31,476:INFO:Declaring metric variables
2024-09-05 20:57:31,480:INFO:Importing untrained model
2024-09-05 20:57:31,485:INFO:K Neighbors Classifier Imported successfully
2024-09-05 20:57:31,492:INFO:Starting cross validation
2024-09-05 20:57:31,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 20:58:46,354:INFO:Calculating mean and std
2024-09-05 20:58:46,356:INFO:Creating metrics dataframe
2024-09-05 20:58:46,359:INFO:Uploading results into container
2024-09-05 20:58:46,359:INFO:Uploading model into container now
2024-09-05 20:58:46,360:INFO:_master_model_container: 2
2024-09-05 20:58:46,360:INFO:_display_container: 2
2024-09-05 20:58:46,360:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-05 20:58:46,361:INFO:create_model() successfully completed......................................
2024-09-05 20:58:46,482:INFO:SubProcess create_model() end ==================================
2024-09-05 20:58:46,483:INFO:Creating metrics dataframe
2024-09-05 20:58:46,492:INFO:Initializing Naive Bayes
2024-09-05 20:58:46,493:INFO:Total runtime is 6.784119780858358 minutes
2024-09-05 20:58:46,497:INFO:SubProcess create_model() called ==================================
2024-09-05 20:58:46,497:INFO:Initializing create_model()
2024-09-05 20:58:46,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 20:58:46,497:INFO:Checking exceptions
2024-09-05 20:58:46,498:INFO:Importing libraries
2024-09-05 20:58:46,498:INFO:Copying training dataset
2024-09-05 20:58:47,426:INFO:Defining folds
2024-09-05 20:58:47,426:INFO:Declaring metric variables
2024-09-05 20:58:47,430:INFO:Importing untrained model
2024-09-05 20:58:47,433:INFO:Naive Bayes Imported successfully
2024-09-05 20:58:47,442:INFO:Starting cross validation
2024-09-05 20:58:47,446:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 20:59:21,690:INFO:Calculating mean and std
2024-09-05 20:59:21,691:INFO:Creating metrics dataframe
2024-09-05 20:59:21,693:INFO:Uploading results into container
2024-09-05 20:59:21,694:INFO:Uploading model into container now
2024-09-05 20:59:21,695:INFO:_master_model_container: 3
2024-09-05 20:59:21,695:INFO:_display_container: 2
2024-09-05 20:59:21,695:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-05 20:59:21,695:INFO:create_model() successfully completed......................................
2024-09-05 20:59:21,813:INFO:SubProcess create_model() end ==================================
2024-09-05 20:59:21,813:INFO:Creating metrics dataframe
2024-09-05 20:59:21,823:INFO:Initializing Decision Tree Classifier
2024-09-05 20:59:21,823:INFO:Total runtime is 7.372954535484315 minutes
2024-09-05 20:59:21,829:INFO:SubProcess create_model() called ==================================
2024-09-05 20:59:21,829:INFO:Initializing create_model()
2024-09-05 20:59:21,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 20:59:21,829:INFO:Checking exceptions
2024-09-05 20:59:21,830:INFO:Importing libraries
2024-09-05 20:59:21,830:INFO:Copying training dataset
2024-09-05 20:59:22,806:INFO:Defining folds
2024-09-05 20:59:22,806:INFO:Declaring metric variables
2024-09-05 20:59:22,811:INFO:Importing untrained model
2024-09-05 20:59:22,817:INFO:Decision Tree Classifier Imported successfully
2024-09-05 20:59:22,827:INFO:Starting cross validation
2024-09-05 20:59:22,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:01:04,362:INFO:Calculating mean and std
2024-09-05 21:01:04,363:INFO:Creating metrics dataframe
2024-09-05 21:01:04,365:INFO:Uploading results into container
2024-09-05 21:01:04,366:INFO:Uploading model into container now
2024-09-05 21:01:04,366:INFO:_master_model_container: 4
2024-09-05 21:01:04,367:INFO:_display_container: 2
2024-09-05 21:01:04,367:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-05 21:01:04,367:INFO:create_model() successfully completed......................................
2024-09-05 21:01:04,463:INFO:SubProcess create_model() end ==================================
2024-09-05 21:01:04,463:INFO:Creating metrics dataframe
2024-09-05 21:01:04,471:INFO:Initializing SVM - Linear Kernel
2024-09-05 21:01:04,471:INFO:Total runtime is 9.083764763673148 minutes
2024-09-05 21:01:04,474:INFO:SubProcess create_model() called ==================================
2024-09-05 21:01:04,474:INFO:Initializing create_model()
2024-09-05 21:01:04,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:01:04,475:INFO:Checking exceptions
2024-09-05 21:01:04,475:INFO:Importing libraries
2024-09-05 21:01:04,475:INFO:Copying training dataset
2024-09-05 21:01:05,365:INFO:Defining folds
2024-09-05 21:01:05,365:INFO:Declaring metric variables
2024-09-05 21:01:05,369:INFO:Importing untrained model
2024-09-05 21:01:05,374:INFO:SVM - Linear Kernel Imported successfully
2024-09-05 21:01:05,384:INFO:Starting cross validation
2024-09-05 21:01:05,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:01:53,773:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:02,546:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:02,625:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:02,661:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:02,883:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:03,355:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:04,915:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:05,078:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:05,663:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:06,430:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:06,472:INFO:Calculating mean and std
2024-09-05 21:02:06,474:INFO:Creating metrics dataframe
2024-09-05 21:02:06,477:INFO:Uploading results into container
2024-09-05 21:02:06,478:INFO:Uploading model into container now
2024-09-05 21:02:06,478:INFO:_master_model_container: 5
2024-09-05 21:02:06,479:INFO:_display_container: 2
2024-09-05 21:02:06,479:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-05 21:02:06,480:INFO:create_model() successfully completed......................................
2024-09-05 21:02:06,587:INFO:SubProcess create_model() end ==================================
2024-09-05 21:02:06,587:INFO:Creating metrics dataframe
2024-09-05 21:02:06,600:INFO:Initializing Ridge Classifier
2024-09-05 21:02:06,600:INFO:Total runtime is 10.119242489337923 minutes
2024-09-05 21:02:06,604:INFO:SubProcess create_model() called ==================================
2024-09-05 21:02:06,605:INFO:Initializing create_model()
2024-09-05 21:02:06,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:02:06,605:INFO:Checking exceptions
2024-09-05 21:02:06,605:INFO:Importing libraries
2024-09-05 21:02:06,605:INFO:Copying training dataset
2024-09-05 21:02:07,553:INFO:Defining folds
2024-09-05 21:02:07,553:INFO:Declaring metric variables
2024-09-05 21:02:07,557:INFO:Importing untrained model
2024-09-05 21:02:07,562:INFO:Ridge Classifier Imported successfully
2024-09-05 21:02:07,571:INFO:Starting cross validation
2024-09-05 21:02:07,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:02:27,233:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:29,750:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:30,764:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:34,998:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:35,968:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:36,307:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:36,429:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:38,279:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:38,351:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:39,391:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:39,430:INFO:Calculating mean and std
2024-09-05 21:02:39,432:INFO:Creating metrics dataframe
2024-09-05 21:02:39,434:INFO:Uploading results into container
2024-09-05 21:02:39,435:INFO:Uploading model into container now
2024-09-05 21:02:39,436:INFO:_master_model_container: 6
2024-09-05 21:02:39,436:INFO:_display_container: 2
2024-09-05 21:02:39,437:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-05 21:02:39,437:INFO:create_model() successfully completed......................................
2024-09-05 21:02:39,561:INFO:SubProcess create_model() end ==================================
2024-09-05 21:02:39,561:INFO:Creating metrics dataframe
2024-09-05 21:02:39,573:INFO:Initializing Random Forest Classifier
2024-09-05 21:02:39,573:INFO:Total runtime is 10.668787733713788 minutes
2024-09-05 21:02:39,578:INFO:SubProcess create_model() called ==================================
2024-09-05 21:02:39,578:INFO:Initializing create_model()
2024-09-05 21:02:39,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:02:39,579:INFO:Checking exceptions
2024-09-05 21:02:39,579:INFO:Importing libraries
2024-09-05 21:02:39,579:INFO:Copying training dataset
2024-09-05 21:02:40,528:INFO:Defining folds
2024-09-05 21:02:40,528:INFO:Declaring metric variables
2024-09-05 21:02:40,532:INFO:Importing untrained model
2024-09-05 21:02:40,537:INFO:Random Forest Classifier Imported successfully
2024-09-05 21:02:40,549:INFO:Starting cross validation
2024-09-05 21:02:40,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:05:07,896:INFO:Calculating mean and std
2024-09-05 21:05:07,898:INFO:Creating metrics dataframe
2024-09-05 21:05:07,900:INFO:Uploading results into container
2024-09-05 21:05:07,901:INFO:Uploading model into container now
2024-09-05 21:05:07,902:INFO:_master_model_container: 7
2024-09-05 21:05:07,902:INFO:_display_container: 2
2024-09-05 21:05:07,903:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-05 21:05:07,903:INFO:create_model() successfully completed......................................
2024-09-05 21:05:08,042:INFO:SubProcess create_model() end ==================================
2024-09-05 21:05:08,042:INFO:Creating metrics dataframe
2024-09-05 21:05:08,061:INFO:Initializing Quadratic Discriminant Analysis
2024-09-05 21:05:08,061:INFO:Total runtime is 13.143596621354423 minutes
2024-09-05 21:05:08,067:INFO:SubProcess create_model() called ==================================
2024-09-05 21:05:08,067:INFO:Initializing create_model()
2024-09-05 21:05:08,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:05:08,069:INFO:Checking exceptions
2024-09-05 21:05:08,069:INFO:Importing libraries
2024-09-05 21:05:08,069:INFO:Copying training dataset
2024-09-05 21:05:09,354:INFO:Defining folds
2024-09-05 21:05:09,354:INFO:Declaring metric variables
2024-09-05 21:05:09,360:INFO:Importing untrained model
2024-09-05 21:05:09,367:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-05 21:05:09,379:INFO:Starting cross validation
2024-09-05 21:05:09,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:05:36,790:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:39,707:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:46,436:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:46,747:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:47,817:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:47,886:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:48,065:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:49,794:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:05:51,788:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:53,738:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:05:56,497:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:05:58,265:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:05:59,119:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:01,266:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:01,585:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:06:01,662:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:06:01,689:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:02,235:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:07,191:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:07,199:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:07,237:INFO:Calculating mean and std
2024-09-05 21:06:07,240:INFO:Creating metrics dataframe
2024-09-05 21:06:07,246:INFO:Uploading results into container
2024-09-05 21:06:07,249:INFO:Uploading model into container now
2024-09-05 21:06:07,250:INFO:_master_model_container: 8
2024-09-05 21:06:07,251:INFO:_display_container: 2
2024-09-05 21:06:07,251:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-05 21:06:07,251:INFO:create_model() successfully completed......................................
2024-09-05 21:06:07,413:INFO:SubProcess create_model() end ==================================
2024-09-05 21:06:07,413:INFO:Creating metrics dataframe
2024-09-05 21:06:07,430:INFO:Initializing Ada Boost Classifier
2024-09-05 21:06:07,431:INFO:Total runtime is 14.133069785435996 minutes
2024-09-05 21:06:07,435:INFO:SubProcess create_model() called ==================================
2024-09-05 21:06:07,435:INFO:Initializing create_model()
2024-09-05 21:06:07,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:06:07,436:INFO:Checking exceptions
2024-09-05 21:06:07,436:INFO:Importing libraries
2024-09-05 21:06:07,437:INFO:Copying training dataset
2024-09-05 21:06:08,652:INFO:Defining folds
2024-09-05 21:06:08,652:INFO:Declaring metric variables
2024-09-05 21:06:08,657:INFO:Importing untrained model
2024-09-05 21:06:08,661:INFO:Ada Boost Classifier Imported successfully
2024-09-05 21:06:08,672:INFO:Starting cross validation
2024-09-05 21:06:08,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:06:31,914:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:34,571:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:35,019:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:35,352:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:36,260:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:36,594:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:37,869:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:38,346:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:41,985:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:44,598:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:08:35,284:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:37,002:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:37,551:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:44,194:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:47,336:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:49,140:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:52,834:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:09:12,403:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:09:16,811:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:09:20,980:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:09:21,020:INFO:Calculating mean and std
2024-09-05 21:09:21,022:INFO:Creating metrics dataframe
2024-09-05 21:09:21,026:INFO:Uploading results into container
2024-09-05 21:09:21,027:INFO:Uploading model into container now
2024-09-05 21:09:21,027:INFO:_master_model_container: 9
2024-09-05 21:09:21,027:INFO:_display_container: 2
2024-09-05 21:09:21,028:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-05 21:09:21,028:INFO:create_model() successfully completed......................................
2024-09-05 21:09:21,139:INFO:SubProcess create_model() end ==================================
2024-09-05 21:09:21,139:INFO:Creating metrics dataframe
2024-09-05 21:09:21,151:INFO:Initializing Gradient Boosting Classifier
2024-09-05 21:09:21,151:INFO:Total runtime is 17.361753463745117 minutes
2024-09-05 21:09:21,156:INFO:SubProcess create_model() called ==================================
2024-09-05 21:09:21,157:INFO:Initializing create_model()
2024-09-05 21:09:21,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:09:21,157:INFO:Checking exceptions
2024-09-05 21:09:21,157:INFO:Importing libraries
2024-09-05 21:09:21,157:INFO:Copying training dataset
2024-09-05 21:09:22,301:INFO:Defining folds
2024-09-05 21:09:22,301:INFO:Declaring metric variables
2024-09-05 21:09:22,307:INFO:Importing untrained model
2024-09-05 21:09:22,313:INFO:Gradient Boosting Classifier Imported successfully
2024-09-05 21:09:22,324:INFO:Starting cross validation
2024-09-05 21:09:22,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:42:59,599:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:07,801:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:27,915:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:35,803:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:44,464:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:59,314:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:45:08,024:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:45:08,143:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:45:30,467:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:03,518:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:03,601:INFO:Calculating mean and std
2024-09-05 21:46:03,625:INFO:Creating metrics dataframe
2024-09-05 21:46:03,654:INFO:Uploading results into container
2024-09-05 21:46:03,655:INFO:Uploading model into container now
2024-09-05 21:46:03,662:INFO:_master_model_container: 10
2024-09-05 21:46:03,662:INFO:_display_container: 2
2024-09-05 21:46:03,668:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-05 21:46:03,669:INFO:create_model() successfully completed......................................
2024-09-05 21:46:03,947:INFO:SubProcess create_model() end ==================================
2024-09-05 21:46:03,947:INFO:Creating metrics dataframe
2024-09-05 21:46:03,959:INFO:Initializing Linear Discriminant Analysis
2024-09-05 21:46:03,959:INFO:Total runtime is 54.07522857586543 minutes
2024-09-05 21:46:03,963:INFO:SubProcess create_model() called ==================================
2024-09-05 21:46:03,963:INFO:Initializing create_model()
2024-09-05 21:46:03,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:46:03,964:INFO:Checking exceptions
2024-09-05 21:46:03,964:INFO:Importing libraries
2024-09-05 21:46:03,964:INFO:Copying training dataset
2024-09-05 21:46:05,120:INFO:Defining folds
2024-09-05 21:46:05,120:INFO:Declaring metric variables
2024-09-05 21:46:05,123:INFO:Importing untrained model
2024-09-05 21:46:05,127:INFO:Linear Discriminant Analysis Imported successfully
2024-09-05 21:46:05,134:INFO:Starting cross validation
2024-09-05 21:46:05,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:46:32,490:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:32,531:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:34,507:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:37,366:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:38,959:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:38,963:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:39,121:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:40,500:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:40,817:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:40,970:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:40,989:INFO:Calculating mean and std
2024-09-05 21:46:40,991:INFO:Creating metrics dataframe
2024-09-05 21:46:40,996:INFO:Uploading results into container
2024-09-05 21:46:40,999:INFO:Uploading model into container now
2024-09-05 21:46:41,000:INFO:_master_model_container: 11
2024-09-05 21:46:41,000:INFO:_display_container: 2
2024-09-05 21:46:41,001:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-05 21:46:41,001:INFO:create_model() successfully completed......................................
2024-09-05 21:46:41,113:INFO:SubProcess create_model() end ==================================
2024-09-05 21:46:41,113:INFO:Creating metrics dataframe
2024-09-05 21:46:41,130:INFO:Initializing Extra Trees Classifier
2024-09-05 21:46:41,130:INFO:Total runtime is 54.694747010866806 minutes
2024-09-05 21:46:41,135:INFO:SubProcess create_model() called ==================================
2024-09-05 21:46:41,135:INFO:Initializing create_model()
2024-09-05 21:46:41,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:46:41,136:INFO:Checking exceptions
2024-09-05 21:46:41,136:INFO:Importing libraries
2024-09-05 21:46:41,137:INFO:Copying training dataset
2024-09-05 21:46:41,980:INFO:Defining folds
2024-09-05 21:46:41,981:INFO:Declaring metric variables
2024-09-05 21:46:41,984:INFO:Importing untrained model
2024-09-05 21:46:41,988:INFO:Extra Trees Classifier Imported successfully
2024-09-05 21:46:41,996:INFO:Starting cross validation
2024-09-05 21:46:42,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:48:27,938:INFO:Calculating mean and std
2024-09-05 21:48:27,939:INFO:Creating metrics dataframe
2024-09-05 21:48:27,942:INFO:Uploading results into container
2024-09-05 21:48:27,943:INFO:Uploading model into container now
2024-09-05 21:48:27,944:INFO:_master_model_container: 12
2024-09-05 21:48:27,944:INFO:_display_container: 2
2024-09-05 21:48:27,945:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-05 21:48:27,945:INFO:create_model() successfully completed......................................
2024-09-05 21:48:28,064:INFO:SubProcess create_model() end ==================================
2024-09-05 21:48:28,064:INFO:Creating metrics dataframe
2024-09-05 21:48:28,079:INFO:Initializing Extreme Gradient Boosting
2024-09-05 21:48:28,079:INFO:Total runtime is 56.47722209294638 minutes
2024-09-05 21:48:28,083:INFO:SubProcess create_model() called ==================================
2024-09-05 21:48:28,083:INFO:Initializing create_model()
2024-09-05 21:48:28,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:48:28,084:INFO:Checking exceptions
2024-09-05 21:48:28,084:INFO:Importing libraries
2024-09-05 21:48:28,084:INFO:Copying training dataset
2024-09-05 21:48:29,079:INFO:Defining folds
2024-09-05 21:48:29,079:INFO:Declaring metric variables
2024-09-05 21:48:29,087:INFO:Importing untrained model
2024-09-05 21:48:29,094:INFO:Extreme Gradient Boosting Imported successfully
2024-09-05 21:48:29,107:INFO:Starting cross validation
2024-09-05 21:48:29,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:50:16,785:INFO:Calculating mean and std
2024-09-05 21:50:16,787:INFO:Creating metrics dataframe
2024-09-05 21:50:16,788:INFO:Uploading results into container
2024-09-05 21:50:16,789:INFO:Uploading model into container now
2024-09-05 21:50:16,789:INFO:_master_model_container: 13
2024-09-05 21:50:16,789:INFO:_display_container: 2
2024-09-05 21:50:16,790:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-05 21:50:16,791:INFO:create_model() successfully completed......................................
2024-09-05 21:50:16,885:INFO:SubProcess create_model() end ==================================
2024-09-05 21:50:16,885:INFO:Creating metrics dataframe
2024-09-05 21:50:16,900:INFO:Initializing Light Gradient Boosting Machine
2024-09-05 21:50:16,900:INFO:Total runtime is 58.29090755780538 minutes
2024-09-05 21:50:16,904:INFO:SubProcess create_model() called ==================================
2024-09-05 21:50:16,904:INFO:Initializing create_model()
2024-09-05 21:50:16,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:50:16,905:INFO:Checking exceptions
2024-09-05 21:50:16,905:INFO:Importing libraries
2024-09-05 21:50:16,905:INFO:Copying training dataset
2024-09-05 21:50:17,716:INFO:Defining folds
2024-09-05 21:50:17,716:INFO:Declaring metric variables
2024-09-05 21:50:17,721:INFO:Importing untrained model
2024-09-05 21:50:17,725:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 21:50:17,732:INFO:Starting cross validation
2024-09-05 21:50:17,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:53:34,946:INFO:Calculating mean and std
2024-09-05 21:53:34,948:INFO:Creating metrics dataframe
2024-09-05 21:53:34,951:INFO:Uploading results into container
2024-09-05 21:53:34,952:INFO:Uploading model into container now
2024-09-05 21:53:34,953:INFO:_master_model_container: 14
2024-09-05 21:53:34,953:INFO:_display_container: 2
2024-09-05 21:53:34,954:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 21:53:34,954:INFO:create_model() successfully completed......................................
2024-09-05 21:53:35,131:INFO:SubProcess create_model() end ==================================
2024-09-05 21:53:35,131:INFO:Creating metrics dataframe
2024-09-05 21:53:35,153:INFO:Initializing Dummy Classifier
2024-09-05 21:53:35,153:INFO:Total runtime is 61.595125134785974 minutes
2024-09-05 21:53:35,161:INFO:SubProcess create_model() called ==================================
2024-09-05 21:53:35,161:INFO:Initializing create_model()
2024-09-05 21:53:35,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:53:35,161:INFO:Checking exceptions
2024-09-05 21:53:35,161:INFO:Importing libraries
2024-09-05 21:53:35,161:INFO:Copying training dataset
2024-09-05 21:53:36,178:INFO:Defining folds
2024-09-05 21:53:36,178:INFO:Declaring metric variables
2024-09-05 21:53:36,183:INFO:Importing untrained model
2024-09-05 21:53:36,188:INFO:Dummy Classifier Imported successfully
2024-09-05 21:53:36,197:INFO:Starting cross validation
2024-09-05 21:53:36,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:53:55,693:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:56,231:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:56,233:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:56,897:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:57,164:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:57,772:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:57,974:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:58,335:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:58,603:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:58,670:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:58,687:INFO:Calculating mean and std
2024-09-05 21:53:58,688:INFO:Creating metrics dataframe
2024-09-05 21:53:58,690:INFO:Uploading results into container
2024-09-05 21:53:58,690:INFO:Uploading model into container now
2024-09-05 21:53:58,692:INFO:_master_model_container: 15
2024-09-05 21:53:58,692:INFO:_display_container: 2
2024-09-05 21:53:58,692:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-05 21:53:58,692:INFO:create_model() successfully completed......................................
2024-09-05 21:53:58,779:INFO:SubProcess create_model() end ==================================
2024-09-05 21:53:58,779:INFO:Creating metrics dataframe
2024-09-05 21:53:58,803:INFO:Initializing create_model()
2024-09-05 21:53:58,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:53:58,804:INFO:Checking exceptions
2024-09-05 21:53:58,807:INFO:Importing libraries
2024-09-05 21:53:58,807:INFO:Copying training dataset
2024-09-05 21:53:59,572:INFO:Defining folds
2024-09-05 21:53:59,572:INFO:Declaring metric variables
2024-09-05 21:53:59,572:INFO:Importing untrained model
2024-09-05 21:53:59,572:INFO:Declaring custom model
2024-09-05 21:53:59,573:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 21:53:59,576:INFO:Cross validation set to False
2024-09-05 21:53:59,576:INFO:Fitting Model
2024-09-05 21:54:04,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174350 seconds.
2024-09-05 21:54:04,894:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 21:54:04,903:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 21:54:04,908:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 21:54:04,912:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 21:54:04,912:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 21:54:04,912:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 21:54:15,335:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 21:54:15,335:INFO:create_model() successfully completed......................................
2024-09-05 21:54:15,468:INFO:_master_model_container: 15
2024-09-05 21:54:15,468:INFO:_display_container: 2
2024-09-05 21:54:15,469:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 21:54:15,469:INFO:compare_models() successfully completed......................................
2024-09-05 22:00:26,204:INFO:Initializing create_model()
2024-09-05 22:00:26,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 22:00:26,204:INFO:Checking exceptions
2024-09-05 22:00:26,220:INFO:Importing libraries
2024-09-05 22:00:26,220:INFO:Copying training dataset
2024-09-05 22:00:27,024:INFO:Defining folds
2024-09-05 22:00:27,024:INFO:Declaring metric variables
2024-09-05 22:00:27,028:INFO:Importing untrained model
2024-09-05 22:00:27,032:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 22:00:27,040:INFO:Starting cross validation
2024-09-05 22:00:27,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 22:03:16,125:INFO:Calculating mean and std
2024-09-05 22:03:16,154:INFO:Creating metrics dataframe
2024-09-05 22:03:16,199:INFO:Finalizing model
2024-09-05 22:03:21,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167547 seconds.
2024-09-05 22:03:21,874:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 22:03:21,884:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 22:03:21,889:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 22:03:21,892:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:03:21,892:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:03:21,892:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:03:34,474:INFO:Uploading results into container
2024-09-05 22:03:34,475:INFO:Uploading model into container now
2024-09-05 22:03:34,513:INFO:_master_model_container: 16
2024-09-05 22:03:34,514:INFO:_display_container: 3
2024-09-05 22:03:34,514:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:03:34,515:INFO:create_model() successfully completed......................................
2024-09-05 22:10:15,075:INFO:Initializing tune_model()
2024-09-05 22:10:15,075:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'min_child_samples': [50, 150, 200]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>)
2024-09-05 22:10:15,075:INFO:Checking exceptions
2024-09-05 22:10:15,075:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-05 22:10:15,556:INFO:Copying training dataset
2024-09-05 22:10:16,014:INFO:Checking base model
2024-09-05 22:10:16,014:INFO:Base model : Light Gradient Boosting Machine
2024-09-05 22:10:16,018:INFO:Declaring metric variables
2024-09-05 22:10:16,021:INFO:Defining Hyperparameters
2024-09-05 22:10:16,101:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[50, 150, 200])}
2024-09-05 22:10:16,101:INFO:Tuning with n_jobs=-1
2024-09-05 22:10:16,104:INFO:Initializing skopt.BayesSearchCV
2024-09-05 22:22:52,399:INFO:best_params: OrderedDict([('actual_estimator__max_depth', 5), ('actual_estimator__min_child_samples', 150), ('actual_estimator__n_estimators', 100)])
2024-09-05 22:22:52,401:INFO:Hyperparameter search completed
2024-09-05 22:22:52,401:INFO:SubProcess create_model() called ==================================
2024-09-05 22:22:52,402:INFO:Initializing create_model()
2024-09-05 22:22:52,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A77D270>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'max_depth': 5, 'min_child_samples': 150, 'n_estimators': 100})
2024-09-05 22:22:52,402:INFO:Checking exceptions
2024-09-05 22:22:52,403:INFO:Importing libraries
2024-09-05 22:22:52,403:INFO:Copying training dataset
2024-09-05 22:22:53,354:INFO:Defining folds
2024-09-05 22:22:53,355:INFO:Declaring metric variables
2024-09-05 22:22:53,360:INFO:Importing untrained model
2024-09-05 22:22:53,360:INFO:Declaring custom model
2024-09-05 22:22:53,364:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 22:22:53,374:INFO:Starting cross validation
2024-09-05 22:22:53,379:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 22:23:56,607:INFO:Calculating mean and std
2024-09-05 22:23:56,609:INFO:Creating metrics dataframe
2024-09-05 22:23:56,617:INFO:Finalizing model
2024-09-05 22:24:02,861:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187376 seconds.
2024-09-05 22:24:02,861:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 22:24:02,872:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 22:24:02,877:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 22:24:02,880:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:24:02,881:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:24:02,881:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:24:02,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,827:INFO:Uploading results into container
2024-09-05 22:24:10,828:INFO:Uploading model into container now
2024-09-05 22:24:10,829:INFO:_master_model_container: 17
2024-09-05 22:24:10,829:INFO:_display_container: 4
2024-09-05 22:24:10,830:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:24:10,830:INFO:create_model() successfully completed......................................
2024-09-05 22:24:10,969:INFO:SubProcess create_model() end ==================================
2024-09-05 22:24:10,970:INFO:choose_better activated
2024-09-05 22:24:10,973:INFO:SubProcess create_model() called ==================================
2024-09-05 22:24:10,974:INFO:Initializing create_model()
2024-09-05 22:24:10,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 22:24:10,974:INFO:Checking exceptions
2024-09-05 22:24:10,976:INFO:Importing libraries
2024-09-05 22:24:10,976:INFO:Copying training dataset
2024-09-05 22:24:11,831:INFO:Defining folds
2024-09-05 22:24:11,831:INFO:Declaring metric variables
2024-09-05 22:24:11,831:INFO:Importing untrained model
2024-09-05 22:24:11,831:INFO:Declaring custom model
2024-09-05 22:24:11,832:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 22:24:11,833:INFO:Starting cross validation
2024-09-05 22:24:11,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 22:25:34,901:INFO:Calculating mean and std
2024-09-05 22:25:34,901:INFO:Creating metrics dataframe
2024-09-05 22:25:34,904:INFO:Finalizing model
2024-09-05 22:25:40,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165781 seconds.
2024-09-05 22:25:40,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 22:25:40,303:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 22:25:40,307:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 22:25:40,310:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:25:40,311:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:25:40,311:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:25:51,517:INFO:Uploading results into container
2024-09-05 22:25:51,518:INFO:Uploading model into container now
2024-09-05 22:25:51,519:INFO:_master_model_container: 18
2024-09-05 22:25:51,519:INFO:_display_container: 5
2024-09-05 22:25:51,519:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:25:51,519:INFO:create_model() successfully completed......................................
2024-09-05 22:25:51,617:INFO:SubProcess create_model() end ==================================
2024-09-05 22:25:51,617:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8294
2024-09-05 22:25:51,618:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8284
2024-09-05 22:25:51,618:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-05 22:25:51,618:INFO:choose_better completed
2024-09-05 22:25:51,619:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-05 22:25:51,628:INFO:_master_model_container: 18
2024-09-05 22:25:51,629:INFO:_display_container: 4
2024-09-05 22:25:51,629:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:25:51,629:INFO:tune_model() successfully completed......................................
2024-09-05 22:25:55,351:INFO:Initializing evaluate_model()
2024-09-05 22:25:55,351:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-09-05 22:25:55,704:INFO:Initializing plot_model()
2024-09-05 22:25:55,704:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:25:55,704:INFO:Checking exceptions
2024-09-05 22:25:55,962:INFO:Preloading libraries
2024-09-05 22:25:55,982:INFO:Copying training dataset
2024-09-05 22:25:55,982:INFO:Plot type: pipeline
2024-09-05 22:25:56,166:INFO:Visual Rendered Successfully
2024-09-05 22:25:56,245:INFO:plot_model() successfully completed......................................
2024-09-05 22:25:57,877:INFO:Initializing plot_model()
2024-09-05 22:25:57,877:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:25:57,878:INFO:Checking exceptions
2024-09-05 22:25:58,137:INFO:Preloading libraries
2024-09-05 22:25:58,158:INFO:Copying training dataset
2024-09-05 22:25:58,158:INFO:Plot type: parameter
2024-09-05 22:25:58,163:INFO:Visual Rendered Successfully
2024-09-05 22:25:58,254:INFO:plot_model() successfully completed......................................
2024-09-05 22:25:59,925:INFO:Initializing plot_model()
2024-09-05 22:25:59,925:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:25:59,925:INFO:Checking exceptions
2024-09-05 22:26:00,213:INFO:Preloading libraries
2024-09-05 22:26:00,233:INFO:Copying training dataset
2024-09-05 22:26:00,233:INFO:Plot type: auc
2024-09-05 22:26:02,869:INFO:Fitting Model
2024-09-05 22:26:02,871:INFO:Scoring test/hold-out set
2024-09-05 22:26:03,303:INFO:Visual Rendered Successfully
2024-09-05 22:26:03,395:INFO:plot_model() successfully completed......................................
2024-09-05 22:26:04,841:INFO:Initializing plot_model()
2024-09-05 22:26:04,841:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:26:04,841:INFO:Checking exceptions
2024-09-05 22:26:05,126:INFO:Preloading libraries
2024-09-05 22:26:05,148:INFO:Copying training dataset
2024-09-05 22:26:05,148:INFO:Plot type: confusion_matrix
2024-09-05 22:26:07,616:INFO:Fitting Model
2024-09-05 22:26:07,618:INFO:Scoring test/hold-out set
2024-09-05 22:26:07,945:INFO:Visual Rendered Successfully
2024-09-05 22:26:08,039:INFO:plot_model() successfully completed......................................
2024-09-05 22:27:45,950:INFO:Initializing plot_model()
2024-09-05 22:27:45,951:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:27:45,951:INFO:Checking exceptions
2024-09-05 22:27:46,275:INFO:Preloading libraries
2024-09-05 22:27:46,296:INFO:Copying training dataset
2024-09-05 22:27:46,296:INFO:Plot type: error
2024-09-05 22:27:48,726:INFO:Fitting Model
2024-09-05 22:27:48,727:INFO:Scoring test/hold-out set
2024-09-05 22:27:49,101:INFO:Visual Rendered Successfully
2024-09-05 22:27:49,189:INFO:plot_model() successfully completed......................................
2024-09-05 22:28:20,674:INFO:Initializing plot_model()
2024-09-05 22:28:20,674:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:28:20,675:INFO:Checking exceptions
2024-09-05 22:28:20,940:INFO:Preloading libraries
2024-09-05 22:28:20,962:INFO:Copying training dataset
2024-09-05 22:28:20,963:INFO:Plot type: class_report
2024-09-05 22:28:23,555:INFO:Fitting Model
2024-09-05 22:28:23,556:INFO:Scoring test/hold-out set
2024-09-05 22:28:23,965:INFO:Visual Rendered Successfully
2024-09-05 22:28:24,066:INFO:plot_model() successfully completed......................................
2024-09-05 22:28:29,022:INFO:Initializing plot_model()
2024-09-05 22:28:29,022:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:28:29,022:INFO:Checking exceptions
2024-09-05 22:28:34,051:INFO:Initializing plot_model()
2024-09-05 22:28:34,051:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:28:34,051:INFO:Checking exceptions
2024-09-05 22:28:34,326:INFO:Preloading libraries
2024-09-05 22:28:34,347:INFO:Copying training dataset
2024-09-05 22:28:34,348:INFO:Plot type: learning
2024-09-05 22:28:36,898:INFO:Fitting Model
2024-09-05 22:37:08,892:INFO:Initializing predict_model()
2024-09-05 22:37:08,892:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002422AB3B490>)
2024-09-05 22:37:08,892:INFO:Checking exceptions
2024-09-05 22:37:08,892:INFO:Preloading libraries
2024-09-05 22:37:11,159:INFO:Initializing evaluate_model()
2024-09-05 22:37:11,159:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-09-05 22:37:11,464:INFO:Initializing plot_model()
2024-09-05 22:37:11,464:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:37:11,464:INFO:Checking exceptions
2024-09-05 22:37:11,723:INFO:Preloading libraries
2024-09-05 22:37:11,747:INFO:Copying training dataset
2024-09-05 22:37:11,747:INFO:Plot type: pipeline
2024-09-05 22:37:11,865:INFO:Visual Rendered Successfully
2024-09-05 22:37:11,966:INFO:plot_model() successfully completed......................................
2024-09-05 22:37:11,989:INFO:Initializing evaluate_model()
2024-09-05 22:37:11,989:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-09-05 22:37:12,279:INFO:Initializing plot_model()
2024-09-05 22:37:12,279:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:37:12,279:INFO:Checking exceptions
2024-09-05 22:37:12,556:INFO:Preloading libraries
2024-09-05 22:37:12,580:INFO:Copying training dataset
2024-09-05 22:37:12,580:INFO:Plot type: pipeline
2024-09-05 22:37:12,697:INFO:Visual Rendered Successfully
2024-09-05 22:37:12,800:INFO:plot_model() successfully completed......................................
2024-09-05 22:37:12,824:INFO:Initializing plot_model()
2024-09-05 22:37:12,825:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:37:12,825:INFO:Checking exceptions
2024-09-05 22:37:13,116:INFO:Preloading libraries
2024-09-05 22:37:13,137:INFO:Copying training dataset
2024-09-05 22:37:13,137:INFO:Plot type: pipeline
2024-09-05 22:37:13,253:INFO:Visual Rendered Successfully
2024-09-05 22:37:13,351:INFO:plot_model() successfully completed......................................
2024-09-05 22:37:24,549:INFO:Initializing get_config()
2024-09-05 22:37:24,549:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, variable=X_train)
2024-09-05 22:37:24,550:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-05 22:37:24,820:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-05 22:37:24,820:INFO:get_config() successfully completed......................................
2024-09-05 22:37:24,821:INFO:Initializing predict_model()
2024-09-05 22:37:24,821:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024235D5B1C0>)
2024-09-05 22:37:24,821:INFO:Checking exceptions
2024-09-05 22:37:24,821:INFO:Preloading libraries
2024-09-05 22:37:24,823:INFO:Set up data.
2024-09-05 22:37:25,079:INFO:Set up index.
2024-09-05 22:37:32,500:INFO:Initializing get_config()
2024-09-05 22:37:32,500:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, variable=X_train)
2024-09-05 22:37:32,500:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-05 22:37:32,777:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-05 22:37:32,777:INFO:get_config() successfully completed......................................
2024-09-05 22:37:32,777:INFO:Initializing predict_model()
2024-09-05 22:37:32,777:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002422A0ABE20>)
2024-09-05 22:37:32,778:INFO:Checking exceptions
2024-09-05 22:37:32,778:INFO:Preloading libraries
2024-09-05 22:37:32,779:INFO:Set up data.
2024-09-05 22:37:33,032:INFO:Set up index.
2024-09-05 22:37:34,570:INFO:Initializing get_config()
2024-09-05 22:37:34,570:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, variable=y_train)
2024-09-05 22:37:34,570:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-05 22:37:34,761:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-05 22:37:34,762:INFO:get_config() successfully completed......................................
2024-09-05 22:37:34,762:INFO:Initializing get_config()
2024-09-05 22:37:34,762:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, variable=y_test)
2024-09-05 22:37:34,762:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-05 22:37:34,901:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-05 22:37:34,901:INFO:get_config() successfully completed......................................
2024-09-05 22:37:46,038:INFO:Initializing finalize_model()
2024-09-05 22:37:46,038:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-05 22:37:46,038:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:37:46,558:INFO:Initializing create_model()
2024-09-05 22:37:46,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 22:37:46,558:INFO:Checking exceptions
2024-09-05 22:37:46,559:INFO:Importing libraries
2024-09-05 22:37:46,559:INFO:Copying training dataset
2024-09-05 22:37:46,650:INFO:Defining folds
2024-09-05 22:37:46,650:INFO:Declaring metric variables
2024-09-05 22:37:46,651:INFO:Importing untrained model
2024-09-05 22:37:46,651:INFO:Declaring custom model
2024-09-05 22:37:46,652:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 22:37:46,655:INFO:Cross validation set to False
2024-09-05 22:37:46,655:INFO:Fitting Model
2024-09-05 22:37:55,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.278672 seconds.
2024-09-05 22:37:55,332:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 22:37:55,344:INFO:[LightGBM] [Info] Total Bins 130277
2024-09-05 22:37:55,348:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 534
2024-09-05 22:37:55,352:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:37:55,352:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:37:55,352:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:38:11,745:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-05 22:38:11,745:INFO:create_model() successfully completed......................................
2024-09-05 22:38:11,875:INFO:_master_model_container: 18
2024-09-05 22:38:11,875:INFO:_display_container: 5
2024-09-05 22:38:11,887:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-05 22:38:11,887:INFO:finalize_model() successfully completed......................................
2024-09-05 22:39:21,622:INFO:Initializing predict_model()
2024-09-05 22:39:21,622:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024235D5B1C0>)
2024-09-05 22:39:21,622:INFO:Checking exceptions
2024-09-05 22:39:21,622:INFO:Preloading libraries
2024-09-05 22:39:21,626:INFO:Set up data.
2024-09-05 22:39:22,161:INFO:Set up index.
2024-09-05 22:43:19,217:INFO:Initializing save_model()
2024-09-05 22:43:19,217:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=C:/Users/jesco/OneDrive - Universidad Santo Toms/Documentos/Python/T3/final_dt_t2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-09-05 22:43:19,217:INFO:Adding model into prep_pipe
2024-09-05 22:43:19,218:WARNING:Only Model saved as it was a pipeline.
2024-09-05 22:43:19,277:INFO:C:/Users/jesco/OneDrive - Universidad Santo Toms/Documentos/Python/T3/final_dt_t2.pkl saved in current working directory
2024-09-05 22:43:19,294:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-05 22:43:19,294:INFO:save_model() successfully completed......................................
2024-09-05 22:58:41,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 22:58:41,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 22:58:41,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 22:58:41,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 22:59:16,766:INFO:PyCaret ClassificationExperiment
2024-09-05 22:59:16,766:INFO:Logging name: clf-default-name
2024-09-05 22:59:16,766:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-05 22:59:16,766:INFO:version 3.3.2
2024-09-05 22:59:16,766:INFO:Initializing setup()
2024-09-05 22:59:16,766:INFO:self.USI: 3408
2024-09-05 22:59:16,766:INFO:self._variable_keys: {'y', 'log_plots_param', 'html_param', 'is_multiclass', 'fold_generator', 'y_train', 'X', 'logging_param', 'n_jobs_param', 'fix_imbalance', '_ml_usecase', 'y_test', 'X_test', 'USI', 'X_train', 'gpu_param', 'exp_name_log', 'seed', 'pipeline', 'memory', 'fold_shuffle_param', 'target_param', '_available_plots', 'data', 'gpu_n_jobs_param', 'exp_id', 'fold_groups_param', 'idx'}
2024-09-05 22:59:16,766:INFO:Checking environment
2024-09-05 22:59:16,766:INFO:python_version: 3.10.11
2024-09-05 22:59:16,766:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-05 22:59:16,766:INFO:machine: AMD64
2024-09-05 22:59:16,766:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-05 22:59:16,766:INFO:Memory: svmem(total=17128263680, available=9607118848, percent=43.9, used=7521144832, free=9607118848)
2024-09-05 22:59:16,767:INFO:Physical Core: 6
2024-09-05 22:59:16,767:INFO:Logical Core: 12
2024-09-05 22:59:16,767:INFO:Checking libraries
2024-09-05 22:59:16,767:INFO:System:
2024-09-05 22:59:16,767:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-05 22:59:16,767:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-05 22:59:16,767:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-05 22:59:16,767:INFO:PyCaret required dependencies:
2024-09-05 22:59:16,783:INFO:                 pip: 24.2
2024-09-05 22:59:16,783:INFO:          setuptools: 72.1.0
2024-09-05 22:59:16,783:INFO:             pycaret: 3.3.2
2024-09-05 22:59:16,783:INFO:             IPython: 8.27.0
2024-09-05 22:59:16,783:INFO:          ipywidgets: 8.1.5
2024-09-05 22:59:16,783:INFO:                tqdm: 4.66.5
2024-09-05 22:59:16,783:INFO:               numpy: 1.26.4
2024-09-05 22:59:16,783:INFO:              pandas: 2.2.2
2024-09-05 22:59:16,783:INFO:              jinja2: 3.1.4
2024-09-05 22:59:16,783:INFO:               scipy: 1.11.4
2024-09-05 22:59:16,783:INFO:              joblib: 1.3.2
2024-09-05 22:59:16,783:INFO:             sklearn: 1.4.2
2024-09-05 22:59:16,783:INFO:                pyod: 2.0.1
2024-09-05 22:59:16,783:INFO:            imblearn: 0.12.3
2024-09-05 22:59:16,783:INFO:   category_encoders: 2.6.3
2024-09-05 22:59:16,783:INFO:            lightgbm: 4.5.0
2024-09-05 22:59:16,783:INFO:               numba: 0.60.0
2024-09-05 22:59:16,783:INFO:            requests: 2.32.3
2024-09-05 22:59:16,783:INFO:          matplotlib: 3.7.5
2024-09-05 22:59:16,783:INFO:          scikitplot: 0.3.7
2024-09-05 22:59:16,783:INFO:         yellowbrick: 1.5
2024-09-05 22:59:16,783:INFO:              plotly: 5.24.0
2024-09-05 22:59:16,783:INFO:    plotly-resampler: Not installed
2024-09-05 22:59:16,783:INFO:             kaleido: 0.2.1
2024-09-05 22:59:16,783:INFO:           schemdraw: 0.15
2024-09-05 22:59:16,783:INFO:         statsmodels: 0.14.2
2024-09-05 22:59:16,783:INFO:              sktime: 0.26.0
2024-09-05 22:59:16,783:INFO:               tbats: 1.1.3
2024-09-05 22:59:16,783:INFO:            pmdarima: 2.0.4
2024-09-05 22:59:16,783:INFO:              psutil: 6.0.0
2024-09-05 22:59:16,783:INFO:          markupsafe: 2.1.5
2024-09-05 22:59:16,783:INFO:             pickle5: Not installed
2024-09-05 22:59:16,783:INFO:         cloudpickle: 3.0.0
2024-09-05 22:59:16,783:INFO:         deprecation: 2.1.0
2024-09-05 22:59:16,783:INFO:              xxhash: 3.5.0
2024-09-05 22:59:16,783:INFO:           wurlitzer: Not installed
2024-09-05 22:59:16,783:INFO:PyCaret optional dependencies:
2024-09-05 22:59:16,799:INFO:                shap: Not installed
2024-09-05 22:59:16,814:INFO:           interpret: Not installed
2024-09-05 22:59:16,814:INFO:                umap: Not installed
2024-09-05 22:59:16,814:INFO:     ydata_profiling: Not installed
2024-09-05 22:59:16,814:INFO:  explainerdashboard: Not installed
2024-09-05 22:59:16,814:INFO:             autoviz: Not installed
2024-09-05 22:59:16,814:INFO:           fairlearn: Not installed
2024-09-05 22:59:16,814:INFO:          deepchecks: Not installed
2024-09-05 22:59:16,814:INFO:             xgboost: 2.1.1
2024-09-05 22:59:16,814:INFO:            catboost: Not installed
2024-09-05 22:59:16,814:INFO:              kmodes: Not installed
2024-09-05 22:59:16,814:INFO:             mlxtend: Not installed
2024-09-05 22:59:16,814:INFO:       statsforecast: Not installed
2024-09-05 22:59:16,814:INFO:        tune_sklearn: Not installed
2024-09-05 22:59:16,814:INFO:                 ray: Not installed
2024-09-05 22:59:16,814:INFO:            hyperopt: 0.2.7
2024-09-05 22:59:16,814:INFO:              optuna: 4.0.0
2024-09-05 22:59:16,814:INFO:               skopt: 0.10.2
2024-09-05 22:59:16,814:INFO:              mlflow: Not installed
2024-09-05 22:59:16,814:INFO:              gradio: Not installed
2024-09-05 22:59:16,814:INFO:             fastapi: Not installed
2024-09-05 22:59:16,814:INFO:             uvicorn: Not installed
2024-09-05 22:59:16,814:INFO:              m2cgen: Not installed
2024-09-05 22:59:16,814:INFO:           evidently: Not installed
2024-09-05 22:59:16,814:INFO:               fugue: Not installed
2024-09-05 22:59:16,814:INFO:           streamlit: Not installed
2024-09-05 22:59:16,814:INFO:             prophet: Not installed
2024-09-05 22:59:16,814:INFO:None
2024-09-05 22:59:16,814:INFO:Set up data.
2024-09-05 22:59:17,502:INFO:Set up folding strategy.
2024-09-05 22:59:17,502:INFO:Set up train/test split.
2024-09-05 22:59:18,310:INFO:Set up index.
2024-09-05 22:59:18,341:INFO:Assigning column types.
2024-09-05 22:59:19,172:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-05 22:59:19,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 22:59:19,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 22:59:19,266:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 22:59:19,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 22:59:19,312:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 22:59:19,312:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 22:59:19,346:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 22:59:19,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 22:59:19,346:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-05 22:59:19,393:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 22:59:19,424:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 22:59:19,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 22:59:19,486:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 22:59:19,518:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 22:59:19,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 22:59:19,518:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-05 22:59:19,596:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 22:59:19,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 22:59:19,674:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 22:59:19,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 22:59:19,690:INFO:Preparing preprocessing pipeline...
2024-09-05 22:59:19,815:INFO:Set up simple imputation.
2024-09-05 22:59:19,815:INFO:Set up imbalanced handling.
2024-09-05 22:59:20,862:INFO:Finished creating preprocessing pipeline.
2024-09-05 22:59:20,877:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-05 22:59:20,877:INFO:Creating final display dataframe.
2024-09-05 22:59:24,102:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 535)
4        Transformed data shape      (99147, 535)
5   Transformed train set shape      (76191, 535)
6    Transformed test set shape      (22956, 535)
7              Numeric features               534
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              3408
2024-09-05 22:59:24,192:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 22:59:24,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 22:59:24,271:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 22:59:24,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 22:59:24,271:INFO:setup() successfully completed in 7.52s...............
2024-09-05 22:59:24,290:INFO:Initializing compare_models()
2024-09-05 22:59:24,290:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-05 22:59:24,290:INFO:Checking exceptions
2024-09-05 22:59:24,832:INFO:Preparing display monitor
2024-09-05 22:59:24,865:INFO:Initializing Logistic Regression
2024-09-05 22:59:24,865:INFO:Total runtime is 0.0 minutes
2024-09-05 22:59:24,868:INFO:SubProcess create_model() called ==================================
2024-09-05 22:59:24,868:INFO:Initializing create_model()
2024-09-05 22:59:24,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 22:59:24,869:INFO:Checking exceptions
2024-09-05 22:59:24,869:INFO:Importing libraries
2024-09-05 22:59:24,869:INFO:Copying training dataset
2024-09-05 22:59:25,706:INFO:Defining folds
2024-09-05 22:59:25,706:INFO:Declaring metric variables
2024-09-05 22:59:25,706:INFO:Importing untrained model
2024-09-05 22:59:25,706:INFO:Logistic Regression Imported successfully
2024-09-05 22:59:25,723:INFO:Starting cross validation
2024-09-05 22:59:25,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:03:13,963:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:18,627:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:19,583:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:25,112:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:25,794:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:26,122:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:26,443:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:27,126:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:28,864:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:34,062:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:03:34,093:INFO:Calculating mean and std
2024-09-05 23:03:34,093:INFO:Creating metrics dataframe
2024-09-05 23:03:34,093:INFO:Uploading results into container
2024-09-05 23:03:34,093:INFO:Uploading model into container now
2024-09-05 23:03:34,093:INFO:_master_model_container: 1
2024-09-05 23:03:34,093:INFO:_display_container: 2
2024-09-05 23:03:34,093:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-05 23:03:34,093:INFO:create_model() successfully completed......................................
2024-09-05 23:03:34,196:INFO:SubProcess create_model() end ==================================
2024-09-05 23:03:34,196:INFO:Creating metrics dataframe
2024-09-05 23:03:34,202:INFO:Initializing K Neighbors Classifier
2024-09-05 23:03:34,202:INFO:Total runtime is 4.155614467461904 minutes
2024-09-05 23:03:34,204:INFO:SubProcess create_model() called ==================================
2024-09-05 23:03:34,204:INFO:Initializing create_model()
2024-09-05 23:03:34,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:03:34,207:INFO:Checking exceptions
2024-09-05 23:03:34,207:INFO:Importing libraries
2024-09-05 23:03:34,207:INFO:Copying training dataset
2024-09-05 23:03:35,068:INFO:Defining folds
2024-09-05 23:03:35,068:INFO:Declaring metric variables
2024-09-05 23:03:35,084:INFO:Importing untrained model
2024-09-05 23:03:35,089:INFO:K Neighbors Classifier Imported successfully
2024-09-05 23:03:35,094:INFO:Starting cross validation
2024-09-05 23:03:35,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:04:31,972:INFO:Calculating mean and std
2024-09-05 23:04:31,974:INFO:Creating metrics dataframe
2024-09-05 23:04:31,976:INFO:Uploading results into container
2024-09-05 23:04:31,977:INFO:Uploading model into container now
2024-09-05 23:04:31,977:INFO:_master_model_container: 2
2024-09-05 23:04:31,977:INFO:_display_container: 2
2024-09-05 23:04:31,978:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-05 23:04:31,978:INFO:create_model() successfully completed......................................
2024-09-05 23:04:32,056:INFO:SubProcess create_model() end ==================================
2024-09-05 23:04:32,056:INFO:Creating metrics dataframe
2024-09-05 23:04:32,071:INFO:Initializing Naive Bayes
2024-09-05 23:04:32,071:INFO:Total runtime is 5.1201113263765965 minutes
2024-09-05 23:04:32,071:INFO:SubProcess create_model() called ==================================
2024-09-05 23:04:32,071:INFO:Initializing create_model()
2024-09-05 23:04:32,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:04:32,082:INFO:Checking exceptions
2024-09-05 23:04:32,082:INFO:Importing libraries
2024-09-05 23:04:32,082:INFO:Copying training dataset
2024-09-05 23:04:32,919:INFO:Defining folds
2024-09-05 23:04:32,919:INFO:Declaring metric variables
2024-09-05 23:04:32,919:INFO:Importing untrained model
2024-09-05 23:04:32,934:INFO:Naive Bayes Imported successfully
2024-09-05 23:04:32,941:INFO:Starting cross validation
2024-09-05 23:04:32,945:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:04:55,695:INFO:Calculating mean and std
2024-09-05 23:04:55,695:INFO:Creating metrics dataframe
2024-09-05 23:04:55,695:INFO:Uploading results into container
2024-09-05 23:04:55,695:INFO:Uploading model into container now
2024-09-05 23:04:55,695:INFO:_master_model_container: 3
2024-09-05 23:04:55,695:INFO:_display_container: 2
2024-09-05 23:04:55,695:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-05 23:04:55,695:INFO:create_model() successfully completed......................................
2024-09-05 23:04:55,771:INFO:SubProcess create_model() end ==================================
2024-09-05 23:04:55,771:INFO:Creating metrics dataframe
2024-09-05 23:04:55,786:INFO:Initializing Decision Tree Classifier
2024-09-05 23:04:55,786:INFO:Total runtime is 5.515358022848765 minutes
2024-09-05 23:04:55,786:INFO:SubProcess create_model() called ==================================
2024-09-05 23:04:55,786:INFO:Initializing create_model()
2024-09-05 23:04:55,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:04:55,786:INFO:Checking exceptions
2024-09-05 23:04:55,786:INFO:Importing libraries
2024-09-05 23:04:55,786:INFO:Copying training dataset
2024-09-05 23:04:56,590:INFO:Defining folds
2024-09-05 23:04:56,590:INFO:Declaring metric variables
2024-09-05 23:04:56,605:INFO:Importing untrained model
2024-09-05 23:04:56,612:INFO:Decision Tree Classifier Imported successfully
2024-09-05 23:04:56,616:INFO:Starting cross validation
2024-09-05 23:04:56,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:06:02,201:INFO:Calculating mean and std
2024-09-05 23:06:02,201:INFO:Creating metrics dataframe
2024-09-05 23:06:02,201:INFO:Uploading results into container
2024-09-05 23:06:02,201:INFO:Uploading model into container now
2024-09-05 23:06:02,201:INFO:_master_model_container: 4
2024-09-05 23:06:02,201:INFO:_display_container: 2
2024-09-05 23:06:02,201:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-05 23:06:02,201:INFO:create_model() successfully completed......................................
2024-09-05 23:06:02,287:INFO:SubProcess create_model() end ==================================
2024-09-05 23:06:02,287:INFO:Creating metrics dataframe
2024-09-05 23:06:02,295:INFO:Initializing SVM - Linear Kernel
2024-09-05 23:06:02,295:INFO:Total runtime is 6.623838452498118 minutes
2024-09-05 23:06:02,299:INFO:SubProcess create_model() called ==================================
2024-09-05 23:06:02,299:INFO:Initializing create_model()
2024-09-05 23:06:02,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:06:02,299:INFO:Checking exceptions
2024-09-05 23:06:02,299:INFO:Importing libraries
2024-09-05 23:06:02,299:INFO:Copying training dataset
2024-09-05 23:06:03,131:INFO:Defining folds
2024-09-05 23:06:03,131:INFO:Declaring metric variables
2024-09-05 23:06:03,131:INFO:Importing untrained model
2024-09-05 23:06:03,149:INFO:SVM - Linear Kernel Imported successfully
2024-09-05 23:06:03,156:INFO:Starting cross validation
2024-09-05 23:06:03,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:06:43,080:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:44,519:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:46,533:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:47,049:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:47,402:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:48,964:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:49,151:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:49,183:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:49,762:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:49,980:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:06:50,012:INFO:Calculating mean and std
2024-09-05 23:06:50,012:INFO:Creating metrics dataframe
2024-09-05 23:06:50,012:INFO:Uploading results into container
2024-09-05 23:06:50,012:INFO:Uploading model into container now
2024-09-05 23:06:50,012:INFO:_master_model_container: 5
2024-09-05 23:06:50,012:INFO:_display_container: 2
2024-09-05 23:06:50,018:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-05 23:06:50,018:INFO:create_model() successfully completed......................................
2024-09-05 23:06:50,089:INFO:SubProcess create_model() end ==================================
2024-09-05 23:06:50,089:INFO:Creating metrics dataframe
2024-09-05 23:06:50,105:INFO:Initializing Ridge Classifier
2024-09-05 23:06:50,105:INFO:Total runtime is 7.420665001869201 minutes
2024-09-05 23:06:50,109:INFO:SubProcess create_model() called ==================================
2024-09-05 23:06:50,109:INFO:Initializing create_model()
2024-09-05 23:06:50,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:06:50,109:INFO:Checking exceptions
2024-09-05 23:06:50,109:INFO:Importing libraries
2024-09-05 23:06:50,109:INFO:Copying training dataset
2024-09-05 23:06:50,895:INFO:Defining folds
2024-09-05 23:06:50,895:INFO:Declaring metric variables
2024-09-05 23:06:50,899:INFO:Importing untrained model
2024-09-05 23:06:50,903:INFO:Ridge Classifier Imported successfully
2024-09-05 23:06:50,911:INFO:Starting cross validation
2024-09-05 23:06:50,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:07:09,700:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:10,294:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:11,163:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:11,210:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:11,818:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:12,150:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:12,275:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:12,562:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:13,046:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:13,419:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:07:13,466:INFO:Calculating mean and std
2024-09-05 23:07:13,466:INFO:Creating metrics dataframe
2024-09-05 23:07:13,466:INFO:Uploading results into container
2024-09-05 23:07:13,466:INFO:Uploading model into container now
2024-09-05 23:07:13,466:INFO:_master_model_container: 6
2024-09-05 23:07:13,466:INFO:_display_container: 2
2024-09-05 23:07:13,466:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-05 23:07:13,466:INFO:create_model() successfully completed......................................
2024-09-05 23:07:13,535:INFO:SubProcess create_model() end ==================================
2024-09-05 23:07:13,535:INFO:Creating metrics dataframe
2024-09-05 23:07:13,548:INFO:Initializing Random Forest Classifier
2024-09-05 23:07:13,548:INFO:Total runtime is 7.811384538809458 minutes
2024-09-05 23:07:13,551:INFO:SubProcess create_model() called ==================================
2024-09-05 23:07:13,551:INFO:Initializing create_model()
2024-09-05 23:07:13,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:07:13,551:INFO:Checking exceptions
2024-09-05 23:07:13,551:INFO:Importing libraries
2024-09-05 23:07:13,551:INFO:Copying training dataset
2024-09-05 23:07:14,312:INFO:Defining folds
2024-09-05 23:07:14,312:INFO:Declaring metric variables
2024-09-05 23:07:14,312:INFO:Importing untrained model
2024-09-05 23:07:14,330:INFO:Random Forest Classifier Imported successfully
2024-09-05 23:07:14,336:INFO:Starting cross validation
2024-09-05 23:07:14,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:09:09,699:INFO:Calculating mean and std
2024-09-05 23:09:09,699:INFO:Creating metrics dataframe
2024-09-05 23:09:09,699:INFO:Uploading results into container
2024-09-05 23:09:09,699:INFO:Uploading model into container now
2024-09-05 23:09:09,699:INFO:_master_model_container: 7
2024-09-05 23:09:09,699:INFO:_display_container: 2
2024-09-05 23:09:09,699:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-05 23:09:09,699:INFO:create_model() successfully completed......................................
2024-09-05 23:09:09,776:INFO:SubProcess create_model() end ==================================
2024-09-05 23:09:09,776:INFO:Creating metrics dataframe
2024-09-05 23:09:09,792:INFO:Initializing Quadratic Discriminant Analysis
2024-09-05 23:09:09,792:INFO:Total runtime is 9.74878066778183 minutes
2024-09-05 23:09:09,799:INFO:SubProcess create_model() called ==================================
2024-09-05 23:09:09,799:INFO:Initializing create_model()
2024-09-05 23:09:09,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:09:09,799:INFO:Checking exceptions
2024-09-05 23:09:09,799:INFO:Importing libraries
2024-09-05 23:09:09,799:INFO:Copying training dataset
2024-09-05 23:09:10,660:INFO:Defining folds
2024-09-05 23:09:10,660:INFO:Declaring metric variables
2024-09-05 23:09:10,660:INFO:Importing untrained model
2024-09-05 23:09:10,674:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-05 23:09:10,674:INFO:Starting cross validation
2024-09-05 23:09:10,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:09:31,741:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:32,521:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:34,373:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:36,772:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:37,532:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:39,186:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:39,658:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:41,640:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:41,861:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:43,140:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 23:09:43,373:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:45,374:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:46,774:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:48,500:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:48,750:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:49,346:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:49,670:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:50,246:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:50,309:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:50,641:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:09:50,672:INFO:Calculating mean and std
2024-09-05 23:09:50,672:INFO:Creating metrics dataframe
2024-09-05 23:09:50,672:INFO:Uploading results into container
2024-09-05 23:09:50,672:INFO:Uploading model into container now
2024-09-05 23:09:50,672:INFO:_master_model_container: 8
2024-09-05 23:09:50,672:INFO:_display_container: 2
2024-09-05 23:09:50,672:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-05 23:09:50,672:INFO:create_model() successfully completed......................................
2024-09-05 23:09:50,737:INFO:SubProcess create_model() end ==================================
2024-09-05 23:09:50,737:INFO:Creating metrics dataframe
2024-09-05 23:09:50,757:INFO:Initializing Ada Boost Classifier
2024-09-05 23:09:50,757:INFO:Total runtime is 10.431533869107565 minutes
2024-09-05 23:09:50,760:INFO:SubProcess create_model() called ==================================
2024-09-05 23:09:50,761:INFO:Initializing create_model()
2024-09-05 23:09:50,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:09:50,761:INFO:Checking exceptions
2024-09-05 23:09:50,761:INFO:Importing libraries
2024-09-05 23:09:50,761:INFO:Copying training dataset
2024-09-05 23:09:51,540:INFO:Defining folds
2024-09-05 23:09:51,540:INFO:Declaring metric variables
2024-09-05 23:09:51,554:INFO:Importing untrained model
2024-09-05 23:09:51,554:INFO:Ada Boost Classifier Imported successfully
2024-09-05 23:09:51,566:INFO:Starting cross validation
2024-09-05 23:09:51,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:10:09,587:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:10:09,931:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:10:10,306:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:10:10,777:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:10:11,292:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:10:11,433:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:10:11,946:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:10:12,434:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:10:12,763:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:10:13,248:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 23:11:44,498:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:44,983:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:45,395:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:45,536:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:45,833:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:46,336:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:46,456:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:46,581:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:46,870:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:47,380:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:11:47,411:INFO:Calculating mean and std
2024-09-05 23:11:47,411:INFO:Creating metrics dataframe
2024-09-05 23:11:47,411:INFO:Uploading results into container
2024-09-05 23:11:47,411:INFO:Uploading model into container now
2024-09-05 23:11:47,411:INFO:_master_model_container: 9
2024-09-05 23:11:47,411:INFO:_display_container: 2
2024-09-05 23:11:47,411:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-05 23:11:47,411:INFO:create_model() successfully completed......................................
2024-09-05 23:11:47,485:INFO:SubProcess create_model() end ==================================
2024-09-05 23:11:47,485:INFO:Creating metrics dataframe
2024-09-05 23:11:47,485:INFO:Initializing Gradient Boosting Classifier
2024-09-05 23:11:47,485:INFO:Total runtime is 12.377005712191265 minutes
2024-09-05 23:11:47,485:INFO:SubProcess create_model() called ==================================
2024-09-05 23:11:47,485:INFO:Initializing create_model()
2024-09-05 23:11:47,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:11:47,485:INFO:Checking exceptions
2024-09-05 23:11:47,485:INFO:Importing libraries
2024-09-05 23:11:47,499:INFO:Copying training dataset
2024-09-05 23:11:48,263:INFO:Defining folds
2024-09-05 23:11:48,263:INFO:Declaring metric variables
2024-09-05 23:11:48,282:INFO:Importing untrained model
2024-09-05 23:11:48,287:INFO:Gradient Boosting Classifier Imported successfully
2024-09-05 23:11:48,295:INFO:Starting cross validation
2024-09-05 23:11:48,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:35:22,998:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:23,510:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:23,760:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:25,776:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:25,869:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:25,916:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:25,979:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:26,182:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:26,213:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:26,405:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:26,441:INFO:Calculating mean and std
2024-09-05 23:35:26,441:INFO:Creating metrics dataframe
2024-09-05 23:35:26,441:INFO:Uploading results into container
2024-09-05 23:35:26,441:INFO:Uploading model into container now
2024-09-05 23:35:26,441:INFO:_master_model_container: 10
2024-09-05 23:35:26,441:INFO:_display_container: 2
2024-09-05 23:35:26,441:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-05 23:35:26,441:INFO:create_model() successfully completed......................................
2024-09-05 23:35:26,518:INFO:SubProcess create_model() end ==================================
2024-09-05 23:35:26,518:INFO:Creating metrics dataframe
2024-09-05 23:35:26,534:INFO:Initializing Linear Discriminant Analysis
2024-09-05 23:35:26,534:INFO:Total runtime is 36.027822375297546 minutes
2024-09-05 23:35:26,537:INFO:SubProcess create_model() called ==================================
2024-09-05 23:35:26,537:INFO:Initializing create_model()
2024-09-05 23:35:26,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:35:26,537:INFO:Checking exceptions
2024-09-05 23:35:26,538:INFO:Importing libraries
2024-09-05 23:35:26,538:INFO:Copying training dataset
2024-09-05 23:35:27,424:INFO:Defining folds
2024-09-05 23:35:27,424:INFO:Declaring metric variables
2024-09-05 23:35:27,439:INFO:Importing untrained model
2024-09-05 23:35:27,446:INFO:Linear Discriminant Analysis Imported successfully
2024-09-05 23:35:27,451:INFO:Starting cross validation
2024-09-05 23:35:27,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:35:52,084:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:52,850:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:53,724:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:55,693:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:57,512:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:58,310:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:58,406:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:58,437:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:58,828:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:59,183:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 23:35:59,215:INFO:Calculating mean and std
2024-09-05 23:35:59,215:INFO:Creating metrics dataframe
2024-09-05 23:35:59,215:INFO:Uploading results into container
2024-09-05 23:35:59,215:INFO:Uploading model into container now
2024-09-05 23:35:59,215:INFO:_master_model_container: 11
2024-09-05 23:35:59,215:INFO:_display_container: 2
2024-09-05 23:35:59,215:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-05 23:35:59,215:INFO:create_model() successfully completed......................................
2024-09-05 23:35:59,291:INFO:SubProcess create_model() end ==================================
2024-09-05 23:35:59,291:INFO:Creating metrics dataframe
2024-09-05 23:35:59,307:INFO:Initializing Extra Trees Classifier
2024-09-05 23:35:59,307:INFO:Total runtime is 36.574035636583965 minutes
2024-09-05 23:35:59,307:INFO:SubProcess create_model() called ==================================
2024-09-05 23:35:59,307:INFO:Initializing create_model()
2024-09-05 23:35:59,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:35:59,307:INFO:Checking exceptions
2024-09-05 23:35:59,307:INFO:Importing libraries
2024-09-05 23:35:59,307:INFO:Copying training dataset
2024-09-05 23:36:00,099:INFO:Defining folds
2024-09-05 23:36:00,099:INFO:Declaring metric variables
2024-09-05 23:36:00,099:INFO:Importing untrained model
2024-09-05 23:36:00,108:INFO:Extra Trees Classifier Imported successfully
2024-09-05 23:36:00,113:INFO:Starting cross validation
2024-09-05 23:36:00,113:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:37:42,129:INFO:Calculating mean and std
2024-09-05 23:37:42,129:INFO:Creating metrics dataframe
2024-09-05 23:37:42,129:INFO:Uploading results into container
2024-09-05 23:37:42,129:INFO:Uploading model into container now
2024-09-05 23:37:42,129:INFO:_master_model_container: 12
2024-09-05 23:37:42,129:INFO:_display_container: 2
2024-09-05 23:37:42,129:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-05 23:37:42,129:INFO:create_model() successfully completed......................................
2024-09-05 23:37:42,248:INFO:SubProcess create_model() end ==================================
2024-09-05 23:37:42,248:INFO:Creating metrics dataframe
2024-09-05 23:37:42,264:INFO:Initializing Extreme Gradient Boosting
2024-09-05 23:37:42,264:INFO:Total runtime is 38.289983316262564 minutes
2024-09-05 23:37:42,264:INFO:SubProcess create_model() called ==================================
2024-09-05 23:37:42,264:INFO:Initializing create_model()
2024-09-05 23:37:42,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:37:42,264:INFO:Checking exceptions
2024-09-05 23:37:42,264:INFO:Importing libraries
2024-09-05 23:37:42,264:INFO:Copying training dataset
2024-09-05 23:37:43,119:INFO:Defining folds
2024-09-05 23:37:43,119:INFO:Declaring metric variables
2024-09-05 23:37:43,119:INFO:Importing untrained model
2024-09-05 23:37:43,137:INFO:Extreme Gradient Boosting Imported successfully
2024-09-05 23:37:43,144:INFO:Starting cross validation
2024-09-05 23:37:43,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:39:26,795:INFO:Calculating mean and std
2024-09-05 23:39:26,795:INFO:Creating metrics dataframe
2024-09-05 23:39:26,795:INFO:Uploading results into container
2024-09-05 23:39:26,795:INFO:Uploading model into container now
2024-09-05 23:39:26,795:INFO:_master_model_container: 13
2024-09-05 23:39:26,795:INFO:_display_container: 2
2024-09-05 23:39:26,795:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-05 23:39:26,795:INFO:create_model() successfully completed......................................
2024-09-05 23:39:26,873:INFO:SubProcess create_model() end ==================================
2024-09-05 23:39:26,873:INFO:Creating metrics dataframe
2024-09-05 23:39:26,886:INFO:Initializing Light Gradient Boosting Machine
2024-09-05 23:39:26,886:INFO:Total runtime is 40.03368064959844 minutes
2024-09-05 23:39:26,891:INFO:SubProcess create_model() called ==================================
2024-09-05 23:39:26,891:INFO:Initializing create_model()
2024-09-05 23:39:26,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:39:26,892:INFO:Checking exceptions
2024-09-05 23:39:26,892:INFO:Importing libraries
2024-09-05 23:39:26,892:INFO:Copying training dataset
2024-09-05 23:39:27,662:INFO:Defining folds
2024-09-05 23:39:27,662:INFO:Declaring metric variables
2024-09-05 23:39:27,662:INFO:Importing untrained model
2024-09-05 23:39:27,670:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 23:39:27,676:INFO:Starting cross validation
2024-09-05 23:39:27,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:42:43,207:INFO:Calculating mean and std
2024-09-05 23:42:43,207:INFO:Creating metrics dataframe
2024-09-05 23:42:43,207:INFO:Uploading results into container
2024-09-05 23:42:43,207:INFO:Uploading model into container now
2024-09-05 23:42:43,207:INFO:_master_model_container: 14
2024-09-05 23:42:43,207:INFO:_display_container: 2
2024-09-05 23:42:43,207:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 23:42:43,207:INFO:create_model() successfully completed......................................
2024-09-05 23:42:43,306:INFO:SubProcess create_model() end ==================================
2024-09-05 23:42:43,306:INFO:Creating metrics dataframe
2024-09-05 23:42:43,332:INFO:Initializing Dummy Classifier
2024-09-05 23:42:43,332:INFO:Total runtime is 43.30779083569844 minutes
2024-09-05 23:42:43,332:INFO:SubProcess create_model() called ==================================
2024-09-05 23:42:43,332:INFO:Initializing create_model()
2024-09-05 23:42:43,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA42328C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:42:43,332:INFO:Checking exceptions
2024-09-05 23:42:43,332:INFO:Importing libraries
2024-09-05 23:42:43,332:INFO:Copying training dataset
2024-09-05 23:42:44,212:INFO:Defining folds
2024-09-05 23:42:44,212:INFO:Declaring metric variables
2024-09-05 23:42:44,212:INFO:Importing untrained model
2024-09-05 23:42:44,228:INFO:Dummy Classifier Imported successfully
2024-09-05 23:42:44,235:INFO:Starting cross validation
2024-09-05 23:42:44,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 23:43:02,206:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:02,388:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:02,841:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:03,154:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:03,717:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:04,035:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:04,498:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:04,654:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:04,669:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:05,138:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 23:43:05,185:INFO:Calculating mean and std
2024-09-05 23:43:05,185:INFO:Creating metrics dataframe
2024-09-05 23:43:05,185:INFO:Uploading results into container
2024-09-05 23:43:05,185:INFO:Uploading model into container now
2024-09-05 23:43:05,185:INFO:_master_model_container: 15
2024-09-05 23:43:05,185:INFO:_display_container: 2
2024-09-05 23:43:05,185:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-05 23:43:05,185:INFO:create_model() successfully completed......................................
2024-09-05 23:43:05,248:INFO:SubProcess create_model() end ==================================
2024-09-05 23:43:05,248:INFO:Creating metrics dataframe
2024-09-05 23:43:05,279:INFO:Initializing create_model()
2024-09-05 23:43:05,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:43:05,280:INFO:Checking exceptions
2024-09-05 23:43:05,282:INFO:Importing libraries
2024-09-05 23:43:05,282:INFO:Copying training dataset
2024-09-05 23:43:06,027:INFO:Defining folds
2024-09-05 23:43:06,027:INFO:Declaring metric variables
2024-09-05 23:43:06,027:INFO:Importing untrained model
2024-09-05 23:43:06,027:INFO:Declaring custom model
2024-09-05 23:43:06,027:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 23:43:06,027:INFO:Cross validation set to False
2024-09-05 23:43:06,027:INFO:Fitting Model
2024-09-05 23:43:11,560:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.156218 seconds.
2024-09-05 23:43:11,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 23:43:11,560:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 23:43:11,576:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 23:43:11,576:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 23:43:11,576:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 23:43:11,576:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 23:43:21,202:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 23:43:21,202:INFO:create_model() successfully completed......................................
2024-09-05 23:43:21,296:INFO:Initializing create_model()
2024-09-05 23:43:21,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:43:21,310:INFO:Checking exceptions
2024-09-05 23:43:21,312:INFO:Importing libraries
2024-09-05 23:43:21,312:INFO:Copying training dataset
2024-09-05 23:43:22,117:INFO:Defining folds
2024-09-05 23:43:22,117:INFO:Declaring metric variables
2024-09-05 23:43:22,117:INFO:Importing untrained model
2024-09-05 23:43:22,117:INFO:Declaring custom model
2024-09-05 23:43:22,117:INFO:Extreme Gradient Boosting Imported successfully
2024-09-05 23:43:22,117:INFO:Cross validation set to False
2024-09-05 23:43:22,117:INFO:Fitting Model
2024-09-05 23:43:38,078:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-05 23:43:38,078:INFO:create_model() successfully completed......................................
2024-09-05 23:43:38,203:INFO:Initializing create_model()
2024-09-05 23:43:38,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 23:43:38,203:INFO:Checking exceptions
2024-09-05 23:43:38,215:INFO:Importing libraries
2024-09-05 23:43:38,215:INFO:Copying training dataset
2024-09-05 23:43:39,024:INFO:Defining folds
2024-09-05 23:43:39,024:INFO:Declaring metric variables
2024-09-05 23:43:39,024:INFO:Importing untrained model
2024-09-05 23:43:39,024:INFO:Declaring custom model
2024-09-05 23:43:39,024:INFO:Gradient Boosting Classifier Imported successfully
2024-09-05 23:43:39,024:INFO:Cross validation set to False
2024-09-05 23:43:39,024:INFO:Fitting Model
2024-09-06 00:03:46,354:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 00:03:46,354:INFO:create_model() successfully completed......................................
2024-09-06 00:03:46,432:INFO:Initializing create_model()
2024-09-06 00:03:46,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:03:46,432:INFO:Checking exceptions
2024-09-06 00:03:46,443:INFO:Importing libraries
2024-09-06 00:03:46,444:INFO:Copying training dataset
2024-09-06 00:03:47,280:INFO:Defining folds
2024-09-06 00:03:47,280:INFO:Declaring metric variables
2024-09-06 00:03:47,280:INFO:Importing untrained model
2024-09-06 00:03:47,280:INFO:Declaring custom model
2024-09-06 00:03:47,280:INFO:Extra Trees Classifier Imported successfully
2024-09-06 00:03:47,280:INFO:Cross validation set to False
2024-09-06 00:03:47,280:INFO:Fitting Model
2024-09-06 00:03:59,229:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-06 00:03:59,229:INFO:create_model() successfully completed......................................
2024-09-06 00:03:59,356:INFO:_master_model_container: 15
2024-09-06 00:03:59,357:INFO:_display_container: 2
2024-09-06 00:03:59,359:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)]
2024-09-06 00:03:59,359:INFO:compare_models() successfully completed......................................
2024-09-06 00:03:59,369:INFO:Initializing create_model()
2024-09-06 00:03:59,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:03:59,369:INFO:Checking exceptions
2024-09-06 00:03:59,391:INFO:Importing libraries
2024-09-06 00:03:59,391:INFO:Copying training dataset
2024-09-06 00:04:00,196:INFO:Defining folds
2024-09-06 00:04:00,196:INFO:Declaring metric variables
2024-09-06 00:04:00,211:INFO:Importing untrained model
2024-09-06 00:04:00,211:INFO:Declaring custom model
2024-09-06 00:04:00,211:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:04:00,222:INFO:Starting cross validation
2024-09-06 00:04:00,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 00:07:07,262:INFO:Calculating mean and std
2024-09-06 00:07:07,262:INFO:Creating metrics dataframe
2024-09-06 00:07:07,262:INFO:Finalizing model
2024-09-06 00:07:12,725:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163979 seconds.
2024-09-06 00:07:12,725:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 00:07:12,734:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-06 00:07:12,734:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-06 00:07:12,734:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:07:12,734:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:07:12,734:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:07:22,411:INFO:Uploading results into container
2024-09-06 00:07:22,412:INFO:Uploading model into container now
2024-09-06 00:07:22,424:INFO:_master_model_container: 16
2024-09-06 00:07:22,424:INFO:_display_container: 3
2024-09-06 00:07:22,425:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 00:07:22,425:INFO:create_model() successfully completed......................................
2024-09-06 00:07:22,544:INFO:Initializing finalize_model()
2024-09-06 00:07:22,544:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 00:07:22,544:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 00:07:23,176:INFO:Initializing create_model()
2024-09-06 00:07:23,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:07:23,176:INFO:Checking exceptions
2024-09-06 00:07:23,176:INFO:Importing libraries
2024-09-06 00:07:23,176:INFO:Copying training dataset
2024-09-06 00:07:23,269:INFO:Defining folds
2024-09-06 00:07:23,269:INFO:Declaring metric variables
2024-09-06 00:07:23,269:INFO:Importing untrained model
2024-09-06 00:07:23,269:INFO:Declaring custom model
2024-09-06 00:07:23,269:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:07:23,269:INFO:Cross validation set to False
2024-09-06 00:07:23,269:INFO:Fitting Model
2024-09-06 00:07:31,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.269972 seconds.
2024-09-06 00:07:31,652:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 00:07:31,652:INFO:[LightGBM] [Info] Total Bins 130277
2024-09-06 00:07:31,667:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 534
2024-09-06 00:07:31,667:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:07:31,667:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:07:31,667:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:07:46,175:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:07:46,175:INFO:create_model() successfully completed......................................
2024-09-06 00:07:46,269:INFO:_master_model_container: 16
2024-09-06 00:07:46,269:INFO:_display_container: 3
2024-09-06 00:07:46,284:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:07:46,284:INFO:finalize_model() successfully completed......................................
2024-09-06 00:07:46,349:INFO:Initializing predict_model()
2024-09-06 00:07:46,349:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEDEB89F30>)
2024-09-06 00:07:46,349:INFO:Checking exceptions
2024-09-06 00:07:46,349:INFO:Preloading libraries
2024-09-06 00:07:46,365:INFO:Set up data.
2024-09-06 00:07:46,423:INFO:Set up index.
2024-09-06 00:23:35,305:INFO:Initializing finalize_model()
2024-09-06 00:23:35,306:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 00:23:35,306:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 00:23:35,828:INFO:Initializing create_model()
2024-09-06 00:23:35,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:23:35,828:INFO:Checking exceptions
2024-09-06 00:23:35,828:INFO:Importing libraries
2024-09-06 00:23:35,828:INFO:Copying training dataset
2024-09-06 00:23:35,921:INFO:Defining folds
2024-09-06 00:23:35,922:INFO:Declaring metric variables
2024-09-06 00:23:35,922:INFO:Importing untrained model
2024-09-06 00:23:35,922:INFO:Declaring custom model
2024-09-06 00:23:35,922:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:23:35,926:INFO:Cross validation set to False
2024-09-06 00:23:35,926:INFO:Fitting Model
2024-09-06 00:23:44,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219803 seconds.
2024-09-06 00:23:44,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 00:23:44,584:INFO:[LightGBM] [Info] Total Bins 130277
2024-09-06 00:23:44,600:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 534
2024-09-06 00:23:44,600:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:23:44,600:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:23:44,600:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:24:00,456:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:24:00,456:INFO:create_model() successfully completed......................................
2024-09-06 00:24:00,612:INFO:_master_model_container: 16
2024-09-06 00:24:00,612:INFO:_display_container: 3
2024-09-06 00:24:00,628:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:24:00,628:INFO:finalize_model() successfully completed......................................
2024-09-06 00:24:00,772:INFO:Initializing predict_model()
2024-09-06 00:24:00,772:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AE917B4430>)
2024-09-06 00:24:00,772:INFO:Checking exceptions
2024-09-06 00:24:00,772:INFO:Preloading libraries
2024-09-06 00:24:02,811:INFO:Initializing get_config()
2024-09-06 00:24:02,811:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 00:24:02,811:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 00:24:03,095:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 00:24:03,095:INFO:get_config() successfully completed......................................
2024-09-06 00:24:03,106:INFO:Initializing predict_model()
2024-09-06 00:24:03,106:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AE917B4430>)
2024-09-06 00:24:03,106:INFO:Checking exceptions
2024-09-06 00:24:03,106:INFO:Preloading libraries
2024-09-06 00:24:03,108:INFO:Set up data.
2024-09-06 00:24:03,362:INFO:Set up index.
2024-09-06 00:24:15,574:INFO:Initializing finalize_model()
2024-09-06 00:24:15,574:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 00:24:15,575:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 00:24:16,080:INFO:Initializing create_model()
2024-09-06 00:24:16,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:24:16,080:INFO:Checking exceptions
2024-09-06 00:24:16,080:INFO:Importing libraries
2024-09-06 00:24:16,080:INFO:Copying training dataset
2024-09-06 00:24:16,170:INFO:Defining folds
2024-09-06 00:24:16,170:INFO:Declaring metric variables
2024-09-06 00:24:16,170:INFO:Importing untrained model
2024-09-06 00:24:16,170:INFO:Declaring custom model
2024-09-06 00:24:16,170:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:24:16,170:INFO:Cross validation set to False
2024-09-06 00:24:16,170:INFO:Fitting Model
2024-09-06 00:24:24,655:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.272435 seconds.
2024-09-06 00:24:24,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 00:24:24,655:INFO:[LightGBM] [Info] Total Bins 130277
2024-09-06 00:24:24,671:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 534
2024-09-06 00:24:24,671:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:24:24,671:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:24:24,671:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:24:39,650:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:24:39,650:INFO:create_model() successfully completed......................................
2024-09-06 00:24:39,810:INFO:_master_model_container: 16
2024-09-06 00:24:39,810:INFO:_display_container: 4
2024-09-06 00:24:39,822:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:24:39,822:INFO:finalize_model() successfully completed......................................
2024-09-06 00:24:39,963:INFO:Initializing predict_model()
2024-09-06 00:24:39,963:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AE917B4430>)
2024-09-06 00:24:39,963:INFO:Checking exceptions
2024-09-06 00:24:39,963:INFO:Preloading libraries
2024-09-06 00:24:42,033:INFO:Initializing get_config()
2024-09-06 00:24:42,033:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 00:24:42,033:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 00:24:42,326:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 00:24:42,326:INFO:get_config() successfully completed......................................
2024-09-06 00:24:42,337:INFO:Initializing predict_model()
2024-09-06 00:24:42,338:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AE917B4430>)
2024-09-06 00:24:42,338:INFO:Checking exceptions
2024-09-06 00:24:42,338:INFO:Preloading libraries
2024-09-06 00:24:42,340:INFO:Set up data.
2024-09-06 00:24:42,605:INFO:Set up index.
2024-09-06 00:26:05,102:INFO:Initializing finalize_model()
2024-09-06 00:26:05,102:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 00:26:05,103:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 00:26:05,699:INFO:Initializing create_model()
2024-09-06 00:26:05,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:26:05,699:INFO:Checking exceptions
2024-09-06 00:26:05,699:INFO:Importing libraries
2024-09-06 00:26:05,699:INFO:Copying training dataset
2024-09-06 00:26:05,793:INFO:Defining folds
2024-09-06 00:26:05,793:INFO:Declaring metric variables
2024-09-06 00:26:05,793:INFO:Importing untrained model
2024-09-06 00:26:05,793:INFO:Declaring custom model
2024-09-06 00:26:05,793:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:26:05,793:INFO:Cross validation set to False
2024-09-06 00:26:05,793:INFO:Fitting Model
2024-09-06 00:26:14,203:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222457 seconds.
2024-09-06 00:26:14,203:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 00:26:14,216:INFO:[LightGBM] [Info] Total Bins 130277
2024-09-06 00:26:14,224:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 534
2024-09-06 00:26:14,225:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:26:14,225:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:26:14,225:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:26:30,218:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:26:30,218:INFO:create_model() successfully completed......................................
2024-09-06 00:26:30,378:INFO:_master_model_container: 16
2024-09-06 00:26:30,378:INFO:_display_container: 5
2024-09-06 00:26:30,392:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:26:30,392:INFO:finalize_model() successfully completed......................................
2024-09-06 00:26:30,526:INFO:Initializing predict_model()
2024-09-06 00:26:30,526:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AE917B4430>)
2024-09-06 00:26:30,526:INFO:Checking exceptions
2024-09-06 00:26:30,526:INFO:Preloading libraries
2024-09-06 00:27:41,060:INFO:Initializing predict_model()
2024-09-06 00:27:41,060:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEE9E93760>)
2024-09-06 00:27:41,061:INFO:Checking exceptions
2024-09-06 00:27:41,061:INFO:Preloading libraries
2024-09-06 00:27:43,015:INFO:Initializing get_config()
2024-09-06 00:27:43,015:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 00:27:43,015:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 00:27:43,297:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 00:27:43,297:INFO:get_config() successfully completed......................................
2024-09-06 00:27:43,297:INFO:Initializing predict_model()
2024-09-06 00:27:43,297:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AE917B4430>)
2024-09-06 00:27:43,297:INFO:Checking exceptions
2024-09-06 00:27:43,297:INFO:Preloading libraries
2024-09-06 00:27:43,297:INFO:Set up data.
2024-09-06 00:27:43,540:INFO:Set up index.
2024-09-06 00:27:53,570:INFO:Initializing predict_model()
2024-09-06 00:27:53,570:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEE9E93520>)
2024-09-06 00:27:53,570:INFO:Checking exceptions
2024-09-06 00:27:53,570:INFO:Preloading libraries
2024-09-06 00:27:55,553:INFO:Initializing get_config()
2024-09-06 00:27:55,553:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 00:27:55,553:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 00:27:55,826:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 00:27:55,826:INFO:get_config() successfully completed......................................
2024-09-06 00:27:55,826:INFO:Initializing predict_model()
2024-09-06 00:27:55,826:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEDD6F4CA0>)
2024-09-06 00:27:55,826:INFO:Checking exceptions
2024-09-06 00:27:55,826:INFO:Preloading libraries
2024-09-06 00:27:55,826:INFO:Set up data.
2024-09-06 00:27:56,108:INFO:Set up index.
2024-09-06 00:29:37,228:INFO:Initializing predict_model()
2024-09-06 00:29:37,229:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEDD6F4F70>)
2024-09-06 00:29:37,229:INFO:Checking exceptions
2024-09-06 00:29:37,229:INFO:Preloading libraries
2024-09-06 00:29:39,174:INFO:Initializing get_config()
2024-09-06 00:29:39,174:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 00:29:39,174:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 00:29:39,441:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 00:29:39,441:INFO:get_config() successfully completed......................................
2024-09-06 00:29:39,457:INFO:Initializing predict_model()
2024-09-06 00:29:39,457:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEA41BF880>)
2024-09-06 00:29:39,457:INFO:Checking exceptions
2024-09-06 00:29:39,457:INFO:Preloading libraries
2024-09-06 00:29:39,457:INFO:Set up data.
2024-09-06 00:29:39,708:INFO:Set up index.
2024-09-06 00:33:21,690:INFO:Initializing predict_model()
2024-09-06 00:33:21,690:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEB44B7F0>)
2024-09-06 00:33:21,691:INFO:Checking exceptions
2024-09-06 00:33:21,691:INFO:Preloading libraries
2024-09-06 00:33:21,692:INFO:Set up data.
2024-09-06 00:33:21,736:INFO:Set up index.
2024-09-06 00:34:12,074:INFO:Initializing predict_model()
2024-09-06 00:34:12,074:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEB44BE20>)
2024-09-06 00:34:12,074:INFO:Checking exceptions
2024-09-06 00:34:12,075:INFO:Preloading libraries
2024-09-06 00:34:12,077:INFO:Set up data.
2024-09-06 00:34:12,581:INFO:Set up index.
2024-09-06 00:34:13,639:INFO:Initializing get_config()
2024-09-06 00:34:13,639:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 00:34:13,639:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 00:34:13,927:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 00:34:13,927:INFO:get_config() successfully completed......................................
2024-09-06 00:34:13,927:INFO:Initializing predict_model()
2024-09-06 00:34:13,927:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEA5067A0>)
2024-09-06 00:34:13,927:INFO:Checking exceptions
2024-09-06 00:34:13,927:INFO:Preloading libraries
2024-09-06 00:34:13,927:INFO:Set up data.
2024-09-06 00:34:14,221:INFO:Set up index.
2024-09-06 00:34:15,124:INFO:Initializing get_config()
2024-09-06 00:34:15,124:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_train)
2024-09-06 00:34:15,124:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 00:34:15,367:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 00:34:15,367:INFO:get_config() successfully completed......................................
2024-09-06 00:34:15,367:INFO:Initializing get_config()
2024-09-06 00:34:15,367:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_test)
2024-09-06 00:34:15,367:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 00:34:15,523:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 00:34:15,523:INFO:get_config() successfully completed......................................
2024-09-06 00:35:43,068:INFO:Initializing predict_model()
2024-09-06 00:35:43,068:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEBD18C10>)
2024-09-06 00:35:43,069:INFO:Checking exceptions
2024-09-06 00:35:43,069:INFO:Preloading libraries
2024-09-06 00:35:43,071:INFO:Set up data.
2024-09-06 00:35:43,315:INFO:Set up index.
2024-09-06 00:35:43,924:INFO:Initializing get_config()
2024-09-06 00:35:43,924:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 00:35:43,924:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 00:35:44,184:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 00:35:44,184:INFO:get_config() successfully completed......................................
2024-09-06 00:35:44,200:INFO:Initializing predict_model()
2024-09-06 00:35:44,200:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEA5067A0>)
2024-09-06 00:35:44,200:INFO:Checking exceptions
2024-09-06 00:35:44,200:INFO:Preloading libraries
2024-09-06 00:35:44,202:INFO:Set up data.
2024-09-06 00:35:44,455:INFO:Set up index.
2024-09-06 00:35:45,350:INFO:Initializing get_config()
2024-09-06 00:35:45,350:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_train)
2024-09-06 00:35:45,350:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 00:35:45,528:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 00:35:45,528:INFO:get_config() successfully completed......................................
2024-09-06 00:35:45,528:INFO:Initializing get_config()
2024-09-06 00:35:45,528:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_test)
2024-09-06 00:35:45,528:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 00:35:45,679:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 00:35:45,679:INFO:get_config() successfully completed......................................
2024-09-06 00:35:45,683:INFO:Initializing finalize_model()
2024-09-06 00:35:45,683:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 00:35:45,683:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 00:35:46,224:INFO:Initializing create_model()
2024-09-06 00:35:46,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:35:46,225:INFO:Checking exceptions
2024-09-06 00:35:46,225:INFO:Importing libraries
2024-09-06 00:35:46,225:INFO:Copying training dataset
2024-09-06 00:35:46,321:INFO:Defining folds
2024-09-06 00:35:46,321:INFO:Declaring metric variables
2024-09-06 00:35:46,321:INFO:Importing untrained model
2024-09-06 00:35:46,322:INFO:Declaring custom model
2024-09-06 00:35:46,322:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:35:46,326:INFO:Cross validation set to False
2024-09-06 00:35:46,326:INFO:Fitting Model
2024-09-06 00:35:54,753:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.250967 seconds.
2024-09-06 00:35:54,758:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 00:35:54,767:INFO:[LightGBM] [Info] Total Bins 130277
2024-09-06 00:35:54,776:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 534
2024-09-06 00:35:54,779:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:35:54,779:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:35:54,780:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:36:10,129:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:36:10,135:INFO:create_model() successfully completed......................................
2024-09-06 00:36:10,288:INFO:_master_model_container: 16
2024-09-06 00:36:10,288:INFO:_display_container: 11
2024-09-06 00:36:10,304:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:36:10,304:INFO:finalize_model() successfully completed......................................
2024-09-06 00:36:10,440:INFO:Initializing predict_model()
2024-09-06 00:36:10,440:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEA5067A0>)
2024-09-06 00:36:10,440:INFO:Checking exceptions
2024-09-06 00:36:10,440:INFO:Preloading libraries
2024-09-06 00:36:10,440:INFO:Set up data.
2024-09-06 00:36:10,469:INFO:Set up index.
2024-09-06 00:36:42,801:INFO:Initializing predict_model()
2024-09-06 00:36:42,802:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEDD6F4F70>)
2024-09-06 00:36:42,802:INFO:Checking exceptions
2024-09-06 00:36:42,802:INFO:Preloading libraries
2024-09-06 00:36:42,804:INFO:Set up data.
2024-09-06 00:36:43,066:INFO:Set up index.
2024-09-06 00:36:43,780:INFO:Initializing get_config()
2024-09-06 00:36:43,781:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 00:36:43,781:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 00:36:44,142:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 00:36:44,142:INFO:get_config() successfully completed......................................
2024-09-06 00:36:44,143:INFO:Initializing predict_model()
2024-09-06 00:36:44,143:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEA4243880>)
2024-09-06 00:36:44,143:INFO:Checking exceptions
2024-09-06 00:36:44,143:INFO:Preloading libraries
2024-09-06 00:36:44,145:INFO:Set up data.
2024-09-06 00:36:44,413:INFO:Set up index.
2024-09-06 00:36:45,327:INFO:Initializing get_config()
2024-09-06 00:36:45,327:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_train)
2024-09-06 00:36:45,327:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 00:36:45,521:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 00:36:45,521:INFO:get_config() successfully completed......................................
2024-09-06 00:36:45,521:INFO:Initializing get_config()
2024-09-06 00:36:45,521:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_test)
2024-09-06 00:36:45,521:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 00:36:45,664:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 00:36:45,664:INFO:get_config() successfully completed......................................
2024-09-06 00:36:45,669:INFO:Initializing finalize_model()
2024-09-06 00:36:45,669:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 00:36:45,669:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 00:36:46,194:INFO:Initializing create_model()
2024-09-06 00:36:46,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:36:46,194:INFO:Checking exceptions
2024-09-06 00:36:46,195:INFO:Importing libraries
2024-09-06 00:36:46,196:INFO:Copying training dataset
2024-09-06 00:36:46,279:INFO:Defining folds
2024-09-06 00:36:46,279:INFO:Declaring metric variables
2024-09-06 00:36:46,279:INFO:Importing untrained model
2024-09-06 00:36:46,279:INFO:Declaring custom model
2024-09-06 00:36:46,279:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:36:46,279:INFO:Cross validation set to False
2024-09-06 00:36:46,279:INFO:Fitting Model
2024-09-06 00:36:55,248:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.291430 seconds.
2024-09-06 00:36:55,248:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 00:36:55,248:INFO:[LightGBM] [Info] Total Bins 130277
2024-09-06 00:36:55,264:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 534
2024-09-06 00:36:55,264:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:36:55,264:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:36:55,264:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:37:10,149:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:37:10,150:INFO:create_model() successfully completed......................................
2024-09-06 00:37:10,314:INFO:_master_model_container: 16
2024-09-06 00:37:10,314:INFO:_display_container: 12
2024-09-06 00:37:10,325:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 00:37:10,325:INFO:finalize_model() successfully completed......................................
2024-09-06 00:37:10,464:INFO:Initializing predict_model()
2024-09-06 00:37:10,464:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEA4243880>)
2024-09-06 00:37:10,464:INFO:Checking exceptions
2024-09-06 00:37:10,464:INFO:Preloading libraries
2024-09-06 00:37:10,466:INFO:Set up data.
2024-09-06 00:37:10,713:INFO:Set up index.
2024-09-06 00:43:16,175:INFO:Initializing create_model()
2024-09-06 00:43:16,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:43:16,177:INFO:Checking exceptions
2024-09-06 00:43:16,192:INFO:Importing libraries
2024-09-06 00:43:16,193:INFO:Copying training dataset
2024-09-06 00:43:16,981:INFO:Defining folds
2024-09-06 00:43:16,981:INFO:Declaring metric variables
2024-09-06 00:43:16,983:INFO:Importing untrained model
2024-09-06 00:43:16,983:INFO:Declaring custom model
2024-09-06 00:43:16,983:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:43:16,994:INFO:Starting cross validation
2024-09-06 00:43:16,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 00:46:20,827:INFO:Calculating mean and std
2024-09-06 00:46:20,827:INFO:Creating metrics dataframe
2024-09-06 00:46:20,843:INFO:Finalizing model
2024-09-06 00:46:27,423:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.262021 seconds.
2024-09-06 00:46:27,423:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 00:46:27,437:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-06 00:46:27,444:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-06 00:46:27,448:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:46:27,448:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:46:27,450:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:46:39,412:INFO:Uploading results into container
2024-09-06 00:46:39,415:INFO:Uploading model into container now
2024-09-06 00:46:39,430:INFO:_master_model_container: 17
2024-09-06 00:46:39,430:INFO:_display_container: 14
2024-09-06 00:46:39,431:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 00:46:39,431:INFO:create_model() successfully completed......................................
2024-09-06 00:46:39,626:INFO:Initializing tune_model()
2024-09-06 00:46:39,626:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 150], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.05, 0.1], 'min_child_samples': [20, 50, 100], 'subsample': [0.6, 0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>)
2024-09-06 00:46:39,626:INFO:Checking exceptions
2024-09-06 00:46:39,626:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-06 00:46:40,097:INFO:Copying training dataset
2024-09-06 00:46:40,573:INFO:Checking base model
2024-09-06 00:46:40,573:INFO:Base model : Light Gradient Boosting Machine
2024-09-06 00:46:40,577:INFO:Declaring metric variables
2024-09-06 00:46:40,580:INFO:Defining Hyperparameters
2024-09-06 00:46:40,707:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 150]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__learning_rate': CategoricalDistribution(values=[0.01, 0.05, 0.1]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[20, 50, 100]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.6, 0.8, 1.0]), 'actual_estimator__reg_alpha': CategoricalDistribution(values=[0, 0.1, 0.5]), 'actual_estimator__reg_lambda': CategoricalDistribution(values=[0, 0.1, 0.5])}
2024-09-06 00:46:40,708:INFO:Tuning with n_jobs=-1
2024-09-06 00:46:40,712:INFO:Initializing skopt.BayesSearchCV
2024-09-06 00:58:15,204:INFO:best_params: OrderedDict([('actual_estimator__learning_rate', 0.1), ('actual_estimator__max_depth', 5), ('actual_estimator__min_child_samples', 20), ('actual_estimator__n_estimators', 100), ('actual_estimator__reg_alpha', 0.1), ('actual_estimator__reg_lambda', 0), ('actual_estimator__subsample', 0.8)])
2024-09-06 00:58:15,205:INFO:Hyperparameter search completed
2024-09-06 00:58:15,206:INFO:SubProcess create_model() called ==================================
2024-09-06 00:58:15,207:INFO:Initializing create_model()
2024-09-06 00:58:15,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEE3508850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.1, 'max_depth': 5, 'min_child_samples': 20, 'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0, 'subsample': 0.8})
2024-09-06 00:58:15,207:INFO:Checking exceptions
2024-09-06 00:58:15,207:INFO:Importing libraries
2024-09-06 00:58:15,207:INFO:Copying training dataset
2024-09-06 00:58:16,099:INFO:Defining folds
2024-09-06 00:58:16,099:INFO:Declaring metric variables
2024-09-06 00:58:16,104:INFO:Importing untrained model
2024-09-06 00:58:16,104:INFO:Declaring custom model
2024-09-06 00:58:16,108:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:58:16,115:INFO:Starting cross validation
2024-09-06 00:58:16,118:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 00:59:06,064:INFO:Calculating mean and std
2024-09-06 00:59:06,066:INFO:Creating metrics dataframe
2024-09-06 00:59:06,074:INFO:Finalizing model
2024-09-06 00:59:11,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169048 seconds.
2024-09-06 00:59:11,773:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 00:59:11,782:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-06 00:59:11,786:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-06 00:59:11,789:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:59:11,790:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:59:11,790:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 00:59:11,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:11,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:12,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:13,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:15,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:17,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:18,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 00:59:19,503:INFO:Uploading results into container
2024-09-06 00:59:19,504:INFO:Uploading model into container now
2024-09-06 00:59:19,505:INFO:_master_model_container: 18
2024-09-06 00:59:19,505:INFO:_display_container: 15
2024-09-06 00:59:19,506:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 00:59:19,506:INFO:create_model() successfully completed......................................
2024-09-06 00:59:19,708:INFO:SubProcess create_model() end ==================================
2024-09-06 00:59:19,708:INFO:choose_better activated
2024-09-06 00:59:19,712:INFO:SubProcess create_model() called ==================================
2024-09-06 00:59:19,712:INFO:Initializing create_model()
2024-09-06 00:59:19,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 00:59:19,713:INFO:Checking exceptions
2024-09-06 00:59:19,714:INFO:Importing libraries
2024-09-06 00:59:19,714:INFO:Copying training dataset
2024-09-06 00:59:20,557:INFO:Defining folds
2024-09-06 00:59:20,558:INFO:Declaring metric variables
2024-09-06 00:59:20,558:INFO:Importing untrained model
2024-09-06 00:59:20,558:INFO:Declaring custom model
2024-09-06 00:59:20,559:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 00:59:20,559:INFO:Starting cross validation
2024-09-06 00:59:20,562:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 01:00:45,526:INFO:Calculating mean and std
2024-09-06 01:00:45,527:INFO:Creating metrics dataframe
2024-09-06 01:00:45,529:INFO:Finalizing model
2024-09-06 01:00:50,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.166355 seconds.
2024-09-06 01:00:50,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 01:00:50,883:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-06 01:00:50,887:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-06 01:00:50,890:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 01:00:50,890:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 01:00:50,890:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 01:01:01,913:INFO:Uploading results into container
2024-09-06 01:01:01,914:INFO:Uploading model into container now
2024-09-06 01:01:01,914:INFO:_master_model_container: 19
2024-09-06 01:01:01,915:INFO:_display_container: 16
2024-09-06 01:01:01,915:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 01:01:01,915:INFO:create_model() successfully completed......................................
2024-09-06 01:01:02,072:INFO:SubProcess create_model() end ==================================
2024-09-06 01:01:02,073:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8294
2024-09-06 01:01:02,073:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8284
2024-09-06 01:01:02,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-06 01:01:02,074:INFO:choose_better completed
2024-09-06 01:01:02,074:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-06 01:01:02,083:INFO:_master_model_container: 19
2024-09-06 01:01:02,083:INFO:_display_container: 15
2024-09-06 01:01:02,083:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 01:01:02,084:INFO:tune_model() successfully completed......................................
2024-09-06 01:01:02,272:INFO:Initializing predict_model()
2024-09-06 01:01:02,272:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AED7D430A0>)
2024-09-06 01:01:02,273:INFO:Checking exceptions
2024-09-06 01:01:02,273:INFO:Preloading libraries
2024-09-06 01:01:02,276:INFO:Set up data.
2024-09-06 01:01:02,615:INFO:Set up index.
2024-09-06 01:01:03,259:INFO:Initializing get_config()
2024-09-06 01:01:03,259:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 01:01:03,260:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 01:01:03,583:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 01:01:03,583:INFO:get_config() successfully completed......................................
2024-09-06 01:01:03,583:INFO:Initializing predict_model()
2024-09-06 01:01:03,584:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEBD1BF40>)
2024-09-06 01:01:03,584:INFO:Checking exceptions
2024-09-06 01:01:03,584:INFO:Preloading libraries
2024-09-06 01:01:03,586:INFO:Set up data.
2024-09-06 01:01:03,839:INFO:Set up index.
2024-09-06 01:01:04,788:INFO:Initializing get_config()
2024-09-06 01:01:04,788:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_train)
2024-09-06 01:01:04,789:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 01:01:05,053:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 01:01:05,053:INFO:get_config() successfully completed......................................
2024-09-06 01:01:05,053:INFO:Initializing get_config()
2024-09-06 01:01:05,053:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_test)
2024-09-06 01:01:05,053:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 01:01:05,207:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 01:01:05,207:INFO:get_config() successfully completed......................................
2024-09-06 01:01:05,212:INFO:Initializing finalize_model()
2024-09-06 01:01:05,212:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 01:01:05,212:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 01:01:05,809:INFO:Initializing create_model()
2024-09-06 01:01:05,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 01:01:05,810:INFO:Checking exceptions
2024-09-06 01:01:05,811:INFO:Importing libraries
2024-09-06 01:01:05,811:INFO:Copying training dataset
2024-09-06 01:01:05,908:INFO:Defining folds
2024-09-06 01:01:05,908:INFO:Declaring metric variables
2024-09-06 01:01:05,908:INFO:Importing untrained model
2024-09-06 01:01:05,908:INFO:Declaring custom model
2024-09-06 01:01:05,909:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 01:01:05,912:INFO:Cross validation set to False
2024-09-06 01:01:05,912:INFO:Fitting Model
2024-09-06 01:01:14,859:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.278070 seconds.
2024-09-06 01:01:14,859:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 01:01:14,875:INFO:[LightGBM] [Info] Total Bins 130277
2024-09-06 01:01:14,880:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 534
2024-09-06 01:01:14,883:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 01:01:14,884:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 01:01:14,884:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 01:01:30,027:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 01:01:30,027:INFO:create_model() successfully completed......................................
2024-09-06 01:01:30,176:INFO:_master_model_container: 19
2024-09-06 01:01:30,176:INFO:_display_container: 16
2024-09-06 01:01:30,187:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 01:01:30,187:INFO:finalize_model() successfully completed......................................
2024-09-06 01:01:30,323:INFO:Initializing predict_model()
2024-09-06 01:01:30,323:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AED7D40160>)
2024-09-06 01:01:30,323:INFO:Checking exceptions
2024-09-06 01:01:30,323:INFO:Preloading libraries
2024-09-06 01:01:30,325:INFO:Set up data.
2024-09-06 01:01:30,568:INFO:Set up index.
2024-09-06 01:01:31,236:INFO:Initializing create_model()
2024-09-06 01:01:31,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 01:01:31,237:INFO:Checking exceptions
2024-09-06 01:01:31,252:INFO:Importing libraries
2024-09-06 01:01:31,252:INFO:Copying training dataset
2024-09-06 01:01:32,162:INFO:Defining folds
2024-09-06 01:01:32,162:INFO:Declaring metric variables
2024-09-06 01:01:32,165:INFO:Importing untrained model
2024-09-06 01:01:32,166:INFO:Declaring custom model
2024-09-06 01:01:32,171:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 01:01:32,178:INFO:Starting cross validation
2024-09-06 01:01:32,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 01:03:19,614:INFO:Calculating mean and std
2024-09-06 01:03:19,615:INFO:Creating metrics dataframe
2024-09-06 01:03:19,621:INFO:Finalizing model
2024-09-06 01:03:37,787:INFO:Uploading results into container
2024-09-06 01:03:37,788:INFO:Uploading model into container now
2024-09-06 01:03:37,802:INFO:_master_model_container: 20
2024-09-06 01:03:37,802:INFO:_display_container: 18
2024-09-06 01:03:37,804:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-06 01:03:37,804:INFO:create_model() successfully completed......................................
2024-09-06 01:03:37,963:INFO:Initializing tune_model()
2024-09-06 01:03:37,964:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 150], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.05, 0.1], 'subsample': [0.6, 0.8, 1.0], 'colsample_bytree': [0.6, 0.8, 1.0], 'gamma': [0, 0.1, 0.5], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>)
2024-09-06 01:03:37,964:INFO:Checking exceptions
2024-09-06 01:03:37,964:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-06 01:03:38,296:INFO:Copying training dataset
2024-09-06 01:03:38,854:INFO:Checking base model
2024-09-06 01:03:38,854:INFO:Base model : Extreme Gradient Boosting
2024-09-06 01:03:38,854:INFO:Declaring metric variables
2024-09-06 01:03:38,865:INFO:Defining Hyperparameters
2024-09-06 01:03:38,980:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 150]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__learning_rate': CategoricalDistribution(values=[0.01, 0.05, 0.1]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.6, 0.8, 1.0]), 'actual_estimator__colsample_bytree': CategoricalDistribution(values=[0.6, 0.8, 1.0]), 'actual_estimator__gamma': CategoricalDistribution(values=[0, 0.1, 0.5]), 'actual_estimator__reg_alpha': CategoricalDistribution(values=[0, 0.1, 0.5]), 'actual_estimator__reg_lambda': CategoricalDistribution(values=[0, 0.1, 0.5])}
2024-09-06 01:03:38,980:INFO:Tuning with n_jobs=-1
2024-09-06 01:03:38,996:INFO:Initializing skopt.BayesSearchCV
2024-09-06 01:18:13,445:INFO:best_params: OrderedDict([('actual_estimator__colsample_bytree', 0.6), ('actual_estimator__gamma', 0.5), ('actual_estimator__learning_rate', 0.05), ('actual_estimator__max_depth', 7), ('actual_estimator__n_estimators', 150), ('actual_estimator__reg_alpha', 0), ('actual_estimator__reg_lambda', 0), ('actual_estimator__subsample', 0.8)])
2024-09-06 01:18:13,447:INFO:Hyperparameter search completed
2024-09-06 01:18:13,447:INFO:SubProcess create_model() called ==================================
2024-09-06 01:18:13,448:INFO:Initializing create_model()
2024-09-06 01:18:13,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEEBD80B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'colsample_bytree': 0.6, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 150, 'reg_alpha': 0, 'reg_lambda': 0, 'subsample': 0.8})
2024-09-06 01:18:13,448:INFO:Checking exceptions
2024-09-06 01:18:13,448:INFO:Importing libraries
2024-09-06 01:18:13,448:INFO:Copying training dataset
2024-09-06 01:18:14,441:INFO:Defining folds
2024-09-06 01:18:14,441:INFO:Declaring metric variables
2024-09-06 01:18:14,447:INFO:Importing untrained model
2024-09-06 01:18:14,447:INFO:Declaring custom model
2024-09-06 01:18:14,453:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 01:18:14,461:INFO:Starting cross validation
2024-09-06 01:18:14,466:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 01:20:26,882:INFO:Calculating mean and std
2024-09-06 01:20:26,884:INFO:Creating metrics dataframe
2024-09-06 01:20:26,893:INFO:Finalizing model
2024-09-06 01:21:02,297:INFO:Uploading results into container
2024-09-06 01:21:02,298:INFO:Uploading model into container now
2024-09-06 01:21:02,301:INFO:_master_model_container: 21
2024-09-06 01:21:02,301:INFO:_display_container: 19
2024-09-06 01:21:02,302:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.5, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-06 01:21:02,302:INFO:create_model() successfully completed......................................
2024-09-06 01:21:02,744:INFO:SubProcess create_model() end ==================================
2024-09-06 01:21:02,744:INFO:choose_better activated
2024-09-06 01:21:02,748:INFO:SubProcess create_model() called ==================================
2024-09-06 01:21:02,749:INFO:Initializing create_model()
2024-09-06 01:21:02,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 01:21:02,749:INFO:Checking exceptions
2024-09-06 01:21:02,751:INFO:Importing libraries
2024-09-06 01:21:02,751:INFO:Copying training dataset
2024-09-06 01:21:03,604:INFO:Defining folds
2024-09-06 01:21:03,604:INFO:Declaring metric variables
2024-09-06 01:21:03,604:INFO:Importing untrained model
2024-09-06 01:21:03,604:INFO:Declaring custom model
2024-09-06 01:21:03,606:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 01:21:03,606:INFO:Starting cross validation
2024-09-06 01:21:03,609:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 01:22:16,794:INFO:Calculating mean and std
2024-09-06 01:22:16,794:INFO:Creating metrics dataframe
2024-09-06 01:22:16,796:INFO:Finalizing model
2024-09-06 01:22:35,213:INFO:Uploading results into container
2024-09-06 01:22:35,214:INFO:Uploading model into container now
2024-09-06 01:22:35,215:INFO:_master_model_container: 22
2024-09-06 01:22:35,215:INFO:_display_container: 20
2024-09-06 01:22:35,216:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-06 01:22:35,216:INFO:create_model() successfully completed......................................
2024-09-06 01:22:35,426:INFO:SubProcess create_model() end ==================================
2024-09-06 01:22:35,427:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...) result for Accuracy is 0.8255
2024-09-06 01:22:35,428:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.5, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...) result for Accuracy is 0.8288
2024-09-06 01:22:35,429:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.5, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...) is best model
2024-09-06 01:22:35,429:INFO:choose_better completed
2024-09-06 01:22:35,439:INFO:_master_model_container: 22
2024-09-06 01:22:35,439:INFO:_display_container: 19
2024-09-06 01:22:35,440:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.5, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-06 01:22:35,440:INFO:tune_model() successfully completed......................................
2024-09-06 01:22:35,614:INFO:Initializing predict_model()
2024-09-06 01:22:35,614:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.5, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEBDCEE60>)
2024-09-06 01:22:35,614:INFO:Checking exceptions
2024-09-06 01:22:35,615:INFO:Preloading libraries
2024-09-06 01:22:35,618:INFO:Set up data.
2024-09-06 01:22:35,952:INFO:Set up index.
2024-09-06 01:22:36,858:INFO:Initializing get_config()
2024-09-06 01:22:36,859:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 01:22:36,859:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 01:22:37,185:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 01:22:37,185:INFO:get_config() successfully completed......................................
2024-09-06 01:22:37,186:INFO:Initializing predict_model()
2024-09-06 01:22:37,186:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.5, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEBDCEE60>)
2024-09-06 01:22:37,186:INFO:Checking exceptions
2024-09-06 01:22:37,186:INFO:Preloading libraries
2024-09-06 01:22:37,188:INFO:Set up data.
2024-09-06 01:22:37,440:INFO:Set up index.
2024-09-06 01:22:38,533:INFO:Initializing get_config()
2024-09-06 01:22:38,533:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_train)
2024-09-06 01:22:38,534:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 01:22:38,730:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 01:22:38,730:INFO:get_config() successfully completed......................................
2024-09-06 01:22:38,730:INFO:Initializing get_config()
2024-09-06 01:22:38,730:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_test)
2024-09-06 01:22:38,731:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 01:22:38,875:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 01:22:38,875:INFO:get_config() successfully completed......................................
2024-09-06 01:22:38,880:INFO:Initializing finalize_model()
2024-09-06 01:22:38,880:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.5, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 01:22:38,881:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.5, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-06 01:22:39,433:INFO:Initializing create_model()
2024-09-06 01:22:39,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.5, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 01:22:39,433:INFO:Checking exceptions
2024-09-06 01:22:39,435:INFO:Importing libraries
2024-09-06 01:22:39,435:INFO:Copying training dataset
2024-09-06 01:22:39,531:INFO:Defining folds
2024-09-06 01:22:39,531:INFO:Declaring metric variables
2024-09-06 01:22:39,531:INFO:Importing untrained model
2024-09-06 01:22:39,532:INFO:Declaring custom model
2024-09-06 01:22:39,533:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 01:22:39,536:INFO:Cross validation set to False
2024-09-06 01:22:39,536:INFO:Fitting Model
2024-09-06 01:23:21,474:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.05,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=7, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=150, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='multi:softprob', ...))],
         verbose=False)
2024-09-06 01:23:21,474:INFO:create_model() successfully completed......................................
2024-09-06 01:23:21,678:INFO:_master_model_container: 22
2024-09-06 01:23:21,678:INFO:_display_container: 20
2024-09-06 01:23:21,690:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.05,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=7, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=150, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='multi:softprob', ...))],
         verbose=False)
2024-09-06 01:23:21,690:INFO:finalize_model() successfully completed......................................
2024-09-06 01:23:21,841:INFO:Initializing predict_model()
2024-09-06 01:23:21,841:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.05,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=7, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=150, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='multi:softprob', ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEBDCEE60>)
2024-09-06 01:23:21,841:INFO:Checking exceptions
2024-09-06 01:23:21,841:INFO:Preloading libraries
2024-09-06 01:23:21,844:INFO:Set up data.
2024-09-06 01:23:22,141:INFO:Set up index.
2024-09-06 01:23:23,035:INFO:Initializing create_model()
2024-09-06 01:23:23,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 01:23:23,036:INFO:Checking exceptions
2024-09-06 01:23:23,051:INFO:Importing libraries
2024-09-06 01:23:23,051:INFO:Copying training dataset
2024-09-06 01:23:23,853:INFO:Defining folds
2024-09-06 01:23:23,853:INFO:Declaring metric variables
2024-09-06 01:23:23,856:INFO:Importing untrained model
2024-09-06 01:23:23,857:INFO:Declaring custom model
2024-09-06 01:23:23,860:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 01:23:23,868:INFO:Starting cross validation
2024-09-06 01:23:23,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 01:47:07,387:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:08,903:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:09,059:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:09,653:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:11,451:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:12,920:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:13,311:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:13,420:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:19,998:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:21,404:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 01:47:21,498:INFO:Calculating mean and std
2024-09-06 01:47:21,514:INFO:Creating metrics dataframe
2024-09-06 01:47:21,561:INFO:Finalizing model
2024-09-06 02:07:42,911:INFO:Uploading results into container
2024-09-06 02:07:42,911:INFO:Uploading model into container now
2024-09-06 02:07:42,926:INFO:_master_model_container: 23
2024-09-06 02:07:42,926:INFO:_display_container: 22
2024-09-06 02:07:42,926:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 02:07:42,926:INFO:create_model() successfully completed......................................
2024-09-06 02:07:43,270:INFO:Initializing tune_model()
2024-09-06 02:07:43,270:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 150], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.05, 0.1], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'subsample': [0.6, 0.8, 1.0], 'max_features': ['auto', 'sqrt', 'log2']}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>)
2024-09-06 02:07:43,270:INFO:Checking exceptions
2024-09-06 02:07:43,270:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-06 02:07:43,817:INFO:Copying training dataset
2024-09-06 02:07:44,317:INFO:Checking base model
2024-09-06 02:07:44,317:INFO:Base model : Gradient Boosting Classifier
2024-09-06 02:07:44,317:INFO:Declaring metric variables
2024-09-06 02:07:44,317:INFO:Defining Hyperparameters
2024-09-06 02:07:44,442:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 150]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__learning_rate': CategoricalDistribution(values=[0.01, 0.05, 0.1]), 'actual_estimator__min_samples_split': CategoricalDistribution(values=[2, 5, 10]), 'actual_estimator__min_samples_leaf': CategoricalDistribution(values=[1, 2, 4]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.6, 0.8, 1.0]), 'actual_estimator__max_features': CategoricalDistribution(values=['auto', 'sqrt', 'log2'])}
2024-09-06 02:07:44,442:INFO:Tuning with n_jobs=-1
2024-09-06 02:07:44,442:INFO:Initializing skopt.BayesSearchCV
2024-09-06 10:47:44,467:INFO:Initializing plot_model()
2024-09-06 10:47:44,469:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, system=True)
2024-09-06 10:47:44,469:INFO:Checking exceptions
2024-09-06 10:47:45,270:INFO:Preloading libraries
2024-09-06 10:47:45,296:INFO:Copying training dataset
2024-09-06 10:47:45,296:INFO:Plot type: confusion_matrix
2024-09-06 10:47:48,041:INFO:Fitting Model
2024-09-06 10:47:48,044:INFO:Scoring test/hold-out set
2024-09-06 10:47:48,869:INFO:Visual Rendered Successfully
2024-09-06 10:47:49,287:INFO:plot_model() successfully completed......................................
2024-09-06 10:48:19,616:INFO:Initializing evaluate_model()
2024-09-06 10:48:19,616:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-09-06 10:48:19,915:INFO:Initializing plot_model()
2024-09-06 10:48:19,915:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, system=True)
2024-09-06 10:48:19,915:INFO:Checking exceptions
2024-09-06 10:48:20,198:INFO:Preloading libraries
2024-09-06 10:48:20,222:INFO:Copying training dataset
2024-09-06 10:48:20,222:INFO:Plot type: pipeline
2024-09-06 10:48:20,361:INFO:Visual Rendered Successfully
2024-09-06 10:48:20,489:INFO:plot_model() successfully completed......................................
2024-09-06 10:48:22,960:INFO:Initializing plot_model()
2024-09-06 10:48:22,960:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, system=True)
2024-09-06 10:48:22,960:INFO:Checking exceptions
2024-09-06 10:48:23,211:INFO:Preloading libraries
2024-09-06 10:48:23,242:INFO:Copying training dataset
2024-09-06 10:48:23,242:INFO:Plot type: parameter
2024-09-06 10:48:23,242:INFO:Visual Rendered Successfully
2024-09-06 10:48:23,384:INFO:plot_model() successfully completed......................................
2024-09-06 10:48:24,798:INFO:Initializing plot_model()
2024-09-06 10:48:24,798:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, system=True)
2024-09-06 10:48:24,798:INFO:Checking exceptions
2024-09-06 10:48:25,067:INFO:Preloading libraries
2024-09-06 10:48:25,089:INFO:Copying training dataset
2024-09-06 10:48:25,089:INFO:Plot type: auc
2024-09-06 10:48:27,617:INFO:Fitting Model
2024-09-06 10:48:27,617:INFO:Scoring test/hold-out set
2024-09-06 10:48:28,433:INFO:Visual Rendered Successfully
2024-09-06 10:48:28,577:INFO:plot_model() successfully completed......................................
2024-09-06 10:48:33,846:INFO:Initializing plot_model()
2024-09-06 10:48:33,846:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, system=True)
2024-09-06 10:48:33,846:INFO:Checking exceptions
2024-09-06 10:48:34,110:INFO:Preloading libraries
2024-09-06 10:48:34,132:INFO:Copying training dataset
2024-09-06 10:48:34,132:INFO:Plot type: error
2024-09-06 10:48:36,705:INFO:Fitting Model
2024-09-06 10:48:36,720:INFO:Scoring test/hold-out set
2024-09-06 10:48:37,510:INFO:Visual Rendered Successfully
2024-09-06 10:48:37,663:INFO:plot_model() successfully completed......................................
2024-09-06 10:49:39,683:INFO:Initializing predict_model()
2024-09-06 10:49:39,683:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEECA7DC60>)
2024-09-06 10:49:39,683:INFO:Checking exceptions
2024-09-06 10:49:39,684:INFO:Preloading libraries
2024-09-06 10:49:39,686:INFO:Set up data.
2024-09-06 10:49:40,001:INFO:Set up index.
2024-09-06 10:49:41,062:INFO:Initializing get_config()
2024-09-06 10:49:41,062:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=X_train)
2024-09-06 10:49:41,062:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 10:49:41,335:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-06 10:49:41,335:INFO:get_config() successfully completed......................................
2024-09-06 10:49:41,335:INFO:Initializing predict_model()
2024-09-06 10:49:41,335:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEECA7DC60>)
2024-09-06 10:49:41,335:INFO:Checking exceptions
2024-09-06 10:49:41,335:INFO:Preloading libraries
2024-09-06 10:49:41,335:INFO:Set up data.
2024-09-06 10:49:41,600:INFO:Set up index.
2024-09-06 10:49:43,593:INFO:Initializing get_config()
2024-09-06 10:49:43,593:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_train)
2024-09-06 10:49:43,593:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 10:49:43,795:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 10:49:43,795:INFO:get_config() successfully completed......................................
2024-09-06 10:49:43,795:INFO:Initializing get_config()
2024-09-06 10:49:43,795:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AED82039D0>, variable=y_test)
2024-09-06 10:49:43,795:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 10:49:43,935:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 10:49:43,935:INFO:get_config() successfully completed......................................
2024-09-06 11:15:01,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 11:15:01,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 11:15:01,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 11:15:01,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 11:15:37,288:INFO:PyCaret ClassificationExperiment
2024-09-06 11:15:37,288:INFO:Logging name: clf-default-name
2024-09-06 11:15:37,288:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-06 11:15:37,288:INFO:version 3.3.2
2024-09-06 11:15:37,288:INFO:Initializing setup()
2024-09-06 11:15:37,288:INFO:self.USI: 0b14
2024-09-06 11:15:37,288:INFO:self._variable_keys: {'X_test', 'X_train', 'pipeline', 'fold_shuffle_param', 'fold_groups_param', 'gpu_n_jobs_param', 'fix_imbalance', '_available_plots', 'n_jobs_param', 'exp_name_log', 'seed', 'logging_param', 'target_param', 'idx', '_ml_usecase', 'y_test', 'USI', 'y', 'data', 'html_param', 'fold_generator', 'X', 'gpu_param', 'log_plots_param', 'memory', 'exp_id', 'is_multiclass', 'y_train'}
2024-09-06 11:15:37,288:INFO:Checking environment
2024-09-06 11:15:37,288:INFO:python_version: 3.10.11
2024-09-06 11:15:37,288:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-06 11:15:37,288:INFO:machine: AMD64
2024-09-06 11:15:37,288:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-06 11:15:37,288:INFO:Memory: svmem(total=17128263680, available=6966464512, percent=59.3, used=10161799168, free=6966464512)
2024-09-06 11:15:37,288:INFO:Physical Core: 6
2024-09-06 11:15:37,288:INFO:Logical Core: 12
2024-09-06 11:15:37,289:INFO:Checking libraries
2024-09-06 11:15:37,289:INFO:System:
2024-09-06 11:15:37,289:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-06 11:15:37,289:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-06 11:15:37,289:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-06 11:15:37,289:INFO:PyCaret required dependencies:
2024-09-06 11:15:37,313:INFO:                 pip: 24.2
2024-09-06 11:15:37,313:INFO:          setuptools: 72.1.0
2024-09-06 11:15:37,313:INFO:             pycaret: 3.3.2
2024-09-06 11:15:37,313:INFO:             IPython: 8.27.0
2024-09-06 11:15:37,313:INFO:          ipywidgets: 8.1.5
2024-09-06 11:15:37,313:INFO:                tqdm: 4.66.5
2024-09-06 11:15:37,313:INFO:               numpy: 1.26.4
2024-09-06 11:15:37,313:INFO:              pandas: 2.2.2
2024-09-06 11:15:37,313:INFO:              jinja2: 3.1.4
2024-09-06 11:15:37,313:INFO:               scipy: 1.11.4
2024-09-06 11:15:37,313:INFO:              joblib: 1.3.2
2024-09-06 11:15:37,313:INFO:             sklearn: 1.4.2
2024-09-06 11:15:37,313:INFO:                pyod: 2.0.1
2024-09-06 11:15:37,313:INFO:            imblearn: 0.12.3
2024-09-06 11:15:37,314:INFO:   category_encoders: 2.6.3
2024-09-06 11:15:37,314:INFO:            lightgbm: 4.5.0
2024-09-06 11:15:37,314:INFO:               numba: 0.60.0
2024-09-06 11:15:37,314:INFO:            requests: 2.32.3
2024-09-06 11:15:37,314:INFO:          matplotlib: 3.7.5
2024-09-06 11:15:37,314:INFO:          scikitplot: 0.3.7
2024-09-06 11:15:37,314:INFO:         yellowbrick: 1.5
2024-09-06 11:15:37,314:INFO:              plotly: 5.24.0
2024-09-06 11:15:37,314:INFO:    plotly-resampler: Not installed
2024-09-06 11:15:37,314:INFO:             kaleido: 0.2.1
2024-09-06 11:15:37,314:INFO:           schemdraw: 0.15
2024-09-06 11:15:37,314:INFO:         statsmodels: 0.14.2
2024-09-06 11:15:37,314:INFO:              sktime: 0.26.0
2024-09-06 11:15:37,314:INFO:               tbats: 1.1.3
2024-09-06 11:15:37,314:INFO:            pmdarima: 2.0.4
2024-09-06 11:15:37,314:INFO:              psutil: 6.0.0
2024-09-06 11:15:37,314:INFO:          markupsafe: 2.1.5
2024-09-06 11:15:37,314:INFO:             pickle5: Not installed
2024-09-06 11:15:37,314:INFO:         cloudpickle: 3.0.0
2024-09-06 11:15:37,314:INFO:         deprecation: 2.1.0
2024-09-06 11:15:37,315:INFO:              xxhash: 3.5.0
2024-09-06 11:15:37,315:INFO:           wurlitzer: Not installed
2024-09-06 11:15:37,315:INFO:PyCaret optional dependencies:
2024-09-06 11:15:37,334:INFO:                shap: Not installed
2024-09-06 11:15:37,334:INFO:           interpret: Not installed
2024-09-06 11:15:37,334:INFO:                umap: Not installed
2024-09-06 11:15:37,334:INFO:     ydata_profiling: Not installed
2024-09-06 11:15:37,334:INFO:  explainerdashboard: Not installed
2024-09-06 11:15:37,334:INFO:             autoviz: Not installed
2024-09-06 11:15:37,334:INFO:           fairlearn: Not installed
2024-09-06 11:15:37,334:INFO:          deepchecks: Not installed
2024-09-06 11:15:37,334:INFO:             xgboost: 2.1.1
2024-09-06 11:15:37,335:INFO:            catboost: Not installed
2024-09-06 11:15:37,335:INFO:              kmodes: Not installed
2024-09-06 11:15:37,335:INFO:             mlxtend: Not installed
2024-09-06 11:15:37,335:INFO:       statsforecast: Not installed
2024-09-06 11:15:37,335:INFO:        tune_sklearn: Not installed
2024-09-06 11:15:37,335:INFO:                 ray: Not installed
2024-09-06 11:15:37,335:INFO:            hyperopt: 0.2.7
2024-09-06 11:15:37,335:INFO:              optuna: 4.0.0
2024-09-06 11:15:37,335:INFO:               skopt: 0.10.2
2024-09-06 11:15:37,335:INFO:              mlflow: Not installed
2024-09-06 11:15:37,335:INFO:              gradio: Not installed
2024-09-06 11:15:37,335:INFO:             fastapi: Not installed
2024-09-06 11:15:37,335:INFO:             uvicorn: Not installed
2024-09-06 11:15:37,335:INFO:              m2cgen: Not installed
2024-09-06 11:15:37,335:INFO:           evidently: Not installed
2024-09-06 11:15:37,335:INFO:               fugue: Not installed
2024-09-06 11:15:37,335:INFO:           streamlit: Not installed
2024-09-06 11:15:37,335:INFO:             prophet: Not installed
2024-09-06 11:15:37,335:INFO:None
2024-09-06 11:15:37,335:INFO:Set up data.
2024-09-06 11:15:37,873:INFO:Set up folding strategy.
2024-09-06 11:15:37,873:INFO:Set up train/test split.
2024-09-06 11:15:38,516:INFO:Set up index.
2024-09-06 11:15:38,539:INFO:Assigning column types.
2024-09-06 11:15:39,257:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-06 11:15:39,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 11:15:39,311:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 11:15:39,348:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 11:15:39,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 11:15:39,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 11:15:39,402:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 11:15:39,433:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 11:15:39,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 11:15:39,436:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-06 11:15:39,486:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 11:15:39,517:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 11:15:39,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 11:15:39,571:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 11:15:39,601:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 11:15:39,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 11:15:39,605:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-06 11:15:39,686:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 11:15:39,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 11:15:39,771:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 11:15:39,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 11:15:39,776:INFO:Preparing preprocessing pipeline...
2024-09-06 11:15:39,888:INFO:Set up simple imputation.
2024-09-06 11:15:39,888:INFO:Set up imbalanced handling.
2024-09-06 11:15:41,479:INFO:Finished creating preprocessing pipeline.
2024-09-06 11:15:41,489:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-06 11:15:41,489:INFO:Creating final display dataframe.
2024-09-06 11:15:50,882:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 474)
4        Transformed data shape      (99147, 474)
5   Transformed train set shape      (76191, 474)
6    Transformed test set shape      (22956, 474)
7              Numeric features               473
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              0b14
2024-09-06 11:15:50,970:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 11:15:50,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 11:15:51,055:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 11:15:51,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 11:15:51,058:INFO:setup() successfully completed in 13.78s...............
2024-09-06 11:15:51,070:INFO:Initializing compare_models()
2024-09-06 11:15:51,070:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-06 11:15:51,070:INFO:Checking exceptions
2024-09-06 11:15:51,610:INFO:Preparing display monitor
2024-09-06 11:15:51,634:INFO:Initializing Logistic Regression
2024-09-06 11:15:51,634:INFO:Total runtime is 0.0 minutes
2024-09-06 11:15:51,638:INFO:SubProcess create_model() called ==================================
2024-09-06 11:15:51,639:INFO:Initializing create_model()
2024-09-06 11:15:51,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:15:51,639:INFO:Checking exceptions
2024-09-06 11:15:51,639:INFO:Importing libraries
2024-09-06 11:15:51,639:INFO:Copying training dataset
2024-09-06 11:15:52,516:INFO:Defining folds
2024-09-06 11:15:52,516:INFO:Declaring metric variables
2024-09-06 11:15:52,520:INFO:Importing untrained model
2024-09-06 11:15:52,524:INFO:Logistic Regression Imported successfully
2024-09-06 11:15:52,532:INFO:Starting cross validation
2024-09-06 11:15:52,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:19:07,995:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:16,938:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:22,162:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:24,702:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:25,167:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:25,590:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:25,693:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:26,967:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:29,552:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:34,759:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:19:34,782:INFO:Calculating mean and std
2024-09-06 11:19:34,783:INFO:Creating metrics dataframe
2024-09-06 11:19:34,786:INFO:Uploading results into container
2024-09-06 11:19:34,786:INFO:Uploading model into container now
2024-09-06 11:19:34,787:INFO:_master_model_container: 1
2024-09-06 11:19:34,787:INFO:_display_container: 2
2024-09-06 11:19:34,788:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-06 11:19:34,788:INFO:create_model() successfully completed......................................
2024-09-06 11:19:34,873:INFO:SubProcess create_model() end ==================================
2024-09-06 11:19:34,873:INFO:Creating metrics dataframe
2024-09-06 11:19:34,880:INFO:Initializing K Neighbors Classifier
2024-09-06 11:19:34,880:INFO:Total runtime is 3.720756006240845 minutes
2024-09-06 11:19:34,883:INFO:SubProcess create_model() called ==================================
2024-09-06 11:19:34,883:INFO:Initializing create_model()
2024-09-06 11:19:34,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:19:34,884:INFO:Checking exceptions
2024-09-06 11:19:34,884:INFO:Importing libraries
2024-09-06 11:19:34,884:INFO:Copying training dataset
2024-09-06 11:19:35,665:INFO:Defining folds
2024-09-06 11:19:35,665:INFO:Declaring metric variables
2024-09-06 11:19:35,669:INFO:Importing untrained model
2024-09-06 11:19:35,673:INFO:K Neighbors Classifier Imported successfully
2024-09-06 11:19:35,682:INFO:Starting cross validation
2024-09-06 11:19:35,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:20:29,477:INFO:Calculating mean and std
2024-09-06 11:20:29,478:INFO:Creating metrics dataframe
2024-09-06 11:20:29,481:INFO:Uploading results into container
2024-09-06 11:20:29,482:INFO:Uploading model into container now
2024-09-06 11:20:29,482:INFO:_master_model_container: 2
2024-09-06 11:20:29,482:INFO:_display_container: 2
2024-09-06 11:20:29,483:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-06 11:20:29,483:INFO:create_model() successfully completed......................................
2024-09-06 11:20:29,561:INFO:SubProcess create_model() end ==================================
2024-09-06 11:20:29,562:INFO:Creating metrics dataframe
2024-09-06 11:20:29,570:INFO:Initializing Naive Bayes
2024-09-06 11:20:29,570:INFO:Total runtime is 4.63225801785787 minutes
2024-09-06 11:20:29,574:INFO:SubProcess create_model() called ==================================
2024-09-06 11:20:29,574:INFO:Initializing create_model()
2024-09-06 11:20:29,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:20:29,574:INFO:Checking exceptions
2024-09-06 11:20:29,574:INFO:Importing libraries
2024-09-06 11:20:29,574:INFO:Copying training dataset
2024-09-06 11:20:30,289:INFO:Defining folds
2024-09-06 11:20:30,289:INFO:Declaring metric variables
2024-09-06 11:20:30,293:INFO:Importing untrained model
2024-09-06 11:20:30,298:INFO:Naive Bayes Imported successfully
2024-09-06 11:20:30,305:INFO:Starting cross validation
2024-09-06 11:20:30,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:20:50,851:INFO:Calculating mean and std
2024-09-06 11:20:50,852:INFO:Creating metrics dataframe
2024-09-06 11:20:50,854:INFO:Uploading results into container
2024-09-06 11:20:50,856:INFO:Uploading model into container now
2024-09-06 11:20:50,856:INFO:_master_model_container: 3
2024-09-06 11:20:50,856:INFO:_display_container: 2
2024-09-06 11:20:50,857:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-06 11:20:50,857:INFO:create_model() successfully completed......................................
2024-09-06 11:20:50,937:INFO:SubProcess create_model() end ==================================
2024-09-06 11:20:50,938:INFO:Creating metrics dataframe
2024-09-06 11:20:50,945:INFO:Initializing Decision Tree Classifier
2024-09-06 11:20:50,945:INFO:Total runtime is 4.988506968816122 minutes
2024-09-06 11:20:50,948:INFO:SubProcess create_model() called ==================================
2024-09-06 11:20:50,948:INFO:Initializing create_model()
2024-09-06 11:20:50,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:20:50,948:INFO:Checking exceptions
2024-09-06 11:20:50,948:INFO:Importing libraries
2024-09-06 11:20:50,949:INFO:Copying training dataset
2024-09-06 11:20:51,670:INFO:Defining folds
2024-09-06 11:20:51,670:INFO:Declaring metric variables
2024-09-06 11:20:51,674:INFO:Importing untrained model
2024-09-06 11:20:51,678:INFO:Decision Tree Classifier Imported successfully
2024-09-06 11:20:51,686:INFO:Starting cross validation
2024-09-06 11:20:51,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:21:52,870:INFO:Calculating mean and std
2024-09-06 11:21:52,871:INFO:Creating metrics dataframe
2024-09-06 11:21:52,873:INFO:Uploading results into container
2024-09-06 11:21:52,874:INFO:Uploading model into container now
2024-09-06 11:21:52,874:INFO:_master_model_container: 4
2024-09-06 11:21:52,874:INFO:_display_container: 2
2024-09-06 11:21:52,874:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-06 11:21:52,875:INFO:create_model() successfully completed......................................
2024-09-06 11:21:52,950:INFO:SubProcess create_model() end ==================================
2024-09-06 11:21:52,951:INFO:Creating metrics dataframe
2024-09-06 11:21:52,958:INFO:Initializing SVM - Linear Kernel
2024-09-06 11:21:52,958:INFO:Total runtime is 6.02206860780716 minutes
2024-09-06 11:21:52,962:INFO:SubProcess create_model() called ==================================
2024-09-06 11:21:52,962:INFO:Initializing create_model()
2024-09-06 11:21:52,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:21:52,962:INFO:Checking exceptions
2024-09-06 11:21:52,963:INFO:Importing libraries
2024-09-06 11:21:52,963:INFO:Copying training dataset
2024-09-06 11:21:53,681:INFO:Defining folds
2024-09-06 11:21:53,681:INFO:Declaring metric variables
2024-09-06 11:21:53,685:INFO:Importing untrained model
2024-09-06 11:21:53,690:INFO:SVM - Linear Kernel Imported successfully
2024-09-06 11:21:53,700:INFO:Starting cross validation
2024-09-06 11:21:53,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:22:31,789:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:32,905:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:33,928:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:34,443:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:34,513:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:36,208:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:36,225:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:36,901:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:37,287:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:38,484:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:38,520:INFO:Calculating mean and std
2024-09-06 11:22:38,521:INFO:Creating metrics dataframe
2024-09-06 11:22:38,524:INFO:Uploading results into container
2024-09-06 11:22:38,525:INFO:Uploading model into container now
2024-09-06 11:22:38,526:INFO:_master_model_container: 5
2024-09-06 11:22:38,526:INFO:_display_container: 2
2024-09-06 11:22:38,527:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-06 11:22:38,527:INFO:create_model() successfully completed......................................
2024-09-06 11:22:38,605:INFO:SubProcess create_model() end ==================================
2024-09-06 11:22:38,605:INFO:Creating metrics dataframe
2024-09-06 11:22:38,614:INFO:Initializing Ridge Classifier
2024-09-06 11:22:38,614:INFO:Total runtime is 6.782991631825766 minutes
2024-09-06 11:22:38,617:INFO:SubProcess create_model() called ==================================
2024-09-06 11:22:38,617:INFO:Initializing create_model()
2024-09-06 11:22:38,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:22:38,618:INFO:Checking exceptions
2024-09-06 11:22:38,618:INFO:Importing libraries
2024-09-06 11:22:38,618:INFO:Copying training dataset
2024-09-06 11:22:39,334:INFO:Defining folds
2024-09-06 11:22:39,334:INFO:Declaring metric variables
2024-09-06 11:22:39,338:INFO:Importing untrained model
2024-09-06 11:22:39,343:INFO:Ridge Classifier Imported successfully
2024-09-06 11:22:39,352:INFO:Starting cross validation
2024-09-06 11:22:39,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:22:57,236:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:57,685:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:58,417:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:58,650:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:58,918:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:59,302:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:59,625:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:59,800:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:22:59,894:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:23:00,193:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:23:00,226:INFO:Calculating mean and std
2024-09-06 11:23:00,227:INFO:Creating metrics dataframe
2024-09-06 11:23:00,229:INFO:Uploading results into container
2024-09-06 11:23:00,230:INFO:Uploading model into container now
2024-09-06 11:23:00,230:INFO:_master_model_container: 6
2024-09-06 11:23:00,230:INFO:_display_container: 2
2024-09-06 11:23:00,231:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-06 11:23:00,231:INFO:create_model() successfully completed......................................
2024-09-06 11:23:00,307:INFO:SubProcess create_model() end ==================================
2024-09-06 11:23:00,307:INFO:Creating metrics dataframe
2024-09-06 11:23:00,317:INFO:Initializing Random Forest Classifier
2024-09-06 11:23:00,318:INFO:Total runtime is 7.144727210203808 minutes
2024-09-06 11:23:00,321:INFO:SubProcess create_model() called ==================================
2024-09-06 11:23:00,321:INFO:Initializing create_model()
2024-09-06 11:23:00,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:23:00,322:INFO:Checking exceptions
2024-09-06 11:23:00,322:INFO:Importing libraries
2024-09-06 11:23:00,323:INFO:Copying training dataset
2024-09-06 11:23:01,023:INFO:Defining folds
2024-09-06 11:23:01,023:INFO:Declaring metric variables
2024-09-06 11:23:01,027:INFO:Importing untrained model
2024-09-06 11:23:01,031:INFO:Random Forest Classifier Imported successfully
2024-09-06 11:23:01,038:INFO:Starting cross validation
2024-09-06 11:23:01,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:24:53,040:INFO:Calculating mean and std
2024-09-06 11:24:53,042:INFO:Creating metrics dataframe
2024-09-06 11:24:53,048:INFO:Uploading results into container
2024-09-06 11:24:53,049:INFO:Uploading model into container now
2024-09-06 11:24:53,049:INFO:_master_model_container: 7
2024-09-06 11:24:53,049:INFO:_display_container: 2
2024-09-06 11:24:53,050:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-06 11:24:53,050:INFO:create_model() successfully completed......................................
2024-09-06 11:24:53,153:INFO:SubProcess create_model() end ==================================
2024-09-06 11:24:53,153:INFO:Creating metrics dataframe
2024-09-06 11:24:53,162:INFO:Initializing Quadratic Discriminant Analysis
2024-09-06 11:24:53,162:INFO:Total runtime is 9.0254664738973 minutes
2024-09-06 11:24:53,167:INFO:SubProcess create_model() called ==================================
2024-09-06 11:24:53,167:INFO:Initializing create_model()
2024-09-06 11:24:53,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:24:53,167:INFO:Checking exceptions
2024-09-06 11:24:53,168:INFO:Importing libraries
2024-09-06 11:24:53,168:INFO:Copying training dataset
2024-09-06 11:24:54,010:INFO:Defining folds
2024-09-06 11:24:54,011:INFO:Declaring metric variables
2024-09-06 11:24:54,015:INFO:Importing untrained model
2024-09-06 11:24:54,020:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-06 11:24:54,027:INFO:Starting cross validation
2024-09-06 11:24:54,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:25:13,320:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:14,254:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:16,994:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:17,492:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:18,590:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:19,880:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:21,638:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:22,821:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:22,894:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:24,343:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:26,501:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:28,038:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 11:25:28,284:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:28,696:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:29,754:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:29,933:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:30,456:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:30,776:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:30,857:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:31,978:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:25:32,012:INFO:Calculating mean and std
2024-09-06 11:25:32,014:INFO:Creating metrics dataframe
2024-09-06 11:25:32,016:INFO:Uploading results into container
2024-09-06 11:25:32,016:INFO:Uploading model into container now
2024-09-06 11:25:32,017:INFO:_master_model_container: 8
2024-09-06 11:25:32,017:INFO:_display_container: 2
2024-09-06 11:25:32,017:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-06 11:25:32,017:INFO:create_model() successfully completed......................................
2024-09-06 11:25:32,094:INFO:SubProcess create_model() end ==================================
2024-09-06 11:25:32,094:INFO:Creating metrics dataframe
2024-09-06 11:25:32,104:INFO:Initializing Ada Boost Classifier
2024-09-06 11:25:32,104:INFO:Total runtime is 9.67449686129888 minutes
2024-09-06 11:25:32,108:INFO:SubProcess create_model() called ==================================
2024-09-06 11:25:32,108:INFO:Initializing create_model()
2024-09-06 11:25:32,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:25:32,109:INFO:Checking exceptions
2024-09-06 11:25:32,109:INFO:Importing libraries
2024-09-06 11:25:32,109:INFO:Copying training dataset
2024-09-06 11:25:32,788:INFO:Defining folds
2024-09-06 11:25:32,788:INFO:Declaring metric variables
2024-09-06 11:25:32,792:INFO:Importing untrained model
2024-09-06 11:25:32,795:INFO:Ada Boost Classifier Imported successfully
2024-09-06 11:25:32,802:INFO:Starting cross validation
2024-09-06 11:25:32,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:25:49,371:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:25:49,851:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:25:50,403:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:25:50,875:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:25:51,148:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:25:51,730:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:25:52,001:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:25:52,446:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:25:52,968:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:25:53,171:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 11:27:20,543:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:21,065:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:21,333:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:22,084:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:22,107:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:22,575:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:22,607:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:22,666:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:23,045:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:23,125:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:27:23,163:INFO:Calculating mean and std
2024-09-06 11:27:23,164:INFO:Creating metrics dataframe
2024-09-06 11:27:23,167:INFO:Uploading results into container
2024-09-06 11:27:23,168:INFO:Uploading model into container now
2024-09-06 11:27:23,169:INFO:_master_model_container: 9
2024-09-06 11:27:23,169:INFO:_display_container: 2
2024-09-06 11:27:23,169:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-06 11:27:23,169:INFO:create_model() successfully completed......................................
2024-09-06 11:27:23,245:INFO:SubProcess create_model() end ==================================
2024-09-06 11:27:23,245:INFO:Creating metrics dataframe
2024-09-06 11:27:23,255:INFO:Initializing Gradient Boosting Classifier
2024-09-06 11:27:23,255:INFO:Total runtime is 11.527014656861624 minutes
2024-09-06 11:27:23,259:INFO:SubProcess create_model() called ==================================
2024-09-06 11:27:23,259:INFO:Initializing create_model()
2024-09-06 11:27:23,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:27:23,259:INFO:Checking exceptions
2024-09-06 11:27:23,259:INFO:Importing libraries
2024-09-06 11:27:23,260:INFO:Copying training dataset
2024-09-06 11:27:23,967:INFO:Defining folds
2024-09-06 11:27:23,967:INFO:Declaring metric variables
2024-09-06 11:27:23,971:INFO:Importing untrained model
2024-09-06 11:27:23,975:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 11:27:23,982:INFO:Starting cross validation
2024-09-06 11:27:23,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:49:49,072:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:49,203:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:49,310:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:49,623:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:49,871:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:49,923:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:50,657:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:51,135:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:52,207:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:52,223:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:49:52,252:INFO:Calculating mean and std
2024-09-06 11:49:52,253:INFO:Creating metrics dataframe
2024-09-06 11:49:52,256:INFO:Uploading results into container
2024-09-06 11:49:52,257:INFO:Uploading model into container now
2024-09-06 11:49:52,257:INFO:_master_model_container: 10
2024-09-06 11:49:52,257:INFO:_display_container: 2
2024-09-06 11:49:52,257:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 11:49:52,259:INFO:create_model() successfully completed......................................
2024-09-06 11:49:52,335:INFO:SubProcess create_model() end ==================================
2024-09-06 11:49:52,335:INFO:Creating metrics dataframe
2024-09-06 11:49:52,346:INFO:Initializing Linear Discriminant Analysis
2024-09-06 11:49:52,346:INFO:Total runtime is 34.011856230099994 minutes
2024-09-06 11:49:52,349:INFO:SubProcess create_model() called ==================================
2024-09-06 11:49:52,350:INFO:Initializing create_model()
2024-09-06 11:49:52,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:49:52,350:INFO:Checking exceptions
2024-09-06 11:49:52,350:INFO:Importing libraries
2024-09-06 11:49:52,350:INFO:Copying training dataset
2024-09-06 11:49:53,106:INFO:Defining folds
2024-09-06 11:49:53,106:INFO:Declaring metric variables
2024-09-06 11:49:53,110:INFO:Importing untrained model
2024-09-06 11:49:53,114:INFO:Linear Discriminant Analysis Imported successfully
2024-09-06 11:49:53,122:INFO:Starting cross validation
2024-09-06 11:49:53,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:50:16,085:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:16,828:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:17,747:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:18,941:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:21,409:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:21,619:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:22,020:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:22,622:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:23,015:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:23,143:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 11:50:23,162:INFO:Calculating mean and std
2024-09-06 11:50:23,163:INFO:Creating metrics dataframe
2024-09-06 11:50:23,165:INFO:Uploading results into container
2024-09-06 11:50:23,166:INFO:Uploading model into container now
2024-09-06 11:50:23,167:INFO:_master_model_container: 11
2024-09-06 11:50:23,167:INFO:_display_container: 2
2024-09-06 11:50:23,167:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-06 11:50:23,167:INFO:create_model() successfully completed......................................
2024-09-06 11:50:23,258:INFO:SubProcess create_model() end ==================================
2024-09-06 11:50:23,259:INFO:Creating metrics dataframe
2024-09-06 11:50:23,271:INFO:Initializing Extra Trees Classifier
2024-09-06 11:50:23,271:INFO:Total runtime is 34.52727346022924 minutes
2024-09-06 11:50:23,276:INFO:SubProcess create_model() called ==================================
2024-09-06 11:50:23,277:INFO:Initializing create_model()
2024-09-06 11:50:23,277:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:50:23,277:INFO:Checking exceptions
2024-09-06 11:50:23,277:INFO:Importing libraries
2024-09-06 11:50:23,277:INFO:Copying training dataset
2024-09-06 11:50:24,030:INFO:Defining folds
2024-09-06 11:50:24,030:INFO:Declaring metric variables
2024-09-06 11:50:24,035:INFO:Importing untrained model
2024-09-06 11:50:24,040:INFO:Extra Trees Classifier Imported successfully
2024-09-06 11:50:24,049:INFO:Starting cross validation
2024-09-06 11:50:24,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:52:01,365:INFO:Calculating mean and std
2024-09-06 11:52:01,366:INFO:Creating metrics dataframe
2024-09-06 11:52:01,369:INFO:Uploading results into container
2024-09-06 11:52:01,370:INFO:Uploading model into container now
2024-09-06 11:52:01,370:INFO:_master_model_container: 12
2024-09-06 11:52:01,370:INFO:_display_container: 2
2024-09-06 11:52:01,371:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-06 11:52:01,371:INFO:create_model() successfully completed......................................
2024-09-06 11:52:01,472:INFO:SubProcess create_model() end ==================================
2024-09-06 11:52:01,472:INFO:Creating metrics dataframe
2024-09-06 11:52:01,488:INFO:Initializing Extreme Gradient Boosting
2024-09-06 11:52:01,489:INFO:Total runtime is 36.16424206495285 minutes
2024-09-06 11:52:01,494:INFO:SubProcess create_model() called ==================================
2024-09-06 11:52:01,495:INFO:Initializing create_model()
2024-09-06 11:52:01,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:52:01,495:INFO:Checking exceptions
2024-09-06 11:52:01,495:INFO:Importing libraries
2024-09-06 11:52:01,495:INFO:Copying training dataset
2024-09-06 11:52:02,276:INFO:Defining folds
2024-09-06 11:52:02,276:INFO:Declaring metric variables
2024-09-06 11:52:02,280:INFO:Importing untrained model
2024-09-06 11:52:02,285:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 11:52:02,294:INFO:Starting cross validation
2024-09-06 11:52:02,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:53:33,160:INFO:Calculating mean and std
2024-09-06 11:53:33,161:INFO:Creating metrics dataframe
2024-09-06 11:53:33,163:INFO:Uploading results into container
2024-09-06 11:53:33,164:INFO:Uploading model into container now
2024-09-06 11:53:33,164:INFO:_master_model_container: 13
2024-09-06 11:53:33,164:INFO:_display_container: 2
2024-09-06 11:53:33,166:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-06 11:53:33,166:INFO:create_model() successfully completed......................................
2024-09-06 11:53:33,241:INFO:SubProcess create_model() end ==================================
2024-09-06 11:53:33,242:INFO:Creating metrics dataframe
2024-09-06 11:53:33,254:INFO:Initializing Light Gradient Boosting Machine
2024-09-06 11:53:33,254:INFO:Total runtime is 37.69365322987239 minutes
2024-09-06 11:53:33,257:INFO:SubProcess create_model() called ==================================
2024-09-06 11:53:33,258:INFO:Initializing create_model()
2024-09-06 11:53:33,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:53:33,258:INFO:Checking exceptions
2024-09-06 11:53:33,258:INFO:Importing libraries
2024-09-06 11:53:33,258:INFO:Copying training dataset
2024-09-06 11:53:33,922:INFO:Defining folds
2024-09-06 11:53:33,922:INFO:Declaring metric variables
2024-09-06 11:53:33,926:INFO:Importing untrained model
2024-09-06 11:53:33,930:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 11:53:33,939:INFO:Starting cross validation
2024-09-06 11:53:33,945:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:56:12,599:INFO:Calculating mean and std
2024-09-06 11:56:12,601:INFO:Creating metrics dataframe
2024-09-06 11:56:12,606:INFO:Uploading results into container
2024-09-06 11:56:12,607:INFO:Uploading model into container now
2024-09-06 11:56:12,608:INFO:_master_model_container: 14
2024-09-06 11:56:12,608:INFO:_display_container: 2
2024-09-06 11:56:12,609:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 11:56:12,609:INFO:create_model() successfully completed......................................
2024-09-06 11:56:12,738:INFO:SubProcess create_model() end ==================================
2024-09-06 11:56:12,739:INFO:Creating metrics dataframe
2024-09-06 11:56:12,755:INFO:Initializing Dummy Classifier
2024-09-06 11:56:12,755:INFO:Total runtime is 40.35200959841411 minutes
2024-09-06 11:56:12,760:INFO:SubProcess create_model() called ==================================
2024-09-06 11:56:12,760:INFO:Initializing create_model()
2024-09-06 11:56:12,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001816D868550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:56:12,760:INFO:Checking exceptions
2024-09-06 11:56:12,760:INFO:Importing libraries
2024-09-06 11:56:12,760:INFO:Copying training dataset
2024-09-06 11:56:13,528:INFO:Defining folds
2024-09-06 11:56:13,528:INFO:Declaring metric variables
2024-09-06 11:56:13,532:INFO:Importing untrained model
2024-09-06 11:56:13,537:INFO:Dummy Classifier Imported successfully
2024-09-06 11:56:13,545:INFO:Starting cross validation
2024-09-06 11:56:13,552:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 11:56:29,835:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:30,379:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:30,667:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:31,399:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:31,642:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:32,263:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:32,418:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:32,557:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:32,620:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:32,933:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 11:56:32,958:INFO:Calculating mean and std
2024-09-06 11:56:32,959:INFO:Creating metrics dataframe
2024-09-06 11:56:32,962:INFO:Uploading results into container
2024-09-06 11:56:32,962:INFO:Uploading model into container now
2024-09-06 11:56:32,963:INFO:_master_model_container: 15
2024-09-06 11:56:32,963:INFO:_display_container: 2
2024-09-06 11:56:32,963:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-06 11:56:32,963:INFO:create_model() successfully completed......................................
2024-09-06 11:56:33,037:INFO:SubProcess create_model() end ==================================
2024-09-06 11:56:33,038:INFO:Creating metrics dataframe
2024-09-06 11:56:33,060:INFO:Initializing create_model()
2024-09-06 11:56:33,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 11:56:33,060:INFO:Checking exceptions
2024-09-06 11:56:33,064:INFO:Importing libraries
2024-09-06 11:56:33,064:INFO:Copying training dataset
2024-09-06 11:56:33,722:INFO:Defining folds
2024-09-06 11:56:33,722:INFO:Declaring metric variables
2024-09-06 11:56:33,722:INFO:Importing untrained model
2024-09-06 11:56:33,722:INFO:Declaring custom model
2024-09-06 11:56:33,723:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 11:56:33,728:INFO:Cross validation set to False
2024-09-06 11:56:33,728:INFO:Fitting Model
2024-09-06 11:56:38,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147369 seconds.
2024-09-06 11:56:38,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 11:56:38,213:INFO:[LightGBM] [Info] Total Bins 115351
2024-09-06 11:56:38,217:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 473
2024-09-06 11:56:38,222:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 11:56:38,222:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 11:56:38,222:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 11:56:47,651:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 11:56:47,651:INFO:create_model() successfully completed......................................
2024-09-06 11:56:47,766:INFO:_master_model_container: 15
2024-09-06 11:56:47,766:INFO:_display_container: 2
2024-09-06 11:56:47,766:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 11:56:47,767:INFO:compare_models() successfully completed......................................
2024-09-06 12:05:01,251:INFO:Initializing create_model()
2024-09-06 12:05:01,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 12:05:01,252:INFO:Checking exceptions
2024-09-06 12:05:01,271:INFO:Importing libraries
2024-09-06 12:05:01,271:INFO:Copying training dataset
2024-09-06 12:05:02,044:INFO:Defining folds
2024-09-06 12:05:02,044:INFO:Declaring metric variables
2024-09-06 12:05:02,048:INFO:Importing untrained model
2024-09-06 12:05:02,049:INFO:Declaring custom model
2024-09-06 12:05:02,053:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 12:05:02,060:INFO:Starting cross validation
2024-09-06 12:05:02,067:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 12:07:25,317:INFO:Calculating mean and std
2024-09-06 12:07:25,319:INFO:Creating metrics dataframe
2024-09-06 12:07:25,325:INFO:Finalizing model
2024-09-06 12:07:30,679:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.175811 seconds.
2024-09-06 12:07:30,679:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 12:07:30,687:INFO:[LightGBM] [Info] Total Bins 115351
2024-09-06 12:07:30,691:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 473
2024-09-06 12:07:30,695:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:07:30,695:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:07:30,695:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:07:39,822:INFO:Uploading results into container
2024-09-06 12:07:39,822:INFO:Uploading model into container now
2024-09-06 12:07:39,836:INFO:_master_model_container: 16
2024-09-06 12:07:39,837:INFO:_display_container: 3
2024-09-06 12:07:39,837:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 12:07:39,838:INFO:create_model() successfully completed......................................
2024-09-06 12:08:50,395:INFO:Initializing create_model()
2024-09-06 12:08:50,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 12:08:50,395:INFO:Checking exceptions
2024-09-06 12:08:50,413:INFO:Importing libraries
2024-09-06 12:08:50,413:INFO:Copying training dataset
2024-09-06 12:08:51,127:INFO:Defining folds
2024-09-06 12:08:51,127:INFO:Declaring metric variables
2024-09-06 12:08:51,130:INFO:Importing untrained model
2024-09-06 12:08:51,130:INFO:Declaring custom model
2024-09-06 12:08:51,134:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 12:08:51,142:INFO:Starting cross validation
2024-09-06 12:08:51,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 12:11:41,136:INFO:Calculating mean and std
2024-09-06 12:11:41,137:INFO:Creating metrics dataframe
2024-09-06 12:11:41,145:INFO:Finalizing model
2024-09-06 12:11:46,286:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138756 seconds.
2024-09-06 12:11:46,286:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 12:11:46,296:INFO:[LightGBM] [Info] Total Bins 115351
2024-09-06 12:11:46,301:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 473
2024-09-06 12:11:46,304:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:11:46,304:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:11:46,304:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:11:55,451:INFO:Uploading results into container
2024-09-06 12:11:55,452:INFO:Uploading model into container now
2024-09-06 12:11:55,466:INFO:_master_model_container: 17
2024-09-06 12:11:55,467:INFO:_display_container: 4
2024-09-06 12:11:55,467:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 12:11:55,468:INFO:create_model() successfully completed......................................
2024-09-06 12:18:02,153:INFO:Initializing create_model()
2024-09-06 12:18:02,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 12:18:02,153:INFO:Checking exceptions
2024-09-06 12:18:02,172:INFO:Importing libraries
2024-09-06 12:18:02,172:INFO:Copying training dataset
2024-09-06 12:18:02,891:INFO:Defining folds
2024-09-06 12:18:02,891:INFO:Declaring metric variables
2024-09-06 12:18:02,895:INFO:Importing untrained model
2024-09-06 12:18:02,895:INFO:Declaring custom model
2024-09-06 12:18:02,899:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 12:18:02,906:INFO:Starting cross validation
2024-09-06 12:18:02,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 12:20:33,662:INFO:Calculating mean and std
2024-09-06 12:20:33,664:INFO:Creating metrics dataframe
2024-09-06 12:20:33,673:INFO:Finalizing model
2024-09-06 12:20:38,923:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142817 seconds.
2024-09-06 12:20:38,923:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 12:20:38,931:INFO:[LightGBM] [Info] Total Bins 115351
2024-09-06 12:20:38,936:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 473
2024-09-06 12:20:38,939:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:20:38,939:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:20:38,939:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:20:50,661:INFO:Uploading results into container
2024-09-06 12:20:50,662:INFO:Uploading model into container now
2024-09-06 12:20:50,676:INFO:_master_model_container: 18
2024-09-06 12:20:50,676:INFO:_display_container: 5
2024-09-06 12:20:50,677:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 12:20:50,677:INFO:create_model() successfully completed......................................
2024-09-06 12:20:50,809:INFO:Initializing tune_model()
2024-09-06 12:20:50,809:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 200, 300], 'max_depth': [3, 5, 7, 9], 'learning_rate': [0.01, 0.05, 0.1, 0.2], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'subsample': [0.6, 0.8, 1.0]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>)
2024-09-06 12:20:50,810:INFO:Checking exceptions
2024-09-06 12:20:50,810:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-06 12:20:51,217:INFO:Copying training dataset
2024-09-06 12:20:51,640:INFO:Checking base model
2024-09-06 12:20:51,641:INFO:Base model : Light Gradient Boosting Machine
2024-09-06 12:20:51,645:INFO:Declaring metric variables
2024-09-06 12:20:51,648:INFO:Defining Hyperparameters
2024-09-06 12:20:51,731:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200, 300]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7, 9]), 'actual_estimator__learning_rate': CategoricalDistribution(values=[0.01, 0.05, 0.1, 0.2]), 'actual_estimator__min_samples_split': CategoricalDistribution(values=[2, 5, 10]), 'actual_estimator__min_samples_leaf': CategoricalDistribution(values=[1, 2, 4]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.6, 0.8, 1.0])}
2024-09-06 12:20:51,732:INFO:Tuning with n_jobs=-1
2024-09-06 12:20:51,741:INFO:Initializing skopt.BayesSearchCV
2024-09-06 12:37:14,019:INFO:best_params: OrderedDict([('actual_estimator__learning_rate', 0.05), ('actual_estimator__max_depth', 7), ('actual_estimator__min_samples_leaf', 2), ('actual_estimator__min_samples_split', 2), ('actual_estimator__n_estimators', 300), ('actual_estimator__subsample', 0.6)])
2024-09-06 12:37:14,020:INFO:Hyperparameter search completed
2024-09-06 12:37:14,020:INFO:SubProcess create_model() called ==================================
2024-09-06 12:37:14,021:INFO:Initializing create_model()
2024-09-06 12:37:14,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001817356A770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.05, 'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300, 'subsample': 0.6})
2024-09-06 12:37:14,021:INFO:Checking exceptions
2024-09-06 12:37:14,021:INFO:Importing libraries
2024-09-06 12:37:14,021:INFO:Copying training dataset
2024-09-06 12:37:14,751:INFO:Defining folds
2024-09-06 12:37:14,751:INFO:Declaring metric variables
2024-09-06 12:37:14,756:INFO:Importing untrained model
2024-09-06 12:37:14,756:INFO:Declaring custom model
2024-09-06 12:37:14,761:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 12:37:14,769:INFO:Starting cross validation
2024-09-06 12:37:14,778:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 12:40:38,227:INFO:Calculating mean and std
2024-09-06 12:40:38,228:INFO:Creating metrics dataframe
2024-09-06 12:40:38,239:INFO:Finalizing model
2024-09-06 12:40:41,462:INFO:[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=2. Current value: min_data_in_leaf=2
2024-09-06 12:40:41,462:INFO:[LightGBM] [Warning] Unknown parameter: min_samples_split
2024-09-06 12:40:42,904:INFO:[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=2. Current value: min_data_in_leaf=2
2024-09-06 12:40:42,904:INFO:[LightGBM] [Warning] Unknown parameter: min_samples_split
2024-09-06 12:40:43,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177783 seconds.
2024-09-06 12:40:43,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 12:40:43,102:INFO:[LightGBM] [Info] Total Bins 115351
2024-09-06 12:40:43,107:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 473
2024-09-06 12:40:43,110:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:40:43,110:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:40:43,111:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:41:06,217:INFO:Uploading results into container
2024-09-06 12:41:06,218:INFO:Uploading model into container now
2024-09-06 12:41:06,219:INFO:_master_model_container: 19
2024-09-06 12:41:06,219:INFO:_display_container: 6
2024-09-06 12:41:06,220:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.05, max_depth=7,
               min_child_samples=20, min_child_weight=0.001, min_samples_leaf=2,
               min_samples_split=2, min_split_gain=0.0, n_estimators=300,
               n_jobs=-1, num_leaves=31, objective=None, random_state=123,
               reg_alpha=0.0, reg_lambda=0.0, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 12:41:06,220:INFO:create_model() successfully completed......................................
2024-09-06 12:41:06,347:INFO:SubProcess create_model() end ==================================
2024-09-06 12:41:06,347:INFO:choose_better activated
2024-09-06 12:41:06,351:INFO:SubProcess create_model() called ==================================
2024-09-06 12:41:06,351:INFO:Initializing create_model()
2024-09-06 12:41:06,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 12:41:06,352:INFO:Checking exceptions
2024-09-06 12:41:06,353:INFO:Importing libraries
2024-09-06 12:41:06,353:INFO:Copying training dataset
2024-09-06 12:41:07,010:INFO:Defining folds
2024-09-06 12:41:07,010:INFO:Declaring metric variables
2024-09-06 12:41:07,010:INFO:Importing untrained model
2024-09-06 12:41:07,010:INFO:Declaring custom model
2024-09-06 12:41:07,011:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 12:41:07,011:INFO:Starting cross validation
2024-09-06 12:41:07,017:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 12:42:12,913:INFO:Calculating mean and std
2024-09-06 12:42:12,914:INFO:Creating metrics dataframe
2024-09-06 12:42:12,916:INFO:Finalizing model
2024-09-06 12:42:17,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140771 seconds.
2024-09-06 12:42:17,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 12:42:17,470:INFO:[LightGBM] [Info] Total Bins 115351
2024-09-06 12:42:17,475:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 473
2024-09-06 12:42:17,477:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:42:17,478:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:42:17,478:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:42:27,269:INFO:Uploading results into container
2024-09-06 12:42:27,270:INFO:Uploading model into container now
2024-09-06 12:42:27,270:INFO:_master_model_container: 20
2024-09-06 12:42:27,270:INFO:_display_container: 7
2024-09-06 12:42:27,271:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 12:42:27,271:INFO:create_model() successfully completed......................................
2024-09-06 12:42:27,387:INFO:SubProcess create_model() end ==================================
2024-09-06 12:42:27,388:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8286
2024-09-06 12:42:27,389:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.05, max_depth=7,
               min_child_samples=20, min_child_weight=0.001, min_samples_leaf=2,
               min_samples_split=2, min_split_gain=0.0, n_estimators=300,
               n_jobs=-1, num_leaves=31, objective=None, random_state=123,
               reg_alpha=0.0, reg_lambda=0.0, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.828
2024-09-06 12:42:27,389:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-06 12:42:27,389:INFO:choose_better completed
2024-09-06 12:42:27,389:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-06 12:42:27,400:INFO:_master_model_container: 20
2024-09-06 12:42:27,400:INFO:_display_container: 6
2024-09-06 12:42:27,401:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 12:42:27,401:INFO:tune_model() successfully completed......................................
2024-09-06 12:43:11,240:INFO:Initializing predict_model()
2024-09-06 12:43:11,241:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018179AA8C10>)
2024-09-06 12:43:11,241:INFO:Checking exceptions
2024-09-06 12:43:11,241:INFO:Preloading libraries
2024-09-06 12:43:11,245:INFO:Set up data.
2024-09-06 12:43:11,766:INFO:Set up index.
2024-09-06 12:43:12,747:INFO:Initializing get_config()
2024-09-06 12:43:12,747:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, variable=X_train)
2024-09-06 12:43:12,748:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 12:43:13,021:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071  -0.307305   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   1.787297   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904  -0.307305   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743  -0.307305   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044  -0.307305   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403  -0.307305   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365   1.787297   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822  -0.307305   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044  -0.307305   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822  -0.307305   

       feature_6  feature_7  feature_8  feature_9  ...  feature_463  \
71710  -0.216109   -0.06743   1.112682   0.908807  ...    -0.086278   
41786   0.066573   -0.06743  -1.226048  -1.505896  ...    -0.086278   
53345  -1.127987   -0.06743   1.112682   0.908807  ...    -0.086278   
11745  -0.854424   -0.06743  -0.056683   0.975882  ...     6.167595   
23494   3.249027   -0.06743  -0.056683   1.042958  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374   1.516459   -0.06743   1.112682   0.908807  ...    -0.086278   
38857  -2.039865   -0.06743  -0.056683   0.707582  ...    -0.086278   
31149  -0.033734   -0.06743  -0.056683   0.975882  ...    -0.086278   
55353  -0.216109   -0.06743  -0.056683   0.975882  ...    -0.086278   
1638   -0.854424   -0.06743  -0.056683   0.908807  ...    -0.086278   

       feature_464  feature_465  feature_466  feature_467  feature_468  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_469  feature_470  feature_471  feature_472  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 473 columns]
2024-09-06 12:43:13,022:INFO:get_config() successfully completed......................................
2024-09-06 12:43:13,022:INFO:Initializing predict_model()
2024-09-06 12:43:13,022:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001814BD08B80>)
2024-09-06 12:43:13,022:INFO:Checking exceptions
2024-09-06 12:43:13,022:INFO:Preloading libraries
2024-09-06 12:43:13,025:INFO:Set up data.
2024-09-06 12:43:13,248:INFO:Set up index.
2024-09-06 12:43:14,638:INFO:Initializing get_config()
2024-09-06 12:43:14,638:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, variable=y_train)
2024-09-06 12:43:14,638:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 12:43:14,813:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 12:43:14,813:INFO:get_config() successfully completed......................................
2024-09-06 12:43:14,814:INFO:Initializing get_config()
2024-09-06 12:43:14,814:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, variable=y_test)
2024-09-06 12:43:14,814:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 12:43:14,940:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 12:43:14,940:INFO:get_config() successfully completed......................................
2024-09-06 12:43:14,945:INFO:Initializing finalize_model()
2024-09-06 12:43:14,946:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 12:43:14,946:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 12:43:15,408:INFO:Initializing create_model()
2024-09-06 12:43:15,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 12:43:15,408:INFO:Checking exceptions
2024-09-06 12:43:15,409:INFO:Importing libraries
2024-09-06 12:43:15,409:INFO:Copying training dataset
2024-09-06 12:43:15,492:INFO:Defining folds
2024-09-06 12:43:15,492:INFO:Declaring metric variables
2024-09-06 12:43:15,493:INFO:Importing untrained model
2024-09-06 12:43:15,493:INFO:Declaring custom model
2024-09-06 12:43:15,494:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 12:43:15,500:INFO:Cross validation set to False
2024-09-06 12:43:15,501:INFO:Fitting Model
2024-09-06 12:43:23,415:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.231971 seconds.
2024-09-06 12:43:23,415:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 12:43:23,425:INFO:[LightGBM] [Info] Total Bins 116537
2024-09-06 12:43:23,429:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 473
2024-09-06 12:43:23,432:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:43:23,432:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:43:23,432:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 12:43:37,610:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 12:43:37,611:INFO:create_model() successfully completed......................................
2024-09-06 12:43:37,714:INFO:_master_model_container: 20
2024-09-06 12:43:37,714:INFO:_display_container: 7
2024-09-06 12:43:37,725:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 12:43:37,725:INFO:finalize_model() successfully completed......................................
2024-09-06 12:43:37,817:INFO:Initializing predict_model()
2024-09-06 12:43:37,817:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001814BD08B80>)
2024-09-06 12:43:37,817:INFO:Checking exceptions
2024-09-06 12:43:37,817:INFO:Preloading libraries
2024-09-06 12:43:37,819:INFO:Set up data.
2024-09-06 12:43:38,058:INFO:Set up index.
2024-09-06 13:26:44,093:INFO:Initializing create_model()
2024-09-06 13:26:44,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 13:26:44,094:INFO:Checking exceptions
2024-09-06 13:26:44,117:INFO:Importing libraries
2024-09-06 13:26:44,117:INFO:Copying training dataset
2024-09-06 13:26:44,981:INFO:Defining folds
2024-09-06 13:26:44,981:INFO:Declaring metric variables
2024-09-06 13:26:44,984:INFO:Importing untrained model
2024-09-06 13:26:44,989:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 13:26:44,995:INFO:Starting cross validation
2024-09-06 13:26:45,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 13:28:25,761:INFO:Calculating mean and std
2024-09-06 13:28:25,763:INFO:Creating metrics dataframe
2024-09-06 13:28:25,772:INFO:Finalizing model
2024-09-06 13:28:41,393:INFO:Uploading results into container
2024-09-06 13:28:41,394:INFO:Uploading model into container now
2024-09-06 13:28:41,415:INFO:_master_model_container: 21
2024-09-06 13:28:41,415:INFO:_display_container: 9
2024-09-06 13:28:41,416:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-06 13:28:41,416:INFO:create_model() successfully completed......................................
2024-09-06 13:28:41,707:INFO:Initializing tune_model()
2024-09-06 13:28:41,707:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 200, 300], 'max_depth': [3, 5, 7, 9], 'learning_rate': [0.01, 0.05, 0.1, 0.2], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'subsample': [0.6, 0.8, 1.0]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>)
2024-09-06 13:28:41,707:INFO:Checking exceptions
2024-09-06 13:28:41,707:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-06 13:28:42,022:INFO:Copying training dataset
2024-09-06 13:28:42,434:INFO:Checking base model
2024-09-06 13:28:42,435:INFO:Base model : Extreme Gradient Boosting
2024-09-06 13:28:42,439:INFO:Declaring metric variables
2024-09-06 13:28:42,442:INFO:Defining Hyperparameters
2024-09-06 13:28:42,524:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200, 300]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7, 9]), 'actual_estimator__learning_rate': CategoricalDistribution(values=[0.01, 0.05, 0.1, 0.2]), 'actual_estimator__min_samples_split': CategoricalDistribution(values=[2, 5, 10]), 'actual_estimator__min_samples_leaf': CategoricalDistribution(values=[1, 2, 4]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.6, 0.8, 1.0])}
2024-09-06 13:28:42,525:INFO:Tuning with n_jobs=-1
2024-09-06 13:28:42,528:INFO:Initializing skopt.BayesSearchCV
2024-09-06 13:52:14,741:INFO:best_params: OrderedDict([('actual_estimator__learning_rate', 0.05), ('actual_estimator__max_depth', 7), ('actual_estimator__min_samples_leaf', 2), ('actual_estimator__min_samples_split', 2), ('actual_estimator__n_estimators', 300), ('actual_estimator__subsample', 0.6)])
2024-09-06 13:52:14,755:INFO:Hyperparameter search completed
2024-09-06 13:52:14,755:INFO:SubProcess create_model() called ==================================
2024-09-06 13:52:14,759:INFO:Initializing create_model()
2024-09-06 13:52:14,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018167304040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.05, 'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300, 'subsample': 0.6})
2024-09-06 13:52:14,760:INFO:Checking exceptions
2024-09-06 13:52:14,761:INFO:Importing libraries
2024-09-06 13:52:14,761:INFO:Copying training dataset
2024-09-06 13:52:15,659:INFO:Defining folds
2024-09-06 13:52:15,659:INFO:Declaring metric variables
2024-09-06 13:52:15,674:INFO:Importing untrained model
2024-09-06 13:52:15,674:INFO:Declaring custom model
2024-09-06 13:52:15,682:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 13:52:15,690:INFO:Starting cross validation
2024-09-06 13:52:15,715:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 13:55:45,443:INFO:Calculating mean and std
2024-09-06 13:55:45,444:INFO:Creating metrics dataframe
2024-09-06 13:55:45,451:INFO:Finalizing model
2024-09-06 13:56:35,943:INFO:Uploading results into container
2024-09-06 13:56:35,945:INFO:Uploading model into container now
2024-09-06 13:56:35,947:INFO:_master_model_container: 22
2024-09-06 13:56:35,948:INFO:_display_container: 10
2024-09-06 13:56:35,949:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, min_samples_leaf=2, min_samples_split=2,
              missing=nan, monotone_constraints=None, multi_strategy=None,
              n_estimators=300, n_jobs=-1, ...)
2024-09-06 13:56:35,949:INFO:create_model() successfully completed......................................
2024-09-06 13:56:36,201:INFO:SubProcess create_model() end ==================================
2024-09-06 13:56:36,202:INFO:choose_better activated
2024-09-06 13:56:36,206:INFO:SubProcess create_model() called ==================================
2024-09-06 13:56:36,207:INFO:Initializing create_model()
2024-09-06 13:56:36,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 13:56:36,207:INFO:Checking exceptions
2024-09-06 13:56:36,209:INFO:Importing libraries
2024-09-06 13:56:36,209:INFO:Copying training dataset
2024-09-06 13:56:36,906:INFO:Defining folds
2024-09-06 13:56:36,906:INFO:Declaring metric variables
2024-09-06 13:56:36,906:INFO:Importing untrained model
2024-09-06 13:56:36,906:INFO:Declaring custom model
2024-09-06 13:56:36,908:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 13:56:36,908:INFO:Starting cross validation
2024-09-06 13:56:36,915:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 13:57:39,988:INFO:Calculating mean and std
2024-09-06 13:57:39,988:INFO:Creating metrics dataframe
2024-09-06 13:57:39,990:INFO:Finalizing model
2024-09-06 13:57:54,890:INFO:Uploading results into container
2024-09-06 13:57:54,890:INFO:Uploading model into container now
2024-09-06 13:57:54,891:INFO:_master_model_container: 23
2024-09-06 13:57:54,891:INFO:_display_container: 11
2024-09-06 13:57:54,892:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-06 13:57:54,892:INFO:create_model() successfully completed......................................
2024-09-06 13:57:54,996:INFO:SubProcess create_model() end ==================================
2024-09-06 13:57:54,997:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...) result for Accuracy is 0.8255
2024-09-06 13:57:54,997:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, min_samples_leaf=2, min_samples_split=2,
              missing=nan, monotone_constraints=None, multi_strategy=None,
              n_estimators=300, n_jobs=-1, ...) result for Accuracy is 0.8286
2024-09-06 13:57:54,998:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, min_samples_leaf=2, min_samples_split=2,
              missing=nan, monotone_constraints=None, multi_strategy=None,
              n_estimators=300, n_jobs=-1, ...) is best model
2024-09-06 13:57:54,998:INFO:choose_better completed
2024-09-06 13:57:55,007:INFO:_master_model_container: 23
2024-09-06 13:57:55,007:INFO:_display_container: 10
2024-09-06 13:57:55,008:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, min_samples_leaf=2, min_samples_split=2,
              missing=nan, monotone_constraints=None, multi_strategy=None,
              n_estimators=300, n_jobs=-1, ...)
2024-09-06 13:57:55,008:INFO:tune_model() successfully completed......................................
2024-09-06 17:26:36,355:INFO:Initializing plot_model()
2024-09-06 17:26:36,357:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=7, max_leaves=None,
              min_child_weight=None, min_samples_leaf=2, min_samples_split=2,
              missing=nan, monotone_constraints=None, multi_strategy=None,
              n_estimators=300, n_jobs=-1, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018167E27B50>, system=True)
2024-09-06 17:26:36,357:INFO:Checking exceptions
2024-09-06 17:26:36,903:INFO:Preloading libraries
2024-09-06 17:26:36,979:INFO:Copying training dataset
2024-09-06 17:26:36,979:INFO:Plot type: confusion_matrix
2024-09-06 17:26:39,502:INFO:Fitting Model
2024-09-06 17:26:39,504:INFO:Scoring test/hold-out set
2024-09-06 17:26:40,144:INFO:Visual Rendered Successfully
2024-09-06 17:26:40,313:INFO:plot_model() successfully completed......................................
2024-09-06 17:57:44,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 17:57:44,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 17:57:44,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 17:57:44,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 18:10:47,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 18:10:47,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 18:10:47,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 18:10:47,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 18:11:22,873:INFO:PyCaret ClassificationExperiment
2024-09-06 18:11:22,873:INFO:Logging name: clf-default-name
2024-09-06 18:11:22,873:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-06 18:11:22,873:INFO:version 3.3.2
2024-09-06 18:11:22,873:INFO:Initializing setup()
2024-09-06 18:11:22,873:INFO:self.USI: a07b
2024-09-06 18:11:22,873:INFO:self._variable_keys: {'exp_id', 'fix_imbalance', '_ml_usecase', 'memory', 'logging_param', 'X_test', 'y', 'exp_name_log', 'gpu_param', 'pipeline', 'X', 'target_param', 'y_train', 'y_test', 'is_multiclass', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train', 'fold_groups_param', 'html_param', 'idx', 'log_plots_param', 'data', 'fold_generator', '_available_plots', 'seed'}
2024-09-06 18:11:22,873:INFO:Checking environment
2024-09-06 18:11:22,873:INFO:python_version: 3.10.11
2024-09-06 18:11:22,873:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-06 18:11:22,873:INFO:machine: AMD64
2024-09-06 18:11:22,873:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-06 18:11:22,873:INFO:Memory: svmem(total=17128263680, available=8341975040, percent=51.3, used=8786288640, free=8341975040)
2024-09-06 18:11:22,873:INFO:Physical Core: 6
2024-09-06 18:11:22,873:INFO:Logical Core: 12
2024-09-06 18:11:22,874:INFO:Checking libraries
2024-09-06 18:11:22,874:INFO:System:
2024-09-06 18:11:22,874:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-06 18:11:22,874:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-06 18:11:22,874:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-06 18:11:22,874:INFO:PyCaret required dependencies:
2024-09-06 18:11:22,899:INFO:                 pip: 24.2
2024-09-06 18:11:22,899:INFO:          setuptools: 72.1.0
2024-09-06 18:11:22,899:INFO:             pycaret: 3.3.2
2024-09-06 18:11:22,899:INFO:             IPython: 8.27.0
2024-09-06 18:11:22,899:INFO:          ipywidgets: 8.1.5
2024-09-06 18:11:22,899:INFO:                tqdm: 4.66.5
2024-09-06 18:11:22,899:INFO:               numpy: 1.26.4
2024-09-06 18:11:22,899:INFO:              pandas: 2.2.2
2024-09-06 18:11:22,899:INFO:              jinja2: 3.1.4
2024-09-06 18:11:22,899:INFO:               scipy: 1.11.4
2024-09-06 18:11:22,899:INFO:              joblib: 1.3.2
2024-09-06 18:11:22,899:INFO:             sklearn: 1.4.2
2024-09-06 18:11:22,899:INFO:                pyod: 2.0.1
2024-09-06 18:11:22,899:INFO:            imblearn: 0.12.3
2024-09-06 18:11:22,899:INFO:   category_encoders: 2.6.3
2024-09-06 18:11:22,899:INFO:            lightgbm: 4.5.0
2024-09-06 18:11:22,899:INFO:               numba: 0.60.0
2024-09-06 18:11:22,899:INFO:            requests: 2.32.3
2024-09-06 18:11:22,899:INFO:          matplotlib: 3.7.5
2024-09-06 18:11:22,899:INFO:          scikitplot: 0.3.7
2024-09-06 18:11:22,899:INFO:         yellowbrick: 1.5
2024-09-06 18:11:22,899:INFO:              plotly: 5.24.0
2024-09-06 18:11:22,899:INFO:    plotly-resampler: Not installed
2024-09-06 18:11:22,900:INFO:             kaleido: 0.2.1
2024-09-06 18:11:22,900:INFO:           schemdraw: 0.15
2024-09-06 18:11:22,900:INFO:         statsmodels: 0.14.2
2024-09-06 18:11:22,901:INFO:              sktime: 0.26.0
2024-09-06 18:11:22,901:INFO:               tbats: 1.1.3
2024-09-06 18:11:22,901:INFO:            pmdarima: 2.0.4
2024-09-06 18:11:22,901:INFO:              psutil: 6.0.0
2024-09-06 18:11:22,901:INFO:          markupsafe: 2.1.5
2024-09-06 18:11:22,901:INFO:             pickle5: Not installed
2024-09-06 18:11:22,901:INFO:         cloudpickle: 3.0.0
2024-09-06 18:11:22,901:INFO:         deprecation: 2.1.0
2024-09-06 18:11:22,901:INFO:              xxhash: 3.5.0
2024-09-06 18:11:22,901:INFO:           wurlitzer: Not installed
2024-09-06 18:11:22,901:INFO:PyCaret optional dependencies:
2024-09-06 18:11:22,916:INFO:                shap: Not installed
2024-09-06 18:11:22,916:INFO:           interpret: Not installed
2024-09-06 18:11:22,916:INFO:                umap: Not installed
2024-09-06 18:11:22,916:INFO:     ydata_profiling: Not installed
2024-09-06 18:11:22,916:INFO:  explainerdashboard: Not installed
2024-09-06 18:11:22,917:INFO:             autoviz: Not installed
2024-09-06 18:11:22,917:INFO:           fairlearn: Not installed
2024-09-06 18:11:22,917:INFO:          deepchecks: Not installed
2024-09-06 18:11:22,917:INFO:             xgboost: 2.1.1
2024-09-06 18:11:22,917:INFO:            catboost: Not installed
2024-09-06 18:11:22,917:INFO:              kmodes: Not installed
2024-09-06 18:11:22,917:INFO:             mlxtend: Not installed
2024-09-06 18:11:22,917:INFO:       statsforecast: Not installed
2024-09-06 18:11:22,917:INFO:        tune_sklearn: Not installed
2024-09-06 18:11:22,917:INFO:                 ray: Not installed
2024-09-06 18:11:22,917:INFO:            hyperopt: 0.2.7
2024-09-06 18:11:22,917:INFO:              optuna: 4.0.0
2024-09-06 18:11:22,917:INFO:               skopt: 0.10.2
2024-09-06 18:11:22,917:INFO:              mlflow: Not installed
2024-09-06 18:11:22,917:INFO:              gradio: Not installed
2024-09-06 18:11:22,917:INFO:             fastapi: Not installed
2024-09-06 18:11:22,917:INFO:             uvicorn: Not installed
2024-09-06 18:11:22,917:INFO:              m2cgen: Not installed
2024-09-06 18:11:22,917:INFO:           evidently: Not installed
2024-09-06 18:11:22,917:INFO:               fugue: Not installed
2024-09-06 18:11:22,917:INFO:           streamlit: Not installed
2024-09-06 18:11:22,917:INFO:             prophet: Not installed
2024-09-06 18:11:22,918:INFO:None
2024-09-06 18:11:22,918:INFO:Set up data.
2024-09-06 18:11:23,220:INFO:Set up folding strategy.
2024-09-06 18:11:23,220:INFO:Set up train/test split.
2024-09-06 18:11:23,572:INFO:Set up index.
2024-09-06 18:11:23,583:INFO:Assigning column types.
2024-09-06 18:11:23,958:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-06 18:11:24,006:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 18:11:24,010:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 18:11:24,048:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 18:11:24,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 18:11:24,099:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 18:11:24,100:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 18:11:24,130:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 18:11:24,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 18:11:24,134:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-06 18:11:24,182:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 18:11:24,212:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 18:11:24,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 18:11:24,264:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 18:11:24,294:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 18:11:24,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 18:11:24,297:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-06 18:11:24,382:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 18:11:24,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 18:11:24,466:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 18:11:24,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 18:11:24,472:INFO:Preparing preprocessing pipeline...
2024-09-06 18:11:24,535:INFO:Set up simple imputation.
2024-09-06 18:11:24,535:INFO:Set up imbalanced handling.
2024-09-06 18:11:25,417:INFO:Finished creating preprocessing pipeline.
2024-09-06 18:11:25,428:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-06 18:11:25,428:INFO:Creating final display dataframe.
2024-09-06 18:11:31,031:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 259)
4        Transformed data shape      (99147, 259)
5   Transformed train set shape      (76191, 259)
6    Transformed test set shape      (22956, 259)
7              Numeric features               258
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              a07b
2024-09-06 18:11:31,118:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 18:11:31,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 18:11:31,200:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 18:11:31,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 18:11:31,204:INFO:setup() successfully completed in 8.35s...............
2024-09-06 18:11:31,214:INFO:Initializing compare_models()
2024-09-06 18:11:31,214:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-06 18:11:31,214:INFO:Checking exceptions
2024-09-06 18:11:31,503:INFO:Preparing display monitor
2024-09-06 18:11:31,526:INFO:Initializing Logistic Regression
2024-09-06 18:11:31,526:INFO:Total runtime is 0.0 minutes
2024-09-06 18:11:31,528:INFO:SubProcess create_model() called ==================================
2024-09-06 18:11:31,529:INFO:Initializing create_model()
2024-09-06 18:11:31,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:11:31,529:INFO:Checking exceptions
2024-09-06 18:11:31,529:INFO:Importing libraries
2024-09-06 18:11:31,529:INFO:Copying training dataset
2024-09-06 18:11:31,965:INFO:Defining folds
2024-09-06 18:11:31,965:INFO:Declaring metric variables
2024-09-06 18:11:31,970:INFO:Importing untrained model
2024-09-06 18:11:31,973:INFO:Logistic Regression Imported successfully
2024-09-06 18:11:31,980:INFO:Starting cross validation
2024-09-06 18:11:31,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:12:54,944:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:12:55,013:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:12:57,899:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:12:58,738:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:12:59,661:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:13:00,211:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:13:00,831:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:13:01,412:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:13:01,766:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:13:03,640:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:13:03,662:INFO:Calculating mean and std
2024-09-06 18:13:03,663:INFO:Creating metrics dataframe
2024-09-06 18:13:03,666:INFO:Uploading results into container
2024-09-06 18:13:03,666:INFO:Uploading model into container now
2024-09-06 18:13:03,667:INFO:_master_model_container: 1
2024-09-06 18:13:03,667:INFO:_display_container: 2
2024-09-06 18:13:03,667:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-06 18:13:03,668:INFO:create_model() successfully completed......................................
2024-09-06 18:13:03,745:INFO:SubProcess create_model() end ==================================
2024-09-06 18:13:03,746:INFO:Creating metrics dataframe
2024-09-06 18:13:03,753:INFO:Initializing K Neighbors Classifier
2024-09-06 18:13:03,753:INFO:Total runtime is 1.5371236642201742 minutes
2024-09-06 18:13:03,757:INFO:SubProcess create_model() called ==================================
2024-09-06 18:13:03,757:INFO:Initializing create_model()
2024-09-06 18:13:03,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:13:03,757:INFO:Checking exceptions
2024-09-06 18:13:03,757:INFO:Importing libraries
2024-09-06 18:13:03,757:INFO:Copying training dataset
2024-09-06 18:13:04,187:INFO:Defining folds
2024-09-06 18:13:04,187:INFO:Declaring metric variables
2024-09-06 18:13:04,191:INFO:Importing untrained model
2024-09-06 18:13:04,195:INFO:K Neighbors Classifier Imported successfully
2024-09-06 18:13:04,201:INFO:Starting cross validation
2024-09-06 18:13:04,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:13:34,417:INFO:Calculating mean and std
2024-09-06 18:13:34,418:INFO:Creating metrics dataframe
2024-09-06 18:13:34,420:INFO:Uploading results into container
2024-09-06 18:13:34,421:INFO:Uploading model into container now
2024-09-06 18:13:34,421:INFO:_master_model_container: 2
2024-09-06 18:13:34,421:INFO:_display_container: 2
2024-09-06 18:13:34,422:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-06 18:13:34,422:INFO:create_model() successfully completed......................................
2024-09-06 18:13:34,510:INFO:SubProcess create_model() end ==================================
2024-09-06 18:13:34,510:INFO:Creating metrics dataframe
2024-09-06 18:13:34,519:INFO:Initializing Naive Bayes
2024-09-06 18:13:34,519:INFO:Total runtime is 2.049886782964071 minutes
2024-09-06 18:13:34,523:INFO:SubProcess create_model() called ==================================
2024-09-06 18:13:34,523:INFO:Initializing create_model()
2024-09-06 18:13:34,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:13:34,523:INFO:Checking exceptions
2024-09-06 18:13:34,523:INFO:Importing libraries
2024-09-06 18:13:34,523:INFO:Copying training dataset
2024-09-06 18:13:34,953:INFO:Defining folds
2024-09-06 18:13:34,953:INFO:Declaring metric variables
2024-09-06 18:13:34,957:INFO:Importing untrained model
2024-09-06 18:13:34,961:INFO:Naive Bayes Imported successfully
2024-09-06 18:13:34,969:INFO:Starting cross validation
2024-09-06 18:13:34,973:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:13:46,328:INFO:Calculating mean and std
2024-09-06 18:13:46,330:INFO:Creating metrics dataframe
2024-09-06 18:13:46,332:INFO:Uploading results into container
2024-09-06 18:13:46,332:INFO:Uploading model into container now
2024-09-06 18:13:46,332:INFO:_master_model_container: 3
2024-09-06 18:13:46,333:INFO:_display_container: 2
2024-09-06 18:13:46,333:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-06 18:13:46,333:INFO:create_model() successfully completed......................................
2024-09-06 18:13:46,406:INFO:SubProcess create_model() end ==================================
2024-09-06 18:13:46,406:INFO:Creating metrics dataframe
2024-09-06 18:13:46,417:INFO:Initializing Decision Tree Classifier
2024-09-06 18:13:46,417:INFO:Total runtime is 2.2481861352920536 minutes
2024-09-06 18:13:46,423:INFO:SubProcess create_model() called ==================================
2024-09-06 18:13:46,424:INFO:Initializing create_model()
2024-09-06 18:13:46,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:13:46,424:INFO:Checking exceptions
2024-09-06 18:13:46,424:INFO:Importing libraries
2024-09-06 18:13:46,424:INFO:Copying training dataset
2024-09-06 18:13:46,803:INFO:Defining folds
2024-09-06 18:13:46,804:INFO:Declaring metric variables
2024-09-06 18:13:46,808:INFO:Importing untrained model
2024-09-06 18:13:46,812:INFO:Decision Tree Classifier Imported successfully
2024-09-06 18:13:46,819:INFO:Starting cross validation
2024-09-06 18:13:46,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:14:15,025:INFO:Calculating mean and std
2024-09-06 18:14:15,026:INFO:Creating metrics dataframe
2024-09-06 18:14:15,028:INFO:Uploading results into container
2024-09-06 18:14:15,028:INFO:Uploading model into container now
2024-09-06 18:14:15,029:INFO:_master_model_container: 4
2024-09-06 18:14:15,029:INFO:_display_container: 2
2024-09-06 18:14:15,029:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-06 18:14:15,029:INFO:create_model() successfully completed......................................
2024-09-06 18:14:15,106:INFO:SubProcess create_model() end ==================================
2024-09-06 18:14:15,107:INFO:Creating metrics dataframe
2024-09-06 18:14:15,115:INFO:Initializing SVM - Linear Kernel
2024-09-06 18:14:15,115:INFO:Total runtime is 2.726483968893687 minutes
2024-09-06 18:14:15,118:INFO:SubProcess create_model() called ==================================
2024-09-06 18:14:15,118:INFO:Initializing create_model()
2024-09-06 18:14:15,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:14:15,119:INFO:Checking exceptions
2024-09-06 18:14:15,119:INFO:Importing libraries
2024-09-06 18:14:15,119:INFO:Copying training dataset
2024-09-06 18:14:15,515:INFO:Defining folds
2024-09-06 18:14:15,515:INFO:Declaring metric variables
2024-09-06 18:14:15,519:INFO:Importing untrained model
2024-09-06 18:14:15,523:INFO:SVM - Linear Kernel Imported successfully
2024-09-06 18:14:15,531:INFO:Starting cross validation
2024-09-06 18:14:15,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:14:35,279:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:35,588:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:36,822:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:36,836:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:37,111:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:37,632:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:37,635:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:37,643:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:38,569:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:38,584:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:38,616:INFO:Calculating mean and std
2024-09-06 18:14:38,618:INFO:Creating metrics dataframe
2024-09-06 18:14:38,620:INFO:Uploading results into container
2024-09-06 18:14:38,621:INFO:Uploading model into container now
2024-09-06 18:14:38,621:INFO:_master_model_container: 5
2024-09-06 18:14:38,621:INFO:_display_container: 2
2024-09-06 18:14:38,622:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-06 18:14:38,622:INFO:create_model() successfully completed......................................
2024-09-06 18:14:38,699:INFO:SubProcess create_model() end ==================================
2024-09-06 18:14:38,699:INFO:Creating metrics dataframe
2024-09-06 18:14:38,709:INFO:Initializing Ridge Classifier
2024-09-06 18:14:38,709:INFO:Total runtime is 3.1197199980417887 minutes
2024-09-06 18:14:38,713:INFO:SubProcess create_model() called ==================================
2024-09-06 18:14:38,713:INFO:Initializing create_model()
2024-09-06 18:14:38,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:14:38,713:INFO:Checking exceptions
2024-09-06 18:14:38,713:INFO:Importing libraries
2024-09-06 18:14:38,713:INFO:Copying training dataset
2024-09-06 18:14:39,082:INFO:Defining folds
2024-09-06 18:14:39,082:INFO:Declaring metric variables
2024-09-06 18:14:39,086:INFO:Importing untrained model
2024-09-06 18:14:39,090:INFO:Ridge Classifier Imported successfully
2024-09-06 18:14:39,098:INFO:Starting cross validation
2024-09-06 18:14:39,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:14:49,134:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:49,247:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:49,485:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:49,588:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:49,790:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:50,109:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:50,214:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:50,218:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:50,439:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:50,595:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:14:50,615:INFO:Calculating mean and std
2024-09-06 18:14:50,616:INFO:Creating metrics dataframe
2024-09-06 18:14:50,619:INFO:Uploading results into container
2024-09-06 18:14:50,620:INFO:Uploading model into container now
2024-09-06 18:14:50,620:INFO:_master_model_container: 6
2024-09-06 18:14:50,620:INFO:_display_container: 2
2024-09-06 18:14:50,620:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-06 18:14:50,621:INFO:create_model() successfully completed......................................
2024-09-06 18:14:50,692:INFO:SubProcess create_model() end ==================================
2024-09-06 18:14:50,692:INFO:Creating metrics dataframe
2024-09-06 18:14:50,702:INFO:Initializing Random Forest Classifier
2024-09-06 18:14:50,702:INFO:Total runtime is 3.319602564970652 minutes
2024-09-06 18:14:50,705:INFO:SubProcess create_model() called ==================================
2024-09-06 18:14:50,706:INFO:Initializing create_model()
2024-09-06 18:14:50,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:14:50,706:INFO:Checking exceptions
2024-09-06 18:14:50,706:INFO:Importing libraries
2024-09-06 18:14:50,706:INFO:Copying training dataset
2024-09-06 18:14:51,070:INFO:Defining folds
2024-09-06 18:14:51,070:INFO:Declaring metric variables
2024-09-06 18:14:51,074:INFO:Importing untrained model
2024-09-06 18:14:51,079:INFO:Random Forest Classifier Imported successfully
2024-09-06 18:14:51,086:INFO:Starting cross validation
2024-09-06 18:14:51,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:16:00,443:INFO:Calculating mean and std
2024-09-06 18:16:00,444:INFO:Creating metrics dataframe
2024-09-06 18:16:00,447:INFO:Uploading results into container
2024-09-06 18:16:00,448:INFO:Uploading model into container now
2024-09-06 18:16:00,448:INFO:_master_model_container: 7
2024-09-06 18:16:00,448:INFO:_display_container: 2
2024-09-06 18:16:00,449:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-06 18:16:00,449:INFO:create_model() successfully completed......................................
2024-09-06 18:16:00,547:INFO:SubProcess create_model() end ==================================
2024-09-06 18:16:00,547:INFO:Creating metrics dataframe
2024-09-06 18:16:00,558:INFO:Initializing Quadratic Discriminant Analysis
2024-09-06 18:16:00,559:INFO:Total runtime is 4.4838973363240555 minutes
2024-09-06 18:16:00,563:INFO:SubProcess create_model() called ==================================
2024-09-06 18:16:00,564:INFO:Initializing create_model()
2024-09-06 18:16:00,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:16:00,564:INFO:Checking exceptions
2024-09-06 18:16:00,565:INFO:Importing libraries
2024-09-06 18:16:00,565:INFO:Copying training dataset
2024-09-06 18:16:01,029:INFO:Defining folds
2024-09-06 18:16:01,029:INFO:Declaring metric variables
2024-09-06 18:16:01,033:INFO:Importing untrained model
2024-09-06 18:16:01,039:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-06 18:16:01,049:INFO:Starting cross validation
2024-09-06 18:16:01,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:16:11,675:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:12,219:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:12,832:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:13,529:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:13,796:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:14,934:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:15,690:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:16,353:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:16,406:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:16,883:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:16,896:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:17,238:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 18:16:17,860:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:18,358:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:18,431:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:19,050:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:19,375:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:19,438:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:19,584:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:19,628:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:16:19,648:INFO:Calculating mean and std
2024-09-06 18:16:19,649:INFO:Creating metrics dataframe
2024-09-06 18:16:19,651:INFO:Uploading results into container
2024-09-06 18:16:19,652:INFO:Uploading model into container now
2024-09-06 18:16:19,652:INFO:_master_model_container: 8
2024-09-06 18:16:19,653:INFO:_display_container: 2
2024-09-06 18:16:19,653:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-06 18:16:19,653:INFO:create_model() successfully completed......................................
2024-09-06 18:16:19,731:INFO:SubProcess create_model() end ==================================
2024-09-06 18:16:19,731:INFO:Creating metrics dataframe
2024-09-06 18:16:19,740:INFO:Initializing Ada Boost Classifier
2024-09-06 18:16:19,740:INFO:Total runtime is 4.8035753726959225 minutes
2024-09-06 18:16:19,744:INFO:SubProcess create_model() called ==================================
2024-09-06 18:16:19,744:INFO:Initializing create_model()
2024-09-06 18:16:19,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:16:19,744:INFO:Checking exceptions
2024-09-06 18:16:19,744:INFO:Importing libraries
2024-09-06 18:16:19,745:INFO:Copying training dataset
2024-09-06 18:16:20,122:INFO:Defining folds
2024-09-06 18:16:20,122:INFO:Declaring metric variables
2024-09-06 18:16:20,125:INFO:Importing untrained model
2024-09-06 18:16:20,130:INFO:Ada Boost Classifier Imported successfully
2024-09-06 18:16:20,137:INFO:Starting cross validation
2024-09-06 18:16:20,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:16:29,646:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:16:29,800:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:16:30,225:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:16:30,637:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:16:30,660:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:16:31,209:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:16:31,347:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:16:31,402:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:16:31,901:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:16:31,984:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 18:17:15,146:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:15,528:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:15,838:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:16,038:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:16,116:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:16,236:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:16,271:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:16,772:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:16,886:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:19,905:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:17:19,931:INFO:Calculating mean and std
2024-09-06 18:17:19,932:INFO:Creating metrics dataframe
2024-09-06 18:17:19,934:INFO:Uploading results into container
2024-09-06 18:17:19,935:INFO:Uploading model into container now
2024-09-06 18:17:19,935:INFO:_master_model_container: 9
2024-09-06 18:17:19,936:INFO:_display_container: 2
2024-09-06 18:17:19,936:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-06 18:17:19,936:INFO:create_model() successfully completed......................................
2024-09-06 18:17:20,013:INFO:SubProcess create_model() end ==================================
2024-09-06 18:17:20,013:INFO:Creating metrics dataframe
2024-09-06 18:17:20,022:INFO:Initializing Gradient Boosting Classifier
2024-09-06 18:17:20,022:INFO:Total runtime is 5.808278584480285 minutes
2024-09-06 18:17:20,025:INFO:SubProcess create_model() called ==================================
2024-09-06 18:17:20,025:INFO:Initializing create_model()
2024-09-06 18:17:20,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:17:20,025:INFO:Checking exceptions
2024-09-06 18:17:20,025:INFO:Importing libraries
2024-09-06 18:17:20,025:INFO:Copying training dataset
2024-09-06 18:17:20,392:INFO:Defining folds
2024-09-06 18:17:20,392:INFO:Declaring metric variables
2024-09-06 18:17:20,396:INFO:Importing untrained model
2024-09-06 18:17:20,400:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 18:17:20,409:INFO:Starting cross validation
2024-09-06 18:17:20,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:27:45,710:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:45,745:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:45,832:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:46,346:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:46,844:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:47,013:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:47,216:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:47,693:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:48,305:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:48,413:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:27:48,440:INFO:Calculating mean and std
2024-09-06 18:27:48,441:INFO:Creating metrics dataframe
2024-09-06 18:27:48,444:INFO:Uploading results into container
2024-09-06 18:27:48,444:INFO:Uploading model into container now
2024-09-06 18:27:48,445:INFO:_master_model_container: 10
2024-09-06 18:27:48,445:INFO:_display_container: 2
2024-09-06 18:27:48,446:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 18:27:48,446:INFO:create_model() successfully completed......................................
2024-09-06 18:27:48,517:INFO:SubProcess create_model() end ==================================
2024-09-06 18:27:48,517:INFO:Creating metrics dataframe
2024-09-06 18:27:48,525:INFO:Initializing Linear Discriminant Analysis
2024-09-06 18:27:48,525:INFO:Total runtime is 16.28332562446594 minutes
2024-09-06 18:27:48,529:INFO:SubProcess create_model() called ==================================
2024-09-06 18:27:48,529:INFO:Initializing create_model()
2024-09-06 18:27:48,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:27:48,529:INFO:Checking exceptions
2024-09-06 18:27:48,530:INFO:Importing libraries
2024-09-06 18:27:48,530:INFO:Copying training dataset
2024-09-06 18:27:48,900:INFO:Defining folds
2024-09-06 18:27:48,900:INFO:Declaring metric variables
2024-09-06 18:27:48,905:INFO:Importing untrained model
2024-09-06 18:27:48,909:INFO:Linear Discriminant Analysis Imported successfully
2024-09-06 18:27:48,915:INFO:Starting cross validation
2024-09-06 18:27:48,919:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:28:00,664:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:01,539:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:01,755:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:03,598:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:03,719:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:04,028:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:04,321:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:04,529:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:04,559:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:04,609:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:28:04,636:INFO:Calculating mean and std
2024-09-06 18:28:04,637:INFO:Creating metrics dataframe
2024-09-06 18:28:04,639:INFO:Uploading results into container
2024-09-06 18:28:04,640:INFO:Uploading model into container now
2024-09-06 18:28:04,640:INFO:_master_model_container: 11
2024-09-06 18:28:04,640:INFO:_display_container: 2
2024-09-06 18:28:04,641:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-06 18:28:04,641:INFO:create_model() successfully completed......................................
2024-09-06 18:28:04,713:INFO:SubProcess create_model() end ==================================
2024-09-06 18:28:04,714:INFO:Creating metrics dataframe
2024-09-06 18:28:04,723:INFO:Initializing Extra Trees Classifier
2024-09-06 18:28:04,723:INFO:Total runtime is 16.553290037314095 minutes
2024-09-06 18:28:04,726:INFO:SubProcess create_model() called ==================================
2024-09-06 18:28:04,727:INFO:Initializing create_model()
2024-09-06 18:28:04,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:28:04,727:INFO:Checking exceptions
2024-09-06 18:28:04,727:INFO:Importing libraries
2024-09-06 18:28:04,727:INFO:Copying training dataset
2024-09-06 18:28:05,122:INFO:Defining folds
2024-09-06 18:28:05,122:INFO:Declaring metric variables
2024-09-06 18:28:05,125:INFO:Importing untrained model
2024-09-06 18:28:05,129:INFO:Extra Trees Classifier Imported successfully
2024-09-06 18:28:05,137:INFO:Starting cross validation
2024-09-06 18:28:05,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:29:14,076:INFO:Calculating mean and std
2024-09-06 18:29:14,077:INFO:Creating metrics dataframe
2024-09-06 18:29:14,080:INFO:Uploading results into container
2024-09-06 18:29:14,080:INFO:Uploading model into container now
2024-09-06 18:29:14,081:INFO:_master_model_container: 12
2024-09-06 18:29:14,081:INFO:_display_container: 2
2024-09-06 18:29:14,082:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-06 18:29:14,082:INFO:create_model() successfully completed......................................
2024-09-06 18:29:14,172:INFO:SubProcess create_model() end ==================================
2024-09-06 18:29:14,172:INFO:Creating metrics dataframe
2024-09-06 18:29:14,182:INFO:Initializing Extreme Gradient Boosting
2024-09-06 18:29:14,182:INFO:Total runtime is 17.710943567752835 minutes
2024-09-06 18:29:14,186:INFO:SubProcess create_model() called ==================================
2024-09-06 18:29:14,186:INFO:Initializing create_model()
2024-09-06 18:29:14,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:29:14,187:INFO:Checking exceptions
2024-09-06 18:29:14,187:INFO:Importing libraries
2024-09-06 18:29:14,187:INFO:Copying training dataset
2024-09-06 18:29:14,626:INFO:Defining folds
2024-09-06 18:29:14,626:INFO:Declaring metric variables
2024-09-06 18:29:14,630:INFO:Importing untrained model
2024-09-06 18:29:14,637:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 18:29:14,645:INFO:Starting cross validation
2024-09-06 18:29:14,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:30:10,162:INFO:Calculating mean and std
2024-09-06 18:30:10,163:INFO:Creating metrics dataframe
2024-09-06 18:30:10,166:INFO:Uploading results into container
2024-09-06 18:30:10,166:INFO:Uploading model into container now
2024-09-06 18:30:10,167:INFO:_master_model_container: 13
2024-09-06 18:30:10,167:INFO:_display_container: 2
2024-09-06 18:30:10,167:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-06 18:30:10,168:INFO:create_model() successfully completed......................................
2024-09-06 18:30:10,240:INFO:SubProcess create_model() end ==================================
2024-09-06 18:30:10,240:INFO:Creating metrics dataframe
2024-09-06 18:30:10,251:INFO:Initializing Light Gradient Boosting Machine
2024-09-06 18:30:10,251:INFO:Total runtime is 18.645425951480863 minutes
2024-09-06 18:30:10,255:INFO:SubProcess create_model() called ==================================
2024-09-06 18:30:10,255:INFO:Initializing create_model()
2024-09-06 18:30:10,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:30:10,256:INFO:Checking exceptions
2024-09-06 18:30:10,256:INFO:Importing libraries
2024-09-06 18:30:10,256:INFO:Copying training dataset
2024-09-06 18:30:10,613:INFO:Defining folds
2024-09-06 18:30:10,613:INFO:Declaring metric variables
2024-09-06 18:30:10,616:INFO:Importing untrained model
2024-09-06 18:30:10,620:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 18:30:10,629:INFO:Starting cross validation
2024-09-06 18:30:10,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:31:26,750:INFO:Calculating mean and std
2024-09-06 18:31:26,752:INFO:Creating metrics dataframe
2024-09-06 18:31:26,755:INFO:Uploading results into container
2024-09-06 18:31:26,756:INFO:Uploading model into container now
2024-09-06 18:31:26,756:INFO:_master_model_container: 14
2024-09-06 18:31:26,757:INFO:_display_container: 2
2024-09-06 18:31:26,757:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 18:31:26,757:INFO:create_model() successfully completed......................................
2024-09-06 18:31:26,883:INFO:SubProcess create_model() end ==================================
2024-09-06 18:31:26,883:INFO:Creating metrics dataframe
2024-09-06 18:31:26,895:INFO:Initializing Dummy Classifier
2024-09-06 18:31:26,895:INFO:Total runtime is 19.922830021381376 minutes
2024-09-06 18:31:26,899:INFO:SubProcess create_model() called ==================================
2024-09-06 18:31:26,900:INFO:Initializing create_model()
2024-09-06 18:31:26,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A2F8E7A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:31:26,900:INFO:Checking exceptions
2024-09-06 18:31:26,901:INFO:Importing libraries
2024-09-06 18:31:26,901:INFO:Copying training dataset
2024-09-06 18:31:27,359:INFO:Defining folds
2024-09-06 18:31:27,359:INFO:Declaring metric variables
2024-09-06 18:31:27,365:INFO:Importing untrained model
2024-09-06 18:31:27,370:INFO:Dummy Classifier Imported successfully
2024-09-06 18:31:27,378:INFO:Starting cross validation
2024-09-06 18:31:27,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:31:36,977:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:37,180:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:37,601:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:37,880:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:38,006:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:38,255:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:38,486:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:38,614:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:38,634:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:38,745:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 18:31:38,759:INFO:Calculating mean and std
2024-09-06 18:31:38,760:INFO:Creating metrics dataframe
2024-09-06 18:31:38,763:INFO:Uploading results into container
2024-09-06 18:31:38,763:INFO:Uploading model into container now
2024-09-06 18:31:38,763:INFO:_master_model_container: 15
2024-09-06 18:31:38,763:INFO:_display_container: 2
2024-09-06 18:31:38,763:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-06 18:31:38,764:INFO:create_model() successfully completed......................................
2024-09-06 18:31:38,832:INFO:SubProcess create_model() end ==================================
2024-09-06 18:31:38,832:INFO:Creating metrics dataframe
2024-09-06 18:31:38,851:INFO:Initializing create_model()
2024-09-06 18:31:38,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:31:38,852:INFO:Checking exceptions
2024-09-06 18:31:38,853:INFO:Importing libraries
2024-09-06 18:31:38,853:INFO:Copying training dataset
2024-09-06 18:31:39,236:INFO:Defining folds
2024-09-06 18:31:39,236:INFO:Declaring metric variables
2024-09-06 18:31:39,237:INFO:Importing untrained model
2024-09-06 18:31:39,237:INFO:Declaring custom model
2024-09-06 18:31:39,238:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 18:31:39,241:INFO:Cross validation set to False
2024-09-06 18:31:39,241:INFO:Fitting Model
2024-09-06 18:31:41,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063468 seconds.
2024-09-06 18:31:41,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 18:31:41,887:INFO:[LightGBM] [Info] Total Bins 60521
2024-09-06 18:31:41,891:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 258
2024-09-06 18:31:41,893:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 18:31:41,893:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 18:31:41,893:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 18:31:46,712:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 18:31:46,712:INFO:create_model() successfully completed......................................
2024-09-06 18:31:46,823:INFO:_master_model_container: 15
2024-09-06 18:31:46,823:INFO:_display_container: 2
2024-09-06 18:31:46,824:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 18:31:46,824:INFO:compare_models() successfully completed......................................
2024-09-06 18:34:35,234:INFO:Initializing create_model()
2024-09-06 18:34:35,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:34:35,234:INFO:Checking exceptions
2024-09-06 18:34:35,250:INFO:Importing libraries
2024-09-06 18:34:35,250:INFO:Copying training dataset
2024-09-06 18:34:35,604:INFO:Defining folds
2024-09-06 18:34:35,604:INFO:Declaring metric variables
2024-09-06 18:34:35,607:INFO:Importing untrained model
2024-09-06 18:34:35,610:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 18:34:35,619:INFO:Starting cross validation
2024-09-06 18:34:35,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:36:00,503:INFO:Calculating mean and std
2024-09-06 18:36:00,506:INFO:Creating metrics dataframe
2024-09-06 18:36:00,514:INFO:Finalizing model
2024-09-06 18:36:03,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070877 seconds.
2024-09-06 18:36:03,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 18:36:03,328:INFO:[LightGBM] [Info] Total Bins 60521
2024-09-06 18:36:03,332:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 258
2024-09-06 18:36:03,334:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 18:36:03,334:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 18:36:03,334:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 18:36:07,617:INFO:Uploading results into container
2024-09-06 18:36:07,617:INFO:Uploading model into container now
2024-09-06 18:36:07,631:INFO:_master_model_container: 16
2024-09-06 18:36:07,632:INFO:_display_container: 3
2024-09-06 18:36:07,632:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 18:36:07,632:INFO:create_model() successfully completed......................................
2024-09-06 18:36:32,516:INFO:Initializing predict_model()
2024-09-06 18:36:32,516:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A3ED704C0>)
2024-09-06 18:36:32,516:INFO:Checking exceptions
2024-09-06 18:36:32,516:INFO:Preloading libraries
2024-09-06 18:36:32,520:INFO:Set up data.
2024-09-06 18:36:32,652:INFO:Set up index.
2024-09-06 18:36:33,143:INFO:Initializing get_config()
2024-09-06 18:36:33,144:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, variable=X_train)
2024-09-06 18:36:33,144:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 18:36:33,280:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.216109  -0.037036  -0.621245  -0.162261  -0.527968   
41786   1.144238   0.066573  -2.020844   0.247705  -0.162261  -0.527968   
53345  -0.499730  -1.127987  -0.554897  -0.476420  -0.162261  -0.527968   
11745  -0.742247  -0.854424  -0.969187  -0.331595  -0.162261  -0.527968   
23494   0.829220   3.249027   2.839088  -0.621245  -0.162261   0.064610   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893   1.516459   1.126161  -0.621245  -0.162261   1.249768   
38857  -1.387282  -2.039865  -1.502983   2.275255  -0.162261   0.064610   
31149   0.765373  -0.033734   0.560497  -0.476420  -0.162261   0.064610   
55353   0.715438  -0.216109   0.608300  -0.186770  -0.162261   0.064610   
1638   -0.827527  -0.854424  -0.825779  -0.041945  -0.162261   0.064610   

       feature_6  feature_7  feature_8  feature_9  ...  feature_248  \
71710   0.751803  -0.065075   0.287760  -0.142716  ...    -0.086278   
41786   1.885756  -1.548440  -1.893514  -0.142716  ...    -0.086278   
53345   1.035291  -0.065075   0.192922  -0.142716  ...    -0.086278   
11745   0.184827  -0.435916   0.256147  -0.142716  ...     6.167595   
23494  -2.083079  -1.548440  -1.893514  -0.142716  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374   0.184827   1.047449   1.008529  -0.142716  ...    -0.086278   
38857   2.452733  -1.177599   0.003246  -0.142716  ...    -0.086278   
31149  -0.098661   0.676608   0.463888  -0.142716  ...    -0.086278   
55353  -0.382150   0.676608   0.572274  -0.142716  ...    -0.086278   
1638    1.318780  -1.548440  -1.893514  -0.142716  ...    -0.086278   

       feature_249  feature_250  feature_251  feature_252  feature_253  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_254  feature_255  feature_256  feature_257  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 258 columns]
2024-09-06 18:36:33,280:INFO:get_config() successfully completed......................................
2024-09-06 18:36:33,280:INFO:Initializing predict_model()
2024-09-06 18:36:33,281:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A3C2CC160>)
2024-09-06 18:36:33,281:INFO:Checking exceptions
2024-09-06 18:36:33,281:INFO:Preloading libraries
2024-09-06 18:36:33,283:INFO:Set up data.
2024-09-06 18:36:33,407:INFO:Set up index.
2024-09-06 18:36:34,376:INFO:Initializing get_config()
2024-09-06 18:36:34,376:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, variable=y_train)
2024-09-06 18:36:34,376:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 18:36:34,467:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 18:36:34,467:INFO:get_config() successfully completed......................................
2024-09-06 18:36:34,467:INFO:Initializing get_config()
2024-09-06 18:36:34,467:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, variable=y_test)
2024-09-06 18:36:34,468:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 18:36:34,533:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 18:36:34,533:INFO:get_config() successfully completed......................................
2024-09-06 18:36:34,538:INFO:Initializing finalize_model()
2024-09-06 18:36:34,538:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 18:36:34,538:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 18:36:34,780:INFO:Initializing create_model()
2024-09-06 18:36:34,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:36:34,780:INFO:Checking exceptions
2024-09-06 18:36:34,781:INFO:Importing libraries
2024-09-06 18:36:34,781:INFO:Copying training dataset
2024-09-06 18:36:34,822:INFO:Defining folds
2024-09-06 18:36:34,822:INFO:Declaring metric variables
2024-09-06 18:36:34,822:INFO:Importing untrained model
2024-09-06 18:36:34,822:INFO:Declaring custom model
2024-09-06 18:36:34,823:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 18:36:34,828:INFO:Cross validation set to False
2024-09-06 18:36:34,828:INFO:Fitting Model
2024-09-06 18:36:39,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094944 seconds.
2024-09-06 18:36:39,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 18:36:39,371:INFO:[LightGBM] [Info] Total Bins 61687
2024-09-06 18:36:39,373:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 258
2024-09-06 18:36:39,375:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 18:36:39,376:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 18:36:39,376:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 18:36:45,020:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 18:36:45,020:INFO:create_model() successfully completed......................................
2024-09-06 18:36:45,119:INFO:_master_model_container: 16
2024-09-06 18:36:45,119:INFO:_display_container: 4
2024-09-06 18:36:45,130:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 18:36:45,130:INFO:finalize_model() successfully completed......................................
2024-09-06 18:36:45,213:INFO:Initializing predict_model()
2024-09-06 18:36:45,213:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A3C2CC0D0>)
2024-09-06 18:36:45,213:INFO:Checking exceptions
2024-09-06 18:36:45,213:INFO:Preloading libraries
2024-09-06 18:36:45,215:INFO:Set up data.
2024-09-06 18:36:45,327:INFO:Set up index.
2024-09-06 18:39:34,213:INFO:Initializing create_model()
2024-09-06 18:39:34,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:39:34,214:INFO:Checking exceptions
2024-09-06 18:39:34,231:INFO:Importing libraries
2024-09-06 18:39:34,231:INFO:Copying training dataset
2024-09-06 18:39:34,590:INFO:Defining folds
2024-09-06 18:39:34,591:INFO:Declaring metric variables
2024-09-06 18:39:34,594:INFO:Importing untrained model
2024-09-06 18:39:34,597:INFO:Random Forest Classifier Imported successfully
2024-09-06 18:39:34,604:INFO:Starting cross validation
2024-09-06 18:39:34,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:40:43,786:INFO:Calculating mean and std
2024-09-06 18:40:43,788:INFO:Creating metrics dataframe
2024-09-06 18:40:43,794:INFO:Finalizing model
2024-09-06 18:40:52,983:INFO:Uploading results into container
2024-09-06 18:40:52,984:INFO:Uploading model into container now
2024-09-06 18:40:52,994:INFO:_master_model_container: 17
2024-09-06 18:40:52,994:INFO:_display_container: 6
2024-09-06 18:40:52,995:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-06 18:40:52,995:INFO:create_model() successfully completed......................................
2024-09-06 18:41:14,688:INFO:Initializing predict_model()
2024-09-06 18:41:14,688:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A3C2CC0D0>)
2024-09-06 18:41:14,689:INFO:Checking exceptions
2024-09-06 18:41:14,689:INFO:Preloading libraries
2024-09-06 18:41:14,690:INFO:Set up data.
2024-09-06 18:41:14,804:INFO:Set up index.
2024-09-06 18:41:15,434:INFO:Initializing get_config()
2024-09-06 18:41:15,434:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, variable=X_train)
2024-09-06 18:41:15,434:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 18:41:15,575:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.216109  -0.037036  -0.621245  -0.162261  -0.527968   
41786   1.144238   0.066573  -2.020844   0.247705  -0.162261  -0.527968   
53345  -0.499730  -1.127987  -0.554897  -0.476420  -0.162261  -0.527968   
11745  -0.742247  -0.854424  -0.969187  -0.331595  -0.162261  -0.527968   
23494   0.829220   3.249027   2.839088  -0.621245  -0.162261   0.064610   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893   1.516459   1.126161  -0.621245  -0.162261   1.249768   
38857  -1.387282  -2.039865  -1.502983   2.275255  -0.162261   0.064610   
31149   0.765373  -0.033734   0.560497  -0.476420  -0.162261   0.064610   
55353   0.715438  -0.216109   0.608300  -0.186770  -0.162261   0.064610   
1638   -0.827527  -0.854424  -0.825779  -0.041945  -0.162261   0.064610   

       feature_6  feature_7  feature_8  feature_9  ...  feature_248  \
71710   0.751803  -0.065075   0.287760  -0.142716  ...    -0.086278   
41786   1.885756  -1.548440  -1.893514  -0.142716  ...    -0.086278   
53345   1.035291  -0.065075   0.192922  -0.142716  ...    -0.086278   
11745   0.184827  -0.435916   0.256147  -0.142716  ...     6.167595   
23494  -2.083079  -1.548440  -1.893514  -0.142716  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374   0.184827   1.047449   1.008529  -0.142716  ...    -0.086278   
38857   2.452733  -1.177599   0.003246  -0.142716  ...    -0.086278   
31149  -0.098661   0.676608   0.463888  -0.142716  ...    -0.086278   
55353  -0.382150   0.676608   0.572274  -0.142716  ...    -0.086278   
1638    1.318780  -1.548440  -1.893514  -0.142716  ...    -0.086278   

       feature_249  feature_250  feature_251  feature_252  feature_253  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_254  feature_255  feature_256  feature_257  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 258 columns]
2024-09-06 18:41:15,575:INFO:get_config() successfully completed......................................
2024-09-06 18:41:15,576:INFO:Initializing predict_model()
2024-09-06 18:41:15,576:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A3C280CA0>)
2024-09-06 18:41:15,576:INFO:Checking exceptions
2024-09-06 18:41:15,576:INFO:Preloading libraries
2024-09-06 18:41:15,578:INFO:Set up data.
2024-09-06 18:41:15,705:INFO:Set up index.
2024-09-06 18:41:16,429:INFO:Initializing get_config()
2024-09-06 18:41:16,429:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, variable=y_train)
2024-09-06 18:41:16,429:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 18:41:16,552:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 18:41:16,552:INFO:get_config() successfully completed......................................
2024-09-06 18:41:16,553:INFO:Initializing get_config()
2024-09-06 18:41:16,553:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, variable=y_test)
2024-09-06 18:41:16,553:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 18:41:16,620:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 18:41:16,620:INFO:get_config() successfully completed......................................
2024-09-06 18:41:16,624:INFO:Initializing finalize_model()
2024-09-06 18:41:16,624:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 18:41:16,625:INFO:Finalizing RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-06 18:41:16,868:INFO:Initializing create_model()
2024-09-06 18:41:16,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:41:16,869:INFO:Checking exceptions
2024-09-06 18:41:16,870:INFO:Importing libraries
2024-09-06 18:41:16,870:INFO:Copying training dataset
2024-09-06 18:41:16,912:INFO:Defining folds
2024-09-06 18:41:16,912:INFO:Declaring metric variables
2024-09-06 18:41:16,912:INFO:Importing untrained model
2024-09-06 18:41:16,912:INFO:Declaring custom model
2024-09-06 18:41:16,913:INFO:Random Forest Classifier Imported successfully
2024-09-06 18:41:16,917:INFO:Cross validation set to False
2024-09-06 18:41:16,917:INFO:Fitting Model
2024-09-06 18:41:30,669:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-09-06 18:41:30,670:INFO:create_model() successfully completed......................................
2024-09-06 18:41:30,747:INFO:_master_model_container: 17
2024-09-06 18:41:30,748:INFO:_display_container: 7
2024-09-06 18:41:30,756:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-09-06 18:41:30,756:INFO:finalize_model() successfully completed......................................
2024-09-06 18:41:30,840:INFO:Initializing predict_model()
2024-09-06 18:41:30,840:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A3C280CA0>)
2024-09-06 18:41:30,840:INFO:Checking exceptions
2024-09-06 18:41:30,840:INFO:Preloading libraries
2024-09-06 18:41:30,842:INFO:Set up data.
2024-09-06 18:41:30,968:INFO:Set up index.
2024-09-06 18:42:19,182:INFO:Initializing create_model()
2024-09-06 18:42:19,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 18:42:19,183:INFO:Checking exceptions
2024-09-06 18:42:19,201:INFO:Importing libraries
2024-09-06 18:42:19,202:INFO:Copying training dataset
2024-09-06 18:42:19,558:INFO:Defining folds
2024-09-06 18:42:19,558:INFO:Declaring metric variables
2024-09-06 18:42:19,561:INFO:Importing untrained model
2024-09-06 18:42:19,564:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 18:42:19,571:INFO:Starting cross validation
2024-09-06 18:42:19,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 18:52:39,651:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:40,461:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:40,598:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:41,202:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:41,308:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:41,362:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:41,570:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:41,660:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:41,739:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:42,743:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 18:52:42,770:INFO:Calculating mean and std
2024-09-06 18:52:42,771:INFO:Creating metrics dataframe
2024-09-06 18:52:42,778:INFO:Finalizing model
2024-09-06 19:01:18,220:INFO:Uploading results into container
2024-09-06 19:01:18,220:INFO:Uploading model into container now
2024-09-06 19:01:18,232:INFO:_master_model_container: 18
2024-09-06 19:01:18,232:INFO:_display_container: 9
2024-09-06 19:01:18,233:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 19:01:18,233:INFO:create_model() successfully completed......................................
2024-09-06 19:01:20,862:INFO:Initializing predict_model()
2024-09-06 19:01:20,862:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A3ED71D80>)
2024-09-06 19:01:20,863:INFO:Checking exceptions
2024-09-06 19:01:20,863:INFO:Preloading libraries
2024-09-06 19:01:20,865:INFO:Set up data.
2024-09-06 19:01:20,984:INFO:Set up index.
2024-09-06 19:01:21,706:INFO:Initializing get_config()
2024-09-06 19:01:21,706:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, variable=X_train)
2024-09-06 19:01:21,707:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 19:01:21,863:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.216109  -0.037036  -0.621245  -0.162261  -0.527968   
41786   1.144238   0.066573  -2.020844   0.247705  -0.162261  -0.527968   
53345  -0.499730  -1.127987  -0.554897  -0.476420  -0.162261  -0.527968   
11745  -0.742247  -0.854424  -0.969187  -0.331595  -0.162261  -0.527968   
23494   0.829220   3.249027   2.839088  -0.621245  -0.162261   0.064610   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893   1.516459   1.126161  -0.621245  -0.162261   1.249768   
38857  -1.387282  -2.039865  -1.502983   2.275255  -0.162261   0.064610   
31149   0.765373  -0.033734   0.560497  -0.476420  -0.162261   0.064610   
55353   0.715438  -0.216109   0.608300  -0.186770  -0.162261   0.064610   
1638   -0.827527  -0.854424  -0.825779  -0.041945  -0.162261   0.064610   

       feature_6  feature_7  feature_8  feature_9  ...  feature_248  \
71710   0.751803  -0.065075   0.287760  -0.142716  ...    -0.086278   
41786   1.885756  -1.548440  -1.893514  -0.142716  ...    -0.086278   
53345   1.035291  -0.065075   0.192922  -0.142716  ...    -0.086278   
11745   0.184827  -0.435916   0.256147  -0.142716  ...     6.167595   
23494  -2.083079  -1.548440  -1.893514  -0.142716  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374   0.184827   1.047449   1.008529  -0.142716  ...    -0.086278   
38857   2.452733  -1.177599   0.003246  -0.142716  ...    -0.086278   
31149  -0.098661   0.676608   0.463888  -0.142716  ...    -0.086278   
55353  -0.382150   0.676608   0.572274  -0.142716  ...    -0.086278   
1638    1.318780  -1.548440  -1.893514  -0.142716  ...    -0.086278   

       feature_249  feature_250  feature_251  feature_252  feature_253  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_254  feature_255  feature_256  feature_257  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 258 columns]
2024-09-06 19:01:21,863:INFO:get_config() successfully completed......................................
2024-09-06 19:01:21,864:INFO:Initializing predict_model()
2024-09-06 19:01:21,864:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A43C1BEB0>)
2024-09-06 19:01:21,864:INFO:Checking exceptions
2024-09-06 19:01:21,864:INFO:Preloading libraries
2024-09-06 19:01:21,866:INFO:Set up data.
2024-09-06 19:01:21,990:INFO:Set up index.
2024-09-06 19:01:23,560:INFO:Initializing get_config()
2024-09-06 19:01:23,560:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, variable=y_train)
2024-09-06 19:01:23,561:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 19:01:23,650:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 19:01:23,650:INFO:get_config() successfully completed......................................
2024-09-06 19:01:23,650:INFO:Initializing get_config()
2024-09-06 19:01:23,650:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, variable=y_test)
2024-09-06 19:01:23,650:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 19:01:23,717:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 19:01:23,717:INFO:get_config() successfully completed......................................
2024-09-06 19:01:23,722:INFO:Initializing finalize_model()
2024-09-06 19:01:23,722:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 19:01:23,722:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 19:01:23,955:INFO:Initializing create_model()
2024-09-06 19:01:23,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A302360B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 19:01:23,955:INFO:Checking exceptions
2024-09-06 19:01:23,956:INFO:Importing libraries
2024-09-06 19:01:23,956:INFO:Copying training dataset
2024-09-06 19:01:23,997:INFO:Defining folds
2024-09-06 19:01:23,998:INFO:Declaring metric variables
2024-09-06 19:01:23,998:INFO:Importing untrained model
2024-09-06 19:01:23,998:INFO:Declaring custom model
2024-09-06 19:01:23,999:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 19:01:24,004:INFO:Cross validation set to False
2024-09-06 19:01:24,004:INFO:Fitting Model
2024-09-06 19:14:19,689:INFO:PyCaret ClassificationExperiment
2024-09-06 19:14:19,689:INFO:Logging name: clf-default-name
2024-09-06 19:14:19,689:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-06 19:14:19,689:INFO:version 3.3.2
2024-09-06 19:14:19,689:INFO:Initializing setup()
2024-09-06 19:14:19,689:INFO:self.USI: af25
2024-09-06 19:14:19,689:INFO:self._variable_keys: {'exp_id', 'fix_imbalance', '_ml_usecase', 'memory', 'logging_param', 'X_test', 'y', 'exp_name_log', 'gpu_param', 'pipeline', 'X', 'target_param', 'y_train', 'y_test', 'is_multiclass', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train', 'fold_groups_param', 'html_param', 'idx', 'log_plots_param', 'data', 'fold_generator', '_available_plots', 'seed'}
2024-09-06 19:14:19,689:INFO:Checking environment
2024-09-06 19:14:19,689:INFO:python_version: 3.10.11
2024-09-06 19:14:19,689:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-06 19:14:19,689:INFO:machine: AMD64
2024-09-06 19:14:19,689:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-06 19:14:19,689:INFO:Memory: svmem(total=17128263680, available=8102957056, percent=52.7, used=9025306624, free=8102957056)
2024-09-06 19:14:19,689:INFO:Physical Core: 6
2024-09-06 19:14:19,689:INFO:Logical Core: 12
2024-09-06 19:14:19,689:INFO:Checking libraries
2024-09-06 19:14:19,690:INFO:System:
2024-09-06 19:14:19,690:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-06 19:14:19,690:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-06 19:14:19,690:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-06 19:14:19,690:INFO:PyCaret required dependencies:
2024-09-06 19:14:19,690:INFO:                 pip: 24.2
2024-09-06 19:14:19,690:INFO:          setuptools: 72.1.0
2024-09-06 19:14:19,690:INFO:             pycaret: 3.3.2
2024-09-06 19:14:19,690:INFO:             IPython: 8.27.0
2024-09-06 19:14:19,690:INFO:          ipywidgets: 8.1.5
2024-09-06 19:14:19,690:INFO:                tqdm: 4.66.5
2024-09-06 19:14:19,690:INFO:               numpy: 1.26.4
2024-09-06 19:14:19,690:INFO:              pandas: 2.2.2
2024-09-06 19:14:19,690:INFO:              jinja2: 3.1.4
2024-09-06 19:14:19,690:INFO:               scipy: 1.11.4
2024-09-06 19:14:19,690:INFO:              joblib: 1.3.2
2024-09-06 19:14:19,690:INFO:             sklearn: 1.4.2
2024-09-06 19:14:19,690:INFO:                pyod: 2.0.1
2024-09-06 19:14:19,690:INFO:            imblearn: 0.12.3
2024-09-06 19:14:19,690:INFO:   category_encoders: 2.6.3
2024-09-06 19:14:19,690:INFO:            lightgbm: 4.5.0
2024-09-06 19:14:19,691:INFO:               numba: 0.60.0
2024-09-06 19:14:19,691:INFO:            requests: 2.32.3
2024-09-06 19:14:19,691:INFO:          matplotlib: 3.7.5
2024-09-06 19:14:19,691:INFO:          scikitplot: 0.3.7
2024-09-06 19:14:19,691:INFO:         yellowbrick: 1.5
2024-09-06 19:14:19,691:INFO:              plotly: 5.24.0
2024-09-06 19:14:19,691:INFO:    plotly-resampler: Not installed
2024-09-06 19:14:19,691:INFO:             kaleido: 0.2.1
2024-09-06 19:14:19,691:INFO:           schemdraw: 0.15
2024-09-06 19:14:19,691:INFO:         statsmodels: 0.14.2
2024-09-06 19:14:19,691:INFO:              sktime: 0.26.0
2024-09-06 19:14:19,691:INFO:               tbats: 1.1.3
2024-09-06 19:14:19,691:INFO:            pmdarima: 2.0.4
2024-09-06 19:14:19,691:INFO:              psutil: 6.0.0
2024-09-06 19:14:19,691:INFO:          markupsafe: 2.1.5
2024-09-06 19:14:19,691:INFO:             pickle5: Not installed
2024-09-06 19:14:19,691:INFO:         cloudpickle: 3.0.0
2024-09-06 19:14:19,691:INFO:         deprecation: 2.1.0
2024-09-06 19:14:19,691:INFO:              xxhash: 3.5.0
2024-09-06 19:14:19,691:INFO:           wurlitzer: Not installed
2024-09-06 19:14:19,691:INFO:PyCaret optional dependencies:
2024-09-06 19:14:19,691:INFO:                shap: Not installed
2024-09-06 19:14:19,691:INFO:           interpret: Not installed
2024-09-06 19:14:19,692:INFO:                umap: Not installed
2024-09-06 19:14:19,692:INFO:     ydata_profiling: Not installed
2024-09-06 19:14:19,692:INFO:  explainerdashboard: Not installed
2024-09-06 19:14:19,692:INFO:             autoviz: Not installed
2024-09-06 19:14:19,692:INFO:           fairlearn: Not installed
2024-09-06 19:14:19,692:INFO:          deepchecks: Not installed
2024-09-06 19:14:19,692:INFO:             xgboost: 2.1.1
2024-09-06 19:14:19,692:INFO:            catboost: Not installed
2024-09-06 19:14:19,692:INFO:              kmodes: Not installed
2024-09-06 19:14:19,692:INFO:             mlxtend: Not installed
2024-09-06 19:14:19,692:INFO:       statsforecast: Not installed
2024-09-06 19:14:19,692:INFO:        tune_sklearn: Not installed
2024-09-06 19:14:19,692:INFO:                 ray: Not installed
2024-09-06 19:14:19,692:INFO:            hyperopt: 0.2.7
2024-09-06 19:14:19,692:INFO:              optuna: 4.0.0
2024-09-06 19:14:19,692:INFO:               skopt: 0.10.2
2024-09-06 19:14:19,692:INFO:              mlflow: Not installed
2024-09-06 19:14:19,692:INFO:              gradio: Not installed
2024-09-06 19:14:19,692:INFO:             fastapi: Not installed
2024-09-06 19:14:19,692:INFO:             uvicorn: Not installed
2024-09-06 19:14:19,692:INFO:              m2cgen: Not installed
2024-09-06 19:14:19,692:INFO:           evidently: Not installed
2024-09-06 19:14:19,692:INFO:               fugue: Not installed
2024-09-06 19:14:19,693:INFO:           streamlit: Not installed
2024-09-06 19:14:19,693:INFO:             prophet: Not installed
2024-09-06 19:14:19,693:INFO:None
2024-09-06 19:14:19,693:INFO:Set up data.
2024-09-06 19:14:19,993:INFO:Set up folding strategy.
2024-09-06 19:14:19,994:INFO:Set up train/test split.
2024-09-06 19:14:20,332:INFO:Set up index.
2024-09-06 19:14:20,337:INFO:Assigning column types.
2024-09-06 19:14:20,761:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-06 19:14:20,810:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 19:14:20,810:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 19:14:20,841:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 19:14:20,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 19:14:20,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 19:14:20,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 19:14:20,926:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 19:14:20,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 19:14:20,930:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-06 19:14:20,979:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 19:14:21,009:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 19:14:21,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 19:14:21,061:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 19:14:21,092:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 19:14:21,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 19:14:21,096:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-06 19:14:21,175:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 19:14:21,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 19:14:21,258:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 19:14:21,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 19:14:21,262:INFO:Preparing preprocessing pipeline...
2024-09-06 19:14:21,314:INFO:Set up simple imputation.
2024-09-06 19:14:21,747:INFO:Finished creating preprocessing pipeline.
2024-09-06 19:14:21,752:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-09-06 19:14:21,752:INFO:Creating final display dataframe.
2024-09-06 19:14:23,302:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 259)
4        Transformed data shape      (76518, 259)
5   Transformed train set shape      (53562, 259)
6    Transformed test set shape      (22956, 259)
7              Numeric features               258
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              af25
2024-09-06 19:14:23,417:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 19:14:23,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 19:14:23,520:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 19:14:23,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 19:14:23,524:INFO:setup() successfully completed in 3.86s...............
2024-09-06 19:14:23,524:INFO:Initializing create_model()
2024-09-06 19:14:23,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 19:14:23,524:INFO:Checking exceptions
2024-09-06 19:14:23,538:INFO:Importing libraries
2024-09-06 19:14:23,538:INFO:Copying training dataset
2024-09-06 19:14:23,909:INFO:Defining folds
2024-09-06 19:14:23,909:INFO:Declaring metric variables
2024-09-06 19:14:23,912:INFO:Importing untrained model
2024-09-06 19:14:23,915:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 19:14:23,922:INFO:Starting cross validation
2024-09-06 19:14:23,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 19:15:04,364:INFO:Calculating mean and std
2024-09-06 19:15:04,365:INFO:Creating metrics dataframe
2024-09-06 19:15:04,375:INFO:Finalizing model
2024-09-06 19:15:05,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055596 seconds.
2024-09-06 19:15:05,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 19:15:05,159:INFO:[LightGBM] [Info] Total Bins 29255
2024-09-06 19:15:05,160:INFO:[LightGBM] [Info] Number of data points in the train set: 53562, number of used features: 257
2024-09-06 19:15:05,162:INFO:[LightGBM] [Info] Start training from score -1.106880
2024-09-06 19:15:05,162:INFO:[LightGBM] [Info] Start training from score -1.633473
2024-09-06 19:15:05,162:INFO:[LightGBM] [Info] Start training from score -0.746209
2024-09-06 19:15:07,674:INFO:Uploading results into container
2024-09-06 19:15:07,674:INFO:Uploading model into container now
2024-09-06 19:15:07,687:INFO:_master_model_container: 1
2024-09-06 19:15:07,687:INFO:_display_container: 2
2024-09-06 19:15:07,688:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 19:15:07,688:INFO:create_model() successfully completed......................................
2024-09-06 19:15:07,817:INFO:Initializing tune_model()
2024-09-06 19:15:07,818:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5], 'num_leaves': [20, 31, 40], 'min_child_samples': [10, 20, 30], 'subsample': [0.7, 0.8, 0.9], 'colsample_bytree': [0.7, 0.8], 'reg_alpha': [0.1, 0.5, 1.0], 'reg_lambda': [0.1, 0.5, 1.0]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=True, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>)
2024-09-06 19:15:07,818:INFO:Checking exceptions
2024-09-06 19:15:07,818:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-06 19:15:08,121:INFO:Copying training dataset
2024-09-06 19:15:08,386:INFO:Checking base model
2024-09-06 19:15:08,386:INFO:Base model : Light Gradient Boosting Machine
2024-09-06 19:15:08,387:INFO:Declaring metric variables
2024-09-06 19:15:08,387:INFO:Defining Hyperparameters
2024-09-06 19:15:08,498:INFO:custom_grid: {'actual_estimator__learning_rate': CategoricalDistribution(values=[0.01, 0.05, 0.1]), 'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 4, 5]), 'actual_estimator__num_leaves': CategoricalDistribution(values=[20, 31, 40]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[10, 20, 30]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.7, 0.8, 0.9]), 'actual_estimator__colsample_bytree': CategoricalDistribution(values=[0.7, 0.8]), 'actual_estimator__reg_alpha': CategoricalDistribution(values=[0.1, 0.5, 1.0]), 'actual_estimator__reg_lambda': CategoricalDistribution(values=[0.1, 0.5, 1.0])}
2024-09-06 19:15:08,499:INFO:Tuning with n_jobs=-1
2024-09-06 19:15:08,503:INFO:Initializing skopt.BayesSearchCV
2024-09-06 19:16:55,781:INFO:best_params: OrderedDict([('actual_estimator__colsample_bytree', 0.8), ('actual_estimator__learning_rate', 0.05), ('actual_estimator__max_depth', 5), ('actual_estimator__min_child_samples', 20), ('actual_estimator__n_estimators', 200), ('actual_estimator__num_leaves', 20), ('actual_estimator__reg_alpha', 0.1), ('actual_estimator__reg_lambda', 0.5), ('actual_estimator__subsample', 0.8)])
2024-09-06 19:16:55,781:INFO:Hyperparameter search completed
2024-09-06 19:16:55,781:INFO:SubProcess create_model() called ==================================
2024-09-06 19:16:55,782:INFO:Initializing create_model()
2024-09-06 19:16:55,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A3BC4F6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_samples': 20, 'n_estimators': 200, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'subsample': 0.8})
2024-09-06 19:16:55,782:INFO:Checking exceptions
2024-09-06 19:16:55,782:INFO:Importing libraries
2024-09-06 19:16:55,782:INFO:Copying training dataset
2024-09-06 19:16:56,223:INFO:Defining folds
2024-09-06 19:16:56,223:INFO:Declaring metric variables
2024-09-06 19:16:56,223:INFO:Importing untrained model
2024-09-06 19:16:56,223:INFO:Declaring custom model
2024-09-06 19:16:56,224:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 19:16:56,224:INFO:Starting cross validation
2024-09-06 19:16:56,226:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 19:17:12,832:INFO:Calculating mean and std
2024-09-06 19:17:12,833:INFO:Creating metrics dataframe
2024-09-06 19:17:12,835:INFO:Finalizing model
2024-09-06 19:17:13,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039591 seconds.
2024-09-06 19:17:13,653:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 19:17:13,654:INFO:[LightGBM] [Info] Total Bins 29255
2024-09-06 19:17:13,654:INFO:[LightGBM] [Info] Number of data points in the train set: 53562, number of used features: 257
2024-09-06 19:17:13,657:INFO:[LightGBM] [Info] Start training from score -1.106880
2024-09-06 19:17:13,657:INFO:[LightGBM] [Info] Start training from score -1.633473
2024-09-06 19:17:13,657:INFO:[LightGBM] [Info] Start training from score -0.746209
2024-09-06 19:17:15,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:15,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:15,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:16,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 19:17:17,006:INFO:Uploading results into container
2024-09-06 19:17:17,007:INFO:Uploading model into container now
2024-09-06 19:17:17,007:INFO:_master_model_container: 2
2024-09-06 19:17:17,007:INFO:_display_container: 3
2024-09-06 19:17:17,008:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 19:17:17,008:INFO:create_model() successfully completed......................................
2024-09-06 19:17:17,139:INFO:SubProcess create_model() end ==================================
2024-09-06 19:17:17,139:INFO:choose_better activated
2024-09-06 19:17:17,139:INFO:SubProcess create_model() called ==================================
2024-09-06 19:17:17,140:INFO:Initializing create_model()
2024-09-06 19:17:17,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 19:17:17,140:INFO:Checking exceptions
2024-09-06 19:17:17,141:INFO:Importing libraries
2024-09-06 19:17:17,141:INFO:Copying training dataset
2024-09-06 19:17:17,507:INFO:Defining folds
2024-09-06 19:17:17,507:INFO:Declaring metric variables
2024-09-06 19:17:17,508:INFO:Importing untrained model
2024-09-06 19:17:17,508:INFO:Declaring custom model
2024-09-06 19:17:17,509:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 19:17:17,509:INFO:Starting cross validation
2024-09-06 19:17:17,510:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 19:17:33,289:INFO:Calculating mean and std
2024-09-06 19:17:33,290:INFO:Creating metrics dataframe
2024-09-06 19:17:33,292:INFO:Finalizing model
2024-09-06 19:17:34,135:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060066 seconds.
2024-09-06 19:17:34,135:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 19:17:34,137:INFO:[LightGBM] [Info] Total Bins 29255
2024-09-06 19:17:34,139:INFO:[LightGBM] [Info] Number of data points in the train set: 53562, number of used features: 257
2024-09-06 19:17:34,140:INFO:[LightGBM] [Info] Start training from score -1.106880
2024-09-06 19:17:34,141:INFO:[LightGBM] [Info] Start training from score -1.633473
2024-09-06 19:17:34,141:INFO:[LightGBM] [Info] Start training from score -0.746209
2024-09-06 19:17:36,995:INFO:Uploading results into container
2024-09-06 19:17:36,996:INFO:Uploading model into container now
2024-09-06 19:17:36,996:INFO:_master_model_container: 3
2024-09-06 19:17:36,996:INFO:_display_container: 4
2024-09-06 19:17:36,997:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 19:17:36,997:INFO:create_model() successfully completed......................................
2024-09-06 19:17:37,135:INFO:SubProcess create_model() end ==================================
2024-09-06 19:17:37,136:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8284
2024-09-06 19:17:37,136:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8292
2024-09-06 19:17:37,137:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-06 19:17:37,137:INFO:choose_better completed
2024-09-06 19:17:37,137:INFO:_master_model_container: 3
2024-09-06 19:17:37,137:INFO:_display_container: 3
2024-09-06 19:17:37,137:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 19:17:37,137:INFO:tune_model() successfully completed......................................
2024-09-06 19:19:51,769:INFO:Initializing predict_model()
2024-09-06 19:19:51,769:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A36DFFC70>)
2024-09-06 19:19:51,769:INFO:Checking exceptions
2024-09-06 19:19:51,770:INFO:Preloading libraries
2024-09-06 19:19:51,772:INFO:Set up data.
2024-09-06 19:19:51,901:INFO:Set up index.
2024-09-06 19:19:52,625:INFO:Initializing get_config()
2024-09-06 19:19:52,625:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, variable=X_train)
2024-09-06 19:19:52,626:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 19:19:52,783:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.216109  -0.037036  -0.621245  -0.162261  -0.527968   
41786   1.144238   0.066573  -2.020844   0.247705  -0.162261  -0.527968   
53345  -0.499730  -1.127987  -0.554897  -0.476420  -0.162261  -0.527968   
11745  -0.742247  -0.854424  -0.969187  -0.331595  -0.162261  -0.527968   
23494   0.829220   3.249027   2.839088  -0.621245  -0.162261   0.064610   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893   1.516459   1.126161  -0.621245  -0.162261   1.249768   
38857  -1.387282  -2.039865  -1.502983   2.275255  -0.162261   0.064610   
31149   0.765373  -0.033734   0.560497  -0.476420  -0.162261   0.064610   
55353   0.715438  -0.216109   0.608300  -0.186770  -0.162261   0.064610   
1638   -0.827527  -0.854424  -0.825779  -0.041945  -0.162261   0.064610   

       feature_6  feature_7  feature_8  feature_9  ...  feature_248  \
71710   0.751803  -0.065075   0.287760  -0.142716  ...    -0.086278   
41786   1.885756  -1.548440  -1.893514  -0.142716  ...    -0.086278   
53345   1.035291  -0.065075   0.192922  -0.142716  ...    -0.086278   
11745   0.184827  -0.435916   0.256147  -0.142716  ...     6.167595   
23494  -2.083079  -1.548440  -1.893514  -0.142716  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374   0.184827   1.047449   1.008529  -0.142716  ...    -0.086278   
38857   2.452733  -1.177599   0.003246  -0.142716  ...    -0.086278   
31149  -0.098661   0.676608   0.463888  -0.142716  ...    -0.086278   
55353  -0.382150   0.676608   0.572274  -0.142716  ...    -0.086278   
1638    1.318780  -1.548440  -1.893514  -0.142716  ...    -0.086278   

       feature_249  feature_250  feature_251  feature_252  feature_253  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_254  feature_255  feature_256  feature_257  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 258 columns]
2024-09-06 19:19:52,783:INFO:get_config() successfully completed......................................
2024-09-06 19:19:52,784:INFO:Initializing predict_model()
2024-09-06 19:19:52,784:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014AA248EDD0>)
2024-09-06 19:19:52,784:INFO:Checking exceptions
2024-09-06 19:19:52,784:INFO:Preloading libraries
2024-09-06 19:19:52,785:INFO:Set up data.
2024-09-06 19:19:52,906:INFO:Set up index.
2024-09-06 19:19:53,779:INFO:Initializing get_config()
2024-09-06 19:19:53,779:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, variable=y_train)
2024-09-06 19:19:53,780:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 19:19:53,872:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 19:19:53,873:INFO:get_config() successfully completed......................................
2024-09-06 19:19:53,873:INFO:Initializing get_config()
2024-09-06 19:19:53,873:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, variable=y_test)
2024-09-06 19:19:53,873:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 19:19:53,943:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 19:19:53,943:INFO:get_config() successfully completed......................................
2024-09-06 19:19:53,948:INFO:Initializing finalize_model()
2024-09-06 19:19:53,948:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 19:19:53,949:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 19:19:54,204:INFO:Initializing create_model()
2024-09-06 19:19:54,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A36E888E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 19:19:54,204:INFO:Checking exceptions
2024-09-06 19:19:54,205:INFO:Importing libraries
2024-09-06 19:19:54,205:INFO:Copying training dataset
2024-09-06 19:19:54,250:INFO:Defining folds
2024-09-06 19:19:54,250:INFO:Declaring metric variables
2024-09-06 19:19:54,250:INFO:Importing untrained model
2024-09-06 19:19:54,250:INFO:Declaring custom model
2024-09-06 19:19:54,251:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 19:19:54,253:INFO:Cross validation set to False
2024-09-06 19:19:54,253:INFO:Fitting Model
2024-09-06 19:19:55,240:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069048 seconds.
2024-09-06 19:19:55,240:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 19:19:55,243:INFO:[LightGBM] [Info] Total Bins 29948
2024-09-06 19:19:55,244:INFO:[LightGBM] [Info] Number of data points in the train set: 76518, number of used features: 258
2024-09-06 19:19:55,246:INFO:[LightGBM] [Info] Start training from score -1.106880
2024-09-06 19:19:55,246:INFO:[LightGBM] [Info] Start training from score -1.633484
2024-09-06 19:19:55,246:INFO:[LightGBM] [Info] Start training from score -0.746204
2024-09-06 21:23:03,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 21:23:03,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 21:23:03,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 21:23:03,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 21:24:57,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 21:24:57,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 21:24:57,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 21:24:57,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 21:46:19,364:INFO:PyCaret ClassificationExperiment
2024-09-06 21:46:19,364:INFO:Logging name: clf-default-name
2024-09-06 21:46:19,364:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-06 21:46:19,364:INFO:version 3.3.2
2024-09-06 21:46:19,364:INFO:Initializing setup()
2024-09-06 21:46:19,364:INFO:self.USI: 80aa
2024-09-06 21:46:19,364:INFO:self._variable_keys: {'data', 'fold_shuffle_param', '_available_plots', 'X_test', 'html_param', 'gpu_n_jobs_param', 'USI', 'fold_generator', 'exp_name_log', 'y', 'gpu_param', 'is_multiclass', 'memory', 'log_plots_param', 'X', 'y_train', 'fix_imbalance', '_ml_usecase', 'pipeline', 'X_train', 'logging_param', 'idx', 'n_jobs_param', 'exp_id', 'y_test', 'target_param', 'seed', 'fold_groups_param'}
2024-09-06 21:46:19,365:INFO:Checking environment
2024-09-06 21:46:19,365:INFO:python_version: 3.10.11
2024-09-06 21:46:19,365:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-06 21:46:19,365:INFO:machine: AMD64
2024-09-06 21:46:19,365:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-06 21:46:19,365:INFO:Memory: svmem(total=17128263680, available=6814109696, percent=60.2, used=10314153984, free=6814109696)
2024-09-06 21:46:19,365:INFO:Physical Core: 6
2024-09-06 21:46:19,365:INFO:Logical Core: 12
2024-09-06 21:46:19,365:INFO:Checking libraries
2024-09-06 21:46:19,365:INFO:System:
2024-09-06 21:46:19,365:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-06 21:46:19,365:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-06 21:46:19,365:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-06 21:46:19,365:INFO:PyCaret required dependencies:
2024-09-06 21:46:19,392:INFO:                 pip: 24.2
2024-09-06 21:46:19,392:INFO:          setuptools: 72.1.0
2024-09-06 21:46:19,392:INFO:             pycaret: 3.3.2
2024-09-06 21:46:19,392:INFO:             IPython: 8.27.0
2024-09-06 21:46:19,392:INFO:          ipywidgets: 8.1.5
2024-09-06 21:46:19,392:INFO:                tqdm: 4.66.5
2024-09-06 21:46:19,393:INFO:               numpy: 1.26.4
2024-09-06 21:46:19,393:INFO:              pandas: 2.2.2
2024-09-06 21:46:19,393:INFO:              jinja2: 3.1.4
2024-09-06 21:46:19,393:INFO:               scipy: 1.11.4
2024-09-06 21:46:19,393:INFO:              joblib: 1.3.2
2024-09-06 21:46:19,393:INFO:             sklearn: 1.4.2
2024-09-06 21:46:19,393:INFO:                pyod: 2.0.1
2024-09-06 21:46:19,393:INFO:            imblearn: 0.12.3
2024-09-06 21:46:19,393:INFO:   category_encoders: 2.6.3
2024-09-06 21:46:19,393:INFO:            lightgbm: 4.5.0
2024-09-06 21:46:19,393:INFO:               numba: 0.60.0
2024-09-06 21:46:19,393:INFO:            requests: 2.32.3
2024-09-06 21:46:19,393:INFO:          matplotlib: 3.7.5
2024-09-06 21:46:19,393:INFO:          scikitplot: 0.3.7
2024-09-06 21:46:19,393:INFO:         yellowbrick: 1.5
2024-09-06 21:46:19,393:INFO:              plotly: 5.24.0
2024-09-06 21:46:19,393:INFO:    plotly-resampler: Not installed
2024-09-06 21:46:19,393:INFO:             kaleido: 0.2.1
2024-09-06 21:46:19,393:INFO:           schemdraw: 0.15
2024-09-06 21:46:19,393:INFO:         statsmodels: 0.14.2
2024-09-06 21:46:19,393:INFO:              sktime: 0.26.0
2024-09-06 21:46:19,394:INFO:               tbats: 1.1.3
2024-09-06 21:46:19,394:INFO:            pmdarima: 2.0.4
2024-09-06 21:46:19,394:INFO:              psutil: 6.0.0
2024-09-06 21:46:19,394:INFO:          markupsafe: 2.1.5
2024-09-06 21:46:19,394:INFO:             pickle5: Not installed
2024-09-06 21:46:19,394:INFO:         cloudpickle: 3.0.0
2024-09-06 21:46:19,394:INFO:         deprecation: 2.1.0
2024-09-06 21:46:19,394:INFO:              xxhash: 3.5.0
2024-09-06 21:46:19,394:INFO:           wurlitzer: Not installed
2024-09-06 21:46:19,394:INFO:PyCaret optional dependencies:
2024-09-06 21:46:19,408:INFO:                shap: Not installed
2024-09-06 21:46:19,408:INFO:           interpret: Not installed
2024-09-06 21:46:19,408:INFO:                umap: Not installed
2024-09-06 21:46:19,408:INFO:     ydata_profiling: Not installed
2024-09-06 21:46:19,408:INFO:  explainerdashboard: Not installed
2024-09-06 21:46:19,409:INFO:             autoviz: Not installed
2024-09-06 21:46:19,409:INFO:           fairlearn: Not installed
2024-09-06 21:46:19,409:INFO:          deepchecks: Not installed
2024-09-06 21:46:19,409:INFO:             xgboost: 2.1.1
2024-09-06 21:46:19,409:INFO:            catboost: Not installed
2024-09-06 21:46:19,409:INFO:              kmodes: Not installed
2024-09-06 21:46:19,409:INFO:             mlxtend: Not installed
2024-09-06 21:46:19,409:INFO:       statsforecast: Not installed
2024-09-06 21:46:19,409:INFO:        tune_sklearn: Not installed
2024-09-06 21:46:19,409:INFO:                 ray: Not installed
2024-09-06 21:46:19,409:INFO:            hyperopt: 0.2.7
2024-09-06 21:46:19,409:INFO:              optuna: 4.0.0
2024-09-06 21:46:19,409:INFO:               skopt: 0.10.2
2024-09-06 21:46:19,409:INFO:              mlflow: Not installed
2024-09-06 21:46:19,409:INFO:              gradio: Not installed
2024-09-06 21:46:19,409:INFO:             fastapi: Not installed
2024-09-06 21:46:19,409:INFO:             uvicorn: Not installed
2024-09-06 21:46:19,409:INFO:              m2cgen: Not installed
2024-09-06 21:46:19,409:INFO:           evidently: Not installed
2024-09-06 21:46:19,409:INFO:               fugue: Not installed
2024-09-06 21:46:19,409:INFO:           streamlit: Not installed
2024-09-06 21:46:19,409:INFO:             prophet: Not installed
2024-09-06 21:46:19,410:INFO:None
2024-09-06 21:46:19,410:INFO:Set up data.
2024-09-06 21:46:19,493:INFO:Set up folding strategy.
2024-09-06 21:46:19,494:INFO:Set up train/test split.
2024-09-06 21:46:19,608:INFO:Set up index.
2024-09-06 21:46:19,612:INFO:Assigning column types.
2024-09-06 21:46:19,719:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-06 21:46:19,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 21:46:19,772:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 21:46:19,809:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:46:19,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:46:19,861:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 21:46:19,862:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 21:46:19,892:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:46:19,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:46:19,895:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-06 21:46:19,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 21:46:19,974:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:46:19,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:46:20,026:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 21:46:20,057:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:46:20,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:46:20,060:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-06 21:46:20,140:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:46:20,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:46:20,222:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:46:20,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:46:20,227:INFO:Preparing preprocessing pipeline...
2024-09-06 21:46:20,246:INFO:Set up simple imputation.
2024-09-06 21:46:20,246:INFO:Set up imbalanced handling.
2024-09-06 21:46:20,470:INFO:Finished creating preprocessing pipeline.
2024-09-06 21:46:20,478:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-06 21:46:20,479:INFO:Creating final display dataframe.
2024-09-06 21:46:22,897:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape       (76518, 76)
4        Transformed data shape       (99147, 76)
5   Transformed train set shape       (76191, 76)
6    Transformed test set shape       (22956, 76)
7              Numeric features                75
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              80aa
2024-09-06 21:46:22,986:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:46:22,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:46:23,069:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:46:23,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:46:23,073:INFO:setup() successfully completed in 3.74s...............
2024-09-06 21:46:23,080:INFO:Initializing compare_models()
2024-09-06 21:46:23,080:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-06 21:46:23,081:INFO:Checking exceptions
2024-09-06 21:46:23,169:INFO:Preparing display monitor
2024-09-06 21:46:23,191:INFO:Initializing Logistic Regression
2024-09-06 21:46:23,191:INFO:Total runtime is 0.0 minutes
2024-09-06 21:46:23,195:INFO:SubProcess create_model() called ==================================
2024-09-06 21:46:23,195:INFO:Initializing create_model()
2024-09-06 21:46:23,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:46:23,195:INFO:Checking exceptions
2024-09-06 21:46:23,196:INFO:Importing libraries
2024-09-06 21:46:23,196:INFO:Copying training dataset
2024-09-06 21:46:23,330:INFO:Defining folds
2024-09-06 21:46:23,330:INFO:Declaring metric variables
2024-09-06 21:46:23,334:INFO:Importing untrained model
2024-09-06 21:46:23,338:INFO:Logistic Regression Imported successfully
2024-09-06 21:46:23,344:INFO:Starting cross validation
2024-09-06 21:46:23,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:46:42,638:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:42,671:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:42,845:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:43,306:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:43,455:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:43,490:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:43,499:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:43,512:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:43,583:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:43,650:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:46:43,675:INFO:Calculating mean and std
2024-09-06 21:46:43,676:INFO:Creating metrics dataframe
2024-09-06 21:46:43,679:INFO:Uploading results into container
2024-09-06 21:46:43,679:INFO:Uploading model into container now
2024-09-06 21:46:43,679:INFO:_master_model_container: 1
2024-09-06 21:46:43,679:INFO:_display_container: 2
2024-09-06 21:46:43,680:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-06 21:46:43,680:INFO:create_model() successfully completed......................................
2024-09-06 21:46:43,750:INFO:SubProcess create_model() end ==================================
2024-09-06 21:46:43,750:INFO:Creating metrics dataframe
2024-09-06 21:46:43,757:INFO:Initializing K Neighbors Classifier
2024-09-06 21:46:43,757:INFO:Total runtime is 0.34276659886042277 minutes
2024-09-06 21:46:43,760:INFO:SubProcess create_model() called ==================================
2024-09-06 21:46:43,760:INFO:Initializing create_model()
2024-09-06 21:46:43,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:46:43,760:INFO:Checking exceptions
2024-09-06 21:46:43,760:INFO:Importing libraries
2024-09-06 21:46:43,760:INFO:Copying training dataset
2024-09-06 21:46:43,893:INFO:Defining folds
2024-09-06 21:46:43,893:INFO:Declaring metric variables
2024-09-06 21:46:43,897:INFO:Importing untrained model
2024-09-06 21:46:43,900:INFO:K Neighbors Classifier Imported successfully
2024-09-06 21:46:43,907:INFO:Starting cross validation
2024-09-06 21:46:43,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:46:57,944:INFO:Calculating mean and std
2024-09-06 21:46:57,945:INFO:Creating metrics dataframe
2024-09-06 21:46:57,947:INFO:Uploading results into container
2024-09-06 21:46:57,948:INFO:Uploading model into container now
2024-09-06 21:46:57,948:INFO:_master_model_container: 2
2024-09-06 21:46:57,948:INFO:_display_container: 2
2024-09-06 21:46:57,948:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-06 21:46:57,948:INFO:create_model() successfully completed......................................
2024-09-06 21:46:58,017:INFO:SubProcess create_model() end ==================================
2024-09-06 21:46:58,017:INFO:Creating metrics dataframe
2024-09-06 21:46:58,023:INFO:Initializing Naive Bayes
2024-09-06 21:46:58,023:INFO:Total runtime is 0.5805450280507406 minutes
2024-09-06 21:46:58,027:INFO:SubProcess create_model() called ==================================
2024-09-06 21:46:58,027:INFO:Initializing create_model()
2024-09-06 21:46:58,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:46:58,027:INFO:Checking exceptions
2024-09-06 21:46:58,027:INFO:Importing libraries
2024-09-06 21:46:58,027:INFO:Copying training dataset
2024-09-06 21:46:58,160:INFO:Defining folds
2024-09-06 21:46:58,160:INFO:Declaring metric variables
2024-09-06 21:46:58,163:INFO:Importing untrained model
2024-09-06 21:46:58,166:INFO:Naive Bayes Imported successfully
2024-09-06 21:46:58,173:INFO:Starting cross validation
2024-09-06 21:46:58,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:47:02,732:INFO:Calculating mean and std
2024-09-06 21:47:02,733:INFO:Creating metrics dataframe
2024-09-06 21:47:02,735:INFO:Uploading results into container
2024-09-06 21:47:02,735:INFO:Uploading model into container now
2024-09-06 21:47:02,736:INFO:_master_model_container: 3
2024-09-06 21:47:02,736:INFO:_display_container: 2
2024-09-06 21:47:02,736:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-06 21:47:02,736:INFO:create_model() successfully completed......................................
2024-09-06 21:47:02,802:INFO:SubProcess create_model() end ==================================
2024-09-06 21:47:02,802:INFO:Creating metrics dataframe
2024-09-06 21:47:02,809:INFO:Initializing Decision Tree Classifier
2024-09-06 21:47:02,809:INFO:Total runtime is 0.660312302907308 minutes
2024-09-06 21:47:02,812:INFO:SubProcess create_model() called ==================================
2024-09-06 21:47:02,813:INFO:Initializing create_model()
2024-09-06 21:47:02,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:47:02,813:INFO:Checking exceptions
2024-09-06 21:47:02,813:INFO:Importing libraries
2024-09-06 21:47:02,813:INFO:Copying training dataset
2024-09-06 21:47:02,949:INFO:Defining folds
2024-09-06 21:47:02,949:INFO:Declaring metric variables
2024-09-06 21:47:02,952:INFO:Importing untrained model
2024-09-06 21:47:02,955:INFO:Decision Tree Classifier Imported successfully
2024-09-06 21:47:02,962:INFO:Starting cross validation
2024-09-06 21:47:02,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:47:11,459:INFO:Calculating mean and std
2024-09-06 21:47:11,460:INFO:Creating metrics dataframe
2024-09-06 21:47:11,462:INFO:Uploading results into container
2024-09-06 21:47:11,463:INFO:Uploading model into container now
2024-09-06 21:47:11,464:INFO:_master_model_container: 4
2024-09-06 21:47:11,464:INFO:_display_container: 2
2024-09-06 21:47:11,464:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-06 21:47:11,464:INFO:create_model() successfully completed......................................
2024-09-06 21:47:11,530:INFO:SubProcess create_model() end ==================================
2024-09-06 21:47:11,530:INFO:Creating metrics dataframe
2024-09-06 21:47:11,538:INFO:Initializing SVM - Linear Kernel
2024-09-06 21:47:11,538:INFO:Total runtime is 0.8057872811953227 minutes
2024-09-06 21:47:11,541:INFO:SubProcess create_model() called ==================================
2024-09-06 21:47:11,541:INFO:Initializing create_model()
2024-09-06 21:47:11,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:47:11,543:INFO:Checking exceptions
2024-09-06 21:47:11,543:INFO:Importing libraries
2024-09-06 21:47:11,543:INFO:Copying training dataset
2024-09-06 21:47:11,677:INFO:Defining folds
2024-09-06 21:47:11,677:INFO:Declaring metric variables
2024-09-06 21:47:11,681:INFO:Importing untrained model
2024-09-06 21:47:11,686:INFO:SVM - Linear Kernel Imported successfully
2024-09-06 21:47:11,692:INFO:Starting cross validation
2024-09-06 21:47:11,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:47:17,787:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:17,989:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:18,504:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:18,921:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:19,023:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:19,302:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:19,495:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:19,518:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:19,519:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:19,621:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:19,653:INFO:Calculating mean and std
2024-09-06 21:47:19,654:INFO:Creating metrics dataframe
2024-09-06 21:47:19,656:INFO:Uploading results into container
2024-09-06 21:47:19,656:INFO:Uploading model into container now
2024-09-06 21:47:19,657:INFO:_master_model_container: 5
2024-09-06 21:47:19,657:INFO:_display_container: 2
2024-09-06 21:47:19,658:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-06 21:47:19,658:INFO:create_model() successfully completed......................................
2024-09-06 21:47:19,723:INFO:SubProcess create_model() end ==================================
2024-09-06 21:47:19,723:INFO:Creating metrics dataframe
2024-09-06 21:47:19,731:INFO:Initializing Ridge Classifier
2024-09-06 21:47:19,731:INFO:Total runtime is 0.9423437595367432 minutes
2024-09-06 21:47:19,734:INFO:SubProcess create_model() called ==================================
2024-09-06 21:47:19,735:INFO:Initializing create_model()
2024-09-06 21:47:19,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:47:19,735:INFO:Checking exceptions
2024-09-06 21:47:19,735:INFO:Importing libraries
2024-09-06 21:47:19,735:INFO:Copying training dataset
2024-09-06 21:47:19,865:INFO:Defining folds
2024-09-06 21:47:19,865:INFO:Declaring metric variables
2024-09-06 21:47:19,869:INFO:Importing untrained model
2024-09-06 21:47:19,872:INFO:Ridge Classifier Imported successfully
2024-09-06 21:47:19,880:INFO:Starting cross validation
2024-09-06 21:47:19,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:47:23,784:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:23,785:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:23,983:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:24,042:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:24,121:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:24,229:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:24,235:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:24,273:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:24,304:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:24,343:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:47:24,360:INFO:Calculating mean and std
2024-09-06 21:47:24,360:INFO:Creating metrics dataframe
2024-09-06 21:47:24,362:INFO:Uploading results into container
2024-09-06 21:47:24,363:INFO:Uploading model into container now
2024-09-06 21:47:24,363:INFO:_master_model_container: 6
2024-09-06 21:47:24,363:INFO:_display_container: 2
2024-09-06 21:47:24,363:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-06 21:47:24,363:INFO:create_model() successfully completed......................................
2024-09-06 21:47:24,431:INFO:SubProcess create_model() end ==================================
2024-09-06 21:47:24,431:INFO:Creating metrics dataframe
2024-09-06 21:47:24,440:INFO:Initializing Random Forest Classifier
2024-09-06 21:47:24,440:INFO:Total runtime is 1.0208202878634136 minutes
2024-09-06 21:47:24,443:INFO:SubProcess create_model() called ==================================
2024-09-06 21:47:24,443:INFO:Initializing create_model()
2024-09-06 21:47:24,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:47:24,443:INFO:Checking exceptions
2024-09-06 21:47:24,444:INFO:Importing libraries
2024-09-06 21:47:24,444:INFO:Copying training dataset
2024-09-06 21:47:24,579:INFO:Defining folds
2024-09-06 21:47:24,579:INFO:Declaring metric variables
2024-09-06 21:47:24,583:INFO:Importing untrained model
2024-09-06 21:47:24,587:INFO:Random Forest Classifier Imported successfully
2024-09-06 21:47:24,593:INFO:Starting cross validation
2024-09-06 21:47:24,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:47:58,541:INFO:Calculating mean and std
2024-09-06 21:47:58,542:INFO:Creating metrics dataframe
2024-09-06 21:47:58,546:INFO:Uploading results into container
2024-09-06 21:47:58,546:INFO:Uploading model into container now
2024-09-06 21:47:58,546:INFO:_master_model_container: 7
2024-09-06 21:47:58,547:INFO:_display_container: 2
2024-09-06 21:47:58,547:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-06 21:47:58,547:INFO:create_model() successfully completed......................................
2024-09-06 21:47:58,624:INFO:SubProcess create_model() end ==================================
2024-09-06 21:47:58,624:INFO:Creating metrics dataframe
2024-09-06 21:47:58,634:INFO:Initializing Quadratic Discriminant Analysis
2024-09-06 21:47:58,634:INFO:Total runtime is 1.5907245953877767 minutes
2024-09-06 21:47:58,638:INFO:SubProcess create_model() called ==================================
2024-09-06 21:47:58,638:INFO:Initializing create_model()
2024-09-06 21:47:58,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:47:58,639:INFO:Checking exceptions
2024-09-06 21:47:58,639:INFO:Importing libraries
2024-09-06 21:47:58,639:INFO:Copying training dataset
2024-09-06 21:47:58,775:INFO:Defining folds
2024-09-06 21:47:58,775:INFO:Declaring metric variables
2024-09-06 21:47:58,779:INFO:Importing untrained model
2024-09-06 21:47:58,783:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-06 21:47:58,790:INFO:Starting cross validation
2024-09-06 21:47:58,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:48:03,018:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:03,109:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:03,317:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:03,587:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:03,747:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:03,810:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:03,956:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:04,250:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:04,273:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:04,275:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:04,442:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:04,575:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 21:48:04,678:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:05,065:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:05,152:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:05,306:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:05,362:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:05,380:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:05,408:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:05,418:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:05,438:INFO:Calculating mean and std
2024-09-06 21:48:05,439:INFO:Creating metrics dataframe
2024-09-06 21:48:05,441:INFO:Uploading results into container
2024-09-06 21:48:05,442:INFO:Uploading model into container now
2024-09-06 21:48:05,443:INFO:_master_model_container: 8
2024-09-06 21:48:05,443:INFO:_display_container: 2
2024-09-06 21:48:05,443:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-06 21:48:05,444:INFO:create_model() successfully completed......................................
2024-09-06 21:48:05,516:INFO:SubProcess create_model() end ==================================
2024-09-06 21:48:05,516:INFO:Creating metrics dataframe
2024-09-06 21:48:05,533:INFO:Initializing Ada Boost Classifier
2024-09-06 21:48:05,533:INFO:Total runtime is 1.7056969046592712 minutes
2024-09-06 21:48:05,538:INFO:SubProcess create_model() called ==================================
2024-09-06 21:48:05,539:INFO:Initializing create_model()
2024-09-06 21:48:05,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:48:05,539:INFO:Checking exceptions
2024-09-06 21:48:05,539:INFO:Importing libraries
2024-09-06 21:48:05,540:INFO:Copying training dataset
2024-09-06 21:48:05,674:INFO:Defining folds
2024-09-06 21:48:05,675:INFO:Declaring metric variables
2024-09-06 21:48:05,678:INFO:Importing untrained model
2024-09-06 21:48:05,682:INFO:Ada Boost Classifier Imported successfully
2024-09-06 21:48:05,689:INFO:Starting cross validation
2024-09-06 21:48:05,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:48:09,595:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:09,729:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:09,882:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:09,891:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:09,940:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:09,991:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:10,051:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:10,053:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:10,122:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:10,235:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 21:48:24,228:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,232:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,293:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,349:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,419:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,449:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,520:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,532:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,551:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,592:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:48:24,621:INFO:Calculating mean and std
2024-09-06 21:48:24,622:INFO:Creating metrics dataframe
2024-09-06 21:48:24,624:INFO:Uploading results into container
2024-09-06 21:48:24,624:INFO:Uploading model into container now
2024-09-06 21:48:24,625:INFO:_master_model_container: 9
2024-09-06 21:48:24,625:INFO:_display_container: 2
2024-09-06 21:48:24,625:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-06 21:48:24,626:INFO:create_model() successfully completed......................................
2024-09-06 21:48:24,693:INFO:SubProcess create_model() end ==================================
2024-09-06 21:48:24,693:INFO:Creating metrics dataframe
2024-09-06 21:48:24,701:INFO:Initializing Gradient Boosting Classifier
2024-09-06 21:48:24,701:INFO:Total runtime is 2.025174117088318 minutes
2024-09-06 21:48:24,705:INFO:SubProcess create_model() called ==================================
2024-09-06 21:48:24,706:INFO:Initializing create_model()
2024-09-06 21:48:24,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:48:24,706:INFO:Checking exceptions
2024-09-06 21:48:24,706:INFO:Importing libraries
2024-09-06 21:48:24,706:INFO:Copying training dataset
2024-09-06 21:48:24,821:INFO:Defining folds
2024-09-06 21:48:24,821:INFO:Declaring metric variables
2024-09-06 21:48:24,825:INFO:Importing untrained model
2024-09-06 21:48:24,829:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 21:48:24,836:INFO:Starting cross validation
2024-09-06 21:48:24,838:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:51:53,172:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:53,348:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:53,416:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:53,491:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:53,845:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:53,855:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:54,084:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:54,118:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:54,202:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:54,345:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:54,371:INFO:Calculating mean and std
2024-09-06 21:51:54,372:INFO:Creating metrics dataframe
2024-09-06 21:51:54,374:INFO:Uploading results into container
2024-09-06 21:51:54,374:INFO:Uploading model into container now
2024-09-06 21:51:54,374:INFO:_master_model_container: 10
2024-09-06 21:51:54,375:INFO:_display_container: 2
2024-09-06 21:51:54,375:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 21:51:54,375:INFO:create_model() successfully completed......................................
2024-09-06 21:51:54,441:INFO:SubProcess create_model() end ==================================
2024-09-06 21:51:54,441:INFO:Creating metrics dataframe
2024-09-06 21:51:54,450:INFO:Initializing Linear Discriminant Analysis
2024-09-06 21:51:54,451:INFO:Total runtime is 5.521012238661449 minutes
2024-09-06 21:51:54,455:INFO:SubProcess create_model() called ==================================
2024-09-06 21:51:54,455:INFO:Initializing create_model()
2024-09-06 21:51:54,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:51:54,455:INFO:Checking exceptions
2024-09-06 21:51:54,455:INFO:Importing libraries
2024-09-06 21:51:54,455:INFO:Copying training dataset
2024-09-06 21:51:54,574:INFO:Defining folds
2024-09-06 21:51:54,574:INFO:Declaring metric variables
2024-09-06 21:51:54,578:INFO:Importing untrained model
2024-09-06 21:51:54,582:INFO:Linear Discriminant Analysis Imported successfully
2024-09-06 21:51:54,589:INFO:Starting cross validation
2024-09-06 21:51:54,591:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:51:59,190:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:59,378:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:51:59,574:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:52:00,233:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:52:00,552:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:52:00,594:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:52:00,661:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:52:00,681:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:52:00,692:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:52:00,746:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 21:52:00,778:INFO:Calculating mean and std
2024-09-06 21:52:00,779:INFO:Creating metrics dataframe
2024-09-06 21:52:00,782:INFO:Uploading results into container
2024-09-06 21:52:00,782:INFO:Uploading model into container now
2024-09-06 21:52:00,782:INFO:_master_model_container: 11
2024-09-06 21:52:00,782:INFO:_display_container: 2
2024-09-06 21:52:00,784:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-06 21:52:00,784:INFO:create_model() successfully completed......................................
2024-09-06 21:52:00,853:INFO:SubProcess create_model() end ==================================
2024-09-06 21:52:00,853:INFO:Creating metrics dataframe
2024-09-06 21:52:00,863:INFO:Initializing Extra Trees Classifier
2024-09-06 21:52:00,863:INFO:Total runtime is 5.627863081296286 minutes
2024-09-06 21:52:00,866:INFO:SubProcess create_model() called ==================================
2024-09-06 21:52:00,866:INFO:Initializing create_model()
2024-09-06 21:52:00,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:52:00,867:INFO:Checking exceptions
2024-09-06 21:52:00,867:INFO:Importing libraries
2024-09-06 21:52:00,867:INFO:Copying training dataset
2024-09-06 21:52:00,990:INFO:Defining folds
2024-09-06 21:52:00,991:INFO:Declaring metric variables
2024-09-06 21:52:00,994:INFO:Importing untrained model
2024-09-06 21:52:00,998:INFO:Extra Trees Classifier Imported successfully
2024-09-06 21:52:01,005:INFO:Starting cross validation
2024-09-06 21:52:01,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:52:29,122:INFO:Calculating mean and std
2024-09-06 21:52:29,123:INFO:Creating metrics dataframe
2024-09-06 21:52:29,125:INFO:Uploading results into container
2024-09-06 21:52:29,126:INFO:Uploading model into container now
2024-09-06 21:52:29,127:INFO:_master_model_container: 12
2024-09-06 21:52:29,127:INFO:_display_container: 2
2024-09-06 21:52:29,127:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-06 21:52:29,127:INFO:create_model() successfully completed......................................
2024-09-06 21:52:29,200:INFO:SubProcess create_model() end ==================================
2024-09-06 21:52:29,200:INFO:Creating metrics dataframe
2024-09-06 21:52:29,211:INFO:Initializing Extreme Gradient Boosting
2024-09-06 21:52:29,211:INFO:Total runtime is 6.100337533156078 minutes
2024-09-06 21:52:29,215:INFO:SubProcess create_model() called ==================================
2024-09-06 21:52:29,215:INFO:Initializing create_model()
2024-09-06 21:52:29,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:52:29,216:INFO:Checking exceptions
2024-09-06 21:52:29,216:INFO:Importing libraries
2024-09-06 21:52:29,216:INFO:Copying training dataset
2024-09-06 21:52:29,348:INFO:Defining folds
2024-09-06 21:52:29,348:INFO:Declaring metric variables
2024-09-06 21:52:29,352:INFO:Importing untrained model
2024-09-06 21:52:29,356:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 21:52:29,364:INFO:Starting cross validation
2024-09-06 21:52:29,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:52:44,887:INFO:Calculating mean and std
2024-09-06 21:52:44,888:INFO:Creating metrics dataframe
2024-09-06 21:52:44,890:INFO:Uploading results into container
2024-09-06 21:52:44,891:INFO:Uploading model into container now
2024-09-06 21:52:44,891:INFO:_master_model_container: 13
2024-09-06 21:52:44,891:INFO:_display_container: 2
2024-09-06 21:52:44,892:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-06 21:52:44,892:INFO:create_model() successfully completed......................................
2024-09-06 21:52:44,956:INFO:SubProcess create_model() end ==================================
2024-09-06 21:52:44,956:INFO:Creating metrics dataframe
2024-09-06 21:52:44,967:INFO:Initializing Light Gradient Boosting Machine
2024-09-06 21:52:44,967:INFO:Total runtime is 6.362937104701997 minutes
2024-09-06 21:52:44,970:INFO:SubProcess create_model() called ==================================
2024-09-06 21:52:44,970:INFO:Initializing create_model()
2024-09-06 21:52:44,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:52:44,971:INFO:Checking exceptions
2024-09-06 21:52:44,971:INFO:Importing libraries
2024-09-06 21:52:44,971:INFO:Copying training dataset
2024-09-06 21:52:45,078:INFO:Defining folds
2024-09-06 21:52:45,078:INFO:Declaring metric variables
2024-09-06 21:52:45,082:INFO:Importing untrained model
2024-09-06 21:52:45,085:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 21:52:45,092:INFO:Starting cross validation
2024-09-06 21:52:45,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:53:11,535:INFO:Calculating mean and std
2024-09-06 21:53:11,536:INFO:Creating metrics dataframe
2024-09-06 21:53:11,539:INFO:Uploading results into container
2024-09-06 21:53:11,539:INFO:Uploading model into container now
2024-09-06 21:53:11,540:INFO:_master_model_container: 14
2024-09-06 21:53:11,540:INFO:_display_container: 2
2024-09-06 21:53:11,541:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 21:53:11,541:INFO:create_model() successfully completed......................................
2024-09-06 21:53:11,679:INFO:SubProcess create_model() end ==================================
2024-09-06 21:53:11,679:INFO:Creating metrics dataframe
2024-09-06 21:53:11,698:INFO:Initializing Dummy Classifier
2024-09-06 21:53:11,698:INFO:Total runtime is 6.808461515108745 minutes
2024-09-06 21:53:11,707:INFO:SubProcess create_model() called ==================================
2024-09-06 21:53:11,708:INFO:Initializing create_model()
2024-09-06 21:53:11,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B4FFC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:53:11,709:INFO:Checking exceptions
2024-09-06 21:53:11,709:INFO:Importing libraries
2024-09-06 21:53:11,709:INFO:Copying training dataset
2024-09-06 21:53:11,885:INFO:Defining folds
2024-09-06 21:53:11,886:INFO:Declaring metric variables
2024-09-06 21:53:11,890:INFO:Importing untrained model
2024-09-06 21:53:11,895:INFO:Dummy Classifier Imported successfully
2024-09-06 21:53:11,904:INFO:Starting cross validation
2024-09-06 21:53:11,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:53:16,381:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,457:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,615:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,618:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,669:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,695:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,753:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,835:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,840:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,878:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 21:53:16,894:INFO:Calculating mean and std
2024-09-06 21:53:16,895:INFO:Creating metrics dataframe
2024-09-06 21:53:16,897:INFO:Uploading results into container
2024-09-06 21:53:16,898:INFO:Uploading model into container now
2024-09-06 21:53:16,898:INFO:_master_model_container: 15
2024-09-06 21:53:16,898:INFO:_display_container: 2
2024-09-06 21:53:16,898:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-06 21:53:16,898:INFO:create_model() successfully completed......................................
2024-09-06 21:53:16,968:INFO:SubProcess create_model() end ==================================
2024-09-06 21:53:16,969:INFO:Creating metrics dataframe
2024-09-06 21:53:16,990:INFO:Initializing create_model()
2024-09-06 21:53:16,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B1C597250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:53:16,990:INFO:Checking exceptions
2024-09-06 21:53:16,991:INFO:Importing libraries
2024-09-06 21:53:16,992:INFO:Copying training dataset
2024-09-06 21:53:17,108:INFO:Defining folds
2024-09-06 21:53:17,108:INFO:Declaring metric variables
2024-09-06 21:53:17,108:INFO:Importing untrained model
2024-09-06 21:53:17,108:INFO:Declaring custom model
2024-09-06 21:53:17,109:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 21:53:17,111:INFO:Cross validation set to False
2024-09-06 21:53:17,111:INFO:Fitting Model
2024-09-06 21:53:18,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017450 seconds.
2024-09-06 21:53:18,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 21:53:18,193:INFO:[LightGBM] [Info] Total Bins 16813
2024-09-06 21:53:18,194:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 75
2024-09-06 21:53:18,195:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 21:53:18,196:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 21:53:18,196:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-06 21:53:20,235:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 21:53:20,235:INFO:create_model() successfully completed......................................
2024-09-06 21:53:20,344:INFO:_master_model_container: 15
2024-09-06 21:53:20,344:INFO:_display_container: 2
2024-09-06 21:53:20,345:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 21:53:20,345:INFO:compare_models() successfully completed......................................
2024-09-06 21:53:20,397:INFO:PyCaret ClassificationExperiment
2024-09-06 21:53:20,397:INFO:Logging name: clf-default-name
2024-09-06 21:53:20,397:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-06 21:53:20,397:INFO:version 3.3.2
2024-09-06 21:53:20,397:INFO:Initializing setup()
2024-09-06 21:53:20,397:INFO:self.USI: d232
2024-09-06 21:53:20,397:INFO:self._variable_keys: {'data', 'fold_shuffle_param', '_available_plots', 'X_test', 'html_param', 'gpu_n_jobs_param', 'USI', 'fold_generator', 'exp_name_log', 'y', 'gpu_param', 'is_multiclass', 'memory', 'log_plots_param', 'X', 'y_train', 'fix_imbalance', '_ml_usecase', 'pipeline', 'X_train', 'logging_param', 'idx', 'n_jobs_param', 'exp_id', 'y_test', 'target_param', 'seed', 'fold_groups_param'}
2024-09-06 21:53:20,397:INFO:Checking environment
2024-09-06 21:53:20,397:INFO:python_version: 3.10.11
2024-09-06 21:53:20,397:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-06 21:53:20,397:INFO:machine: AMD64
2024-09-06 21:53:20,397:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-06 21:53:20,397:INFO:Memory: svmem(total=17128263680, available=6595731456, percent=61.5, used=10532532224, free=6595731456)
2024-09-06 21:53:20,397:INFO:Physical Core: 6
2024-09-06 21:53:20,397:INFO:Logical Core: 12
2024-09-06 21:53:20,397:INFO:Checking libraries
2024-09-06 21:53:20,397:INFO:System:
2024-09-06 21:53:20,397:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-06 21:53:20,398:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-06 21:53:20,398:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-06 21:53:20,398:INFO:PyCaret required dependencies:
2024-09-06 21:53:20,398:INFO:                 pip: 24.2
2024-09-06 21:53:20,398:INFO:          setuptools: 72.1.0
2024-09-06 21:53:20,398:INFO:             pycaret: 3.3.2
2024-09-06 21:53:20,398:INFO:             IPython: 8.27.0
2024-09-06 21:53:20,398:INFO:          ipywidgets: 8.1.5
2024-09-06 21:53:20,398:INFO:                tqdm: 4.66.5
2024-09-06 21:53:20,398:INFO:               numpy: 1.26.4
2024-09-06 21:53:20,398:INFO:              pandas: 2.2.2
2024-09-06 21:53:20,398:INFO:              jinja2: 3.1.4
2024-09-06 21:53:20,398:INFO:               scipy: 1.11.4
2024-09-06 21:53:20,398:INFO:              joblib: 1.3.2
2024-09-06 21:53:20,398:INFO:             sklearn: 1.4.2
2024-09-06 21:53:20,398:INFO:                pyod: 2.0.1
2024-09-06 21:53:20,398:INFO:            imblearn: 0.12.3
2024-09-06 21:53:20,398:INFO:   category_encoders: 2.6.3
2024-09-06 21:53:20,398:INFO:            lightgbm: 4.5.0
2024-09-06 21:53:20,398:INFO:               numba: 0.60.0
2024-09-06 21:53:20,398:INFO:            requests: 2.32.3
2024-09-06 21:53:20,398:INFO:          matplotlib: 3.7.5
2024-09-06 21:53:20,399:INFO:          scikitplot: 0.3.7
2024-09-06 21:53:20,399:INFO:         yellowbrick: 1.5
2024-09-06 21:53:20,399:INFO:              plotly: 5.24.0
2024-09-06 21:53:20,399:INFO:    plotly-resampler: Not installed
2024-09-06 21:53:20,399:INFO:             kaleido: 0.2.1
2024-09-06 21:53:20,399:INFO:           schemdraw: 0.15
2024-09-06 21:53:20,399:INFO:         statsmodels: 0.14.2
2024-09-06 21:53:20,399:INFO:              sktime: 0.26.0
2024-09-06 21:53:20,399:INFO:               tbats: 1.1.3
2024-09-06 21:53:20,399:INFO:            pmdarima: 2.0.4
2024-09-06 21:53:20,399:INFO:              psutil: 6.0.0
2024-09-06 21:53:20,399:INFO:          markupsafe: 2.1.5
2024-09-06 21:53:20,399:INFO:             pickle5: Not installed
2024-09-06 21:53:20,399:INFO:         cloudpickle: 3.0.0
2024-09-06 21:53:20,399:INFO:         deprecation: 2.1.0
2024-09-06 21:53:20,399:INFO:              xxhash: 3.5.0
2024-09-06 21:53:20,399:INFO:           wurlitzer: Not installed
2024-09-06 21:53:20,399:INFO:PyCaret optional dependencies:
2024-09-06 21:53:20,399:INFO:                shap: Not installed
2024-09-06 21:53:20,399:INFO:           interpret: Not installed
2024-09-06 21:53:20,399:INFO:                umap: Not installed
2024-09-06 21:53:20,400:INFO:     ydata_profiling: Not installed
2024-09-06 21:53:20,400:INFO:  explainerdashboard: Not installed
2024-09-06 21:53:20,400:INFO:             autoviz: Not installed
2024-09-06 21:53:20,400:INFO:           fairlearn: Not installed
2024-09-06 21:53:20,400:INFO:          deepchecks: Not installed
2024-09-06 21:53:20,400:INFO:             xgboost: 2.1.1
2024-09-06 21:53:20,400:INFO:            catboost: Not installed
2024-09-06 21:53:20,400:INFO:              kmodes: Not installed
2024-09-06 21:53:20,400:INFO:             mlxtend: Not installed
2024-09-06 21:53:20,400:INFO:       statsforecast: Not installed
2024-09-06 21:53:20,400:INFO:        tune_sklearn: Not installed
2024-09-06 21:53:20,400:INFO:                 ray: Not installed
2024-09-06 21:53:20,400:INFO:            hyperopt: 0.2.7
2024-09-06 21:53:20,400:INFO:              optuna: 4.0.0
2024-09-06 21:53:20,400:INFO:               skopt: 0.10.2
2024-09-06 21:53:20,400:INFO:              mlflow: Not installed
2024-09-06 21:53:20,400:INFO:              gradio: Not installed
2024-09-06 21:53:20,400:INFO:             fastapi: Not installed
2024-09-06 21:53:20,400:INFO:             uvicorn: Not installed
2024-09-06 21:53:20,400:INFO:              m2cgen: Not installed
2024-09-06 21:53:20,400:INFO:           evidently: Not installed
2024-09-06 21:53:20,400:INFO:               fugue: Not installed
2024-09-06 21:53:20,400:INFO:           streamlit: Not installed
2024-09-06 21:53:20,400:INFO:             prophet: Not installed
2024-09-06 21:53:20,401:INFO:None
2024-09-06 21:53:20,401:INFO:Set up data.
2024-09-06 21:53:20,487:INFO:Set up folding strategy.
2024-09-06 21:53:20,487:INFO:Set up train/test split.
2024-09-06 21:53:20,595:INFO:Set up index.
2024-09-06 21:53:20,597:INFO:Assigning column types.
2024-09-06 21:53:20,696:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-06 21:53:20,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 21:53:20,748:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 21:53:20,779:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:53:20,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:53:20,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 21:53:20,833:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 21:53:20,864:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:53:20,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:53:20,867:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-06 21:53:20,917:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 21:53:20,948:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:53:20,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:53:21,002:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 21:53:21,032:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:53:21,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:53:21,036:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-06 21:53:21,117:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:53:21,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:53:21,201:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:53:21,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:53:21,205:INFO:Preparing preprocessing pipeline...
2024-09-06 21:53:21,218:INFO:Set up simple imputation.
2024-09-06 21:53:21,405:INFO:Finished creating preprocessing pipeline.
2024-09-06 21:53:21,410:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-09-06 21:53:21,410:INFO:Creating final display dataframe.
2024-09-06 21:53:21,935:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape       (76518, 76)
4        Transformed data shape       (76518, 76)
5   Transformed train set shape       (53562, 76)
6    Transformed test set shape       (22956, 76)
7              Numeric features                75
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d232
2024-09-06 21:53:22,023:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:53:22,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:53:22,107:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 21:53:22,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 21:53:22,111:INFO:setup() successfully completed in 1.74s...............
2024-09-06 21:53:22,111:INFO:Initializing create_model()
2024-09-06 21:53:22,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:53:22,111:INFO:Checking exceptions
2024-09-06 21:53:22,126:INFO:Importing libraries
2024-09-06 21:53:22,126:INFO:Copying training dataset
2024-09-06 21:53:22,237:INFO:Defining folds
2024-09-06 21:53:22,237:INFO:Declaring metric variables
2024-09-06 21:53:22,240:INFO:Importing untrained model
2024-09-06 21:53:22,244:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 21:53:22,251:INFO:Starting cross validation
2024-09-06 21:53:22,252:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:53:35,960:INFO:Calculating mean and std
2024-09-06 21:53:35,961:INFO:Creating metrics dataframe
2024-09-06 21:53:35,968:INFO:Finalizing model
2024-09-06 21:53:36,222:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012816 seconds.
2024-09-06 21:53:36,222:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 21:53:36,222:INFO:[LightGBM] [Info] Total Bins 9191
2024-09-06 21:53:36,222:INFO:[LightGBM] [Info] Number of data points in the train set: 53562, number of used features: 75
2024-09-06 21:53:36,224:INFO:[LightGBM] [Info] Start training from score -1.106880
2024-09-06 21:53:36,224:INFO:[LightGBM] [Info] Start training from score -1.633473
2024-09-06 21:53:36,224:INFO:[LightGBM] [Info] Start training from score -0.746209
2024-09-06 21:53:37,637:INFO:Uploading results into container
2024-09-06 21:53:37,637:INFO:Uploading model into container now
2024-09-06 21:53:37,653:INFO:_master_model_container: 1
2024-09-06 21:53:37,654:INFO:_display_container: 2
2024-09-06 21:53:37,655:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 21:53:37,655:INFO:create_model() successfully completed......................................
2024-09-06 21:53:37,751:INFO:Initializing tune_model()
2024-09-06 21:53:37,751:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5], 'num_leaves': [20, 31, 40], 'min_child_samples': [10, 20, 30], 'subsample': [0.7, 0.8, 0.9], 'colsample_bytree': [0.7, 0.8], 'reg_alpha': [0.1, 0.5, 1.0], 'reg_lambda': [0.1, 0.5, 1.0]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=True, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>)
2024-09-06 21:53:37,751:INFO:Checking exceptions
2024-09-06 21:53:37,751:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-06 21:53:37,890:INFO:Copying training dataset
2024-09-06 21:53:37,980:INFO:Checking base model
2024-09-06 21:53:37,981:INFO:Base model : Light Gradient Boosting Machine
2024-09-06 21:53:37,982:INFO:Declaring metric variables
2024-09-06 21:53:37,982:INFO:Defining Hyperparameters
2024-09-06 21:53:38,071:INFO:custom_grid: {'actual_estimator__learning_rate': CategoricalDistribution(values=[0.01, 0.05, 0.1]), 'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 4, 5]), 'actual_estimator__num_leaves': CategoricalDistribution(values=[20, 31, 40]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[10, 20, 30]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.7, 0.8, 0.9]), 'actual_estimator__colsample_bytree': CategoricalDistribution(values=[0.7, 0.8]), 'actual_estimator__reg_alpha': CategoricalDistribution(values=[0.1, 0.5, 1.0]), 'actual_estimator__reg_lambda': CategoricalDistribution(values=[0.1, 0.5, 1.0])}
2024-09-06 21:53:38,071:INFO:Tuning with n_jobs=-1
2024-09-06 21:53:38,077:INFO:Initializing skopt.BayesSearchCV
2024-09-06 21:54:30,826:INFO:best_params: OrderedDict([('actual_estimator__colsample_bytree', 0.7), ('actual_estimator__learning_rate', 0.05), ('actual_estimator__max_depth', 4), ('actual_estimator__min_child_samples', 10), ('actual_estimator__n_estimators', 200), ('actual_estimator__num_leaves', 20), ('actual_estimator__reg_alpha', 1.0), ('actual_estimator__reg_lambda', 0.1), ('actual_estimator__subsample', 0.8)])
2024-09-06 21:54:30,826:INFO:Hyperparameter search completed
2024-09-06 21:54:30,826:INFO:SubProcess create_model() called ==================================
2024-09-06 21:54:30,827:INFO:Initializing create_model()
2024-09-06 21:54:30,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024B5814B730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_samples': 10, 'n_estimators': 200, 'num_leaves': 20, 'reg_alpha': 1.0, 'reg_lambda': 0.1, 'subsample': 0.8})
2024-09-06 21:54:30,827:INFO:Checking exceptions
2024-09-06 21:54:30,827:INFO:Importing libraries
2024-09-06 21:54:30,827:INFO:Copying training dataset
2024-09-06 21:54:30,947:INFO:Defining folds
2024-09-06 21:54:30,947:INFO:Declaring metric variables
2024-09-06 21:54:30,948:INFO:Importing untrained model
2024-09-06 21:54:30,948:INFO:Declaring custom model
2024-09-06 21:54:30,949:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 21:54:30,949:INFO:Starting cross validation
2024-09-06 21:54:30,950:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:54:37,451:INFO:Calculating mean and std
2024-09-06 21:54:37,451:INFO:Creating metrics dataframe
2024-09-06 21:54:37,454:INFO:Finalizing model
2024-09-06 21:54:37,697:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011501 seconds.
2024-09-06 21:54:37,697:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 21:54:37,698:INFO:[LightGBM] [Info] Total Bins 9191
2024-09-06 21:54:37,698:INFO:[LightGBM] [Info] Number of data points in the train set: 53562, number of used features: 75
2024-09-06 21:54:37,699:INFO:[LightGBM] [Info] Start training from score -1.106880
2024-09-06 21:54:37,699:INFO:[LightGBM] [Info] Start training from score -1.633473
2024-09-06 21:54:37,699:INFO:[LightGBM] [Info] Start training from score -0.746209
2024-09-06 21:54:37,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:37,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:38,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:54:39,599:INFO:Uploading results into container
2024-09-06 21:54:39,600:INFO:Uploading model into container now
2024-09-06 21:54:39,601:INFO:_master_model_container: 2
2024-09-06 21:54:39,601:INFO:_display_container: 3
2024-09-06 21:54:39,602:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 21:54:39,602:INFO:create_model() successfully completed......................................
2024-09-06 21:54:39,690:INFO:SubProcess create_model() end ==================================
2024-09-06 21:54:39,690:INFO:choose_better activated
2024-09-06 21:54:39,690:INFO:SubProcess create_model() called ==================================
2024-09-06 21:54:39,691:INFO:Initializing create_model()
2024-09-06 21:54:39,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:54:39,691:INFO:Checking exceptions
2024-09-06 21:54:39,694:INFO:Importing libraries
2024-09-06 21:54:39,694:INFO:Copying training dataset
2024-09-06 21:54:39,819:INFO:Defining folds
2024-09-06 21:54:39,819:INFO:Declaring metric variables
2024-09-06 21:54:39,820:INFO:Importing untrained model
2024-09-06 21:54:39,820:INFO:Declaring custom model
2024-09-06 21:54:39,820:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 21:54:39,821:INFO:Starting cross validation
2024-09-06 21:54:39,822:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 21:54:45,788:INFO:Calculating mean and std
2024-09-06 21:54:45,788:INFO:Creating metrics dataframe
2024-09-06 21:54:45,791:INFO:Finalizing model
2024-09-06 21:54:46,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007984 seconds.
2024-09-06 21:54:46,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 21:54:46,005:INFO:[LightGBM] [Info] Total Bins 9191
2024-09-06 21:54:46,006:INFO:[LightGBM] [Info] Number of data points in the train set: 53562, number of used features: 75
2024-09-06 21:54:46,007:INFO:[LightGBM] [Info] Start training from score -1.106880
2024-09-06 21:54:46,007:INFO:[LightGBM] [Info] Start training from score -1.633473
2024-09-06 21:54:46,007:INFO:[LightGBM] [Info] Start training from score -0.746209
2024-09-06 21:54:47,179:INFO:Uploading results into container
2024-09-06 21:54:47,180:INFO:Uploading model into container now
2024-09-06 21:54:47,180:INFO:_master_model_container: 3
2024-09-06 21:54:47,180:INFO:_display_container: 4
2024-09-06 21:54:47,181:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 21:54:47,181:INFO:create_model() successfully completed......................................
2024-09-06 21:54:47,265:INFO:SubProcess create_model() end ==================================
2024-09-06 21:54:47,266:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8214
2024-09-06 21:54:47,267:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8223
2024-09-06 21:54:47,267:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-06 21:54:47,267:INFO:choose_better completed
2024-09-06 21:54:47,268:INFO:_master_model_container: 3
2024-09-06 21:54:47,268:INFO:_display_container: 3
2024-09-06 21:54:47,268:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 21:54:47,268:INFO:tune_model() successfully completed......................................
2024-09-06 21:55:16,401:INFO:Initializing predict_model()
2024-09-06 21:55:16,401:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024B592CDEA0>)
2024-09-06 21:55:16,402:INFO:Checking exceptions
2024-09-06 21:55:16,402:INFO:Preloading libraries
2024-09-06 21:55:16,405:INFO:Set up data.
2024-09-06 21:55:16,443:INFO:Set up index.
2024-09-06 21:55:16,798:INFO:Initializing get_config()
2024-09-06 21:55:16,798:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, variable=X_train)
2024-09-06 21:55:16,798:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 21:55:16,851:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   0.346688  -0.621245   0.751803  -0.065075   0.287760  -0.568749   
41786   0.346688   0.247705   1.885756  -1.548440  -1.893514  -0.568749   
53345   0.346688  -0.476420   1.035291  -0.065075   0.192922  -0.568749   
11745   0.346688  -0.331595   0.184827  -0.435916   0.256147  -0.568749   
23494   0.346688  -0.621245  -2.083079  -1.548440  -1.893514   0.042008   
...          ...        ...        ...        ...        ...        ...   
45374   0.346688  -0.621245   0.184827   1.047449   1.008529   1.263522   
38857   0.346688   2.275255   2.452733  -1.177599   0.003246   0.042008   
31149   0.346688  -0.476420  -0.098661   0.676608   0.463888   0.042008   
55353   0.346688  -0.186770  -0.382150   0.676608   0.572274   0.042008   
1638   -2.884440  -0.041945   1.318780  -1.548440  -1.893514   0.042008   

       feature_6  feature_7  feature_8  feature_9  ...  feature_65  \
71710  -0.064285  -0.358527   0.671466  -1.748812  ...   -0.289253   
41786  -0.633318  -1.437270  -1.726610   0.571817  ...   -0.735184   
53345   1.073782  -0.718108   0.431658   0.571817  ...    1.048540   
11745   0.504749  -0.358527   0.431658   0.571817  ...    0.305321   
23494  -2.055902  -1.437270  -1.726610   0.571817  ...   -1.199696   
...          ...        ...        ...        ...  ...         ...   
45374   0.220232   1.079797   1.025182   0.571817  ...   -0.010546   
38857   1.358299  -1.077689   0.071947   0.571817  ...    1.475890   
31149   0.220232   0.720216   0.311754   0.571817  ...   -0.010546   
55353  -0.348801   0.720216   0.821345  -1.748812  ...   -0.530799   
1638    1.358299  -1.437270  -1.726610   0.571817  ...    1.475890   

       feature_66  feature_67  feature_68  feature_69  feature_70  feature_71  \
71710   -0.430680    0.268206   -1.185610   -0.639733   -0.309181   -0.908491   
41786   -1.188688   -1.537877   -0.082860   -1.031124   -1.370414   -0.908491   
53345   -0.394584    1.016440    1.240441   -0.857173   -0.733674   -0.206090   
11745   -0.214106    0.552019    0.799341   -0.639733   -0.415305    0.145111   
23494   -1.188688   -1.537877   -1.185610   -1.031124   -1.370414   -0.908491   
...           ...         ...         ...         ...         ...         ...   
45374    0.832668    0.830672    0.578791    1.099783    1.471036    1.549912   
38857   -0.755541    0.784229    1.460991   -0.987636   -1.105106   -0.557290   
31149    0.543902    0.216603    0.578791    0.534440    0.433681    1.198712   
55353    0.110755    0.106948   -1.185610    0.534440    0.884705   -0.908491   
1638    -1.188688   -1.537877    1.460991   -1.031124   -1.370414   -0.908491   

       feature_72  feature_73  feature_74  
71710    0.724720   -1.032953   -1.748812  
41786   -1.630463   -1.032953    0.571817  
53345    0.277235    0.866023    0.571817  
11745    0.277235    0.866023    0.571817  
23494   -1.630463   -1.032953    0.571817  
...           ...         ...         ...  
45374    1.470739    1.388242    0.571817  
38857   -0.305673    0.549527    0.571817  
31149    0.071157    0.760525    0.571817  
55353    1.028318   -1.032953   -1.748812  
1638    -1.630463   -1.032953    0.571817  

[53562 rows x 75 columns]
2024-09-06 21:55:16,851:INFO:get_config() successfully completed......................................
2024-09-06 21:55:16,852:INFO:Initializing predict_model()
2024-09-06 21:55:16,852:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024B1C503D90>)
2024-09-06 21:55:16,852:INFO:Checking exceptions
2024-09-06 21:55:16,852:INFO:Preloading libraries
2024-09-06 21:55:16,854:INFO:Set up data.
2024-09-06 21:55:16,890:INFO:Set up index.
2024-09-06 21:55:17,459:INFO:Initializing get_config()
2024-09-06 21:55:17,459:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, variable=y_train)
2024-09-06 21:55:17,459:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 21:55:17,487:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 21:55:17,487:INFO:get_config() successfully completed......................................
2024-09-06 21:55:17,487:INFO:Initializing get_config()
2024-09-06 21:55:17,487:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, variable=y_test)
2024-09-06 21:55:17,488:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 21:55:17,508:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 21:55:17,508:INFO:get_config() successfully completed......................................
2024-09-06 21:55:37,773:INFO:Initializing predict_model()
2024-09-06 21:55:37,774:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024B5EC4E560>)
2024-09-06 21:55:37,774:INFO:Checking exceptions
2024-09-06 21:55:37,774:INFO:Preloading libraries
2024-09-06 21:55:37,776:INFO:Set up data.
2024-09-06 21:55:37,813:INFO:Set up index.
2024-09-06 21:55:38,200:INFO:Initializing get_config()
2024-09-06 21:55:38,200:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, variable=X_train)
2024-09-06 21:55:38,201:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-06 21:55:38,265:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   0.346688  -0.621245   0.751803  -0.065075   0.287760  -0.568749   
41786   0.346688   0.247705   1.885756  -1.548440  -1.893514  -0.568749   
53345   0.346688  -0.476420   1.035291  -0.065075   0.192922  -0.568749   
11745   0.346688  -0.331595   0.184827  -0.435916   0.256147  -0.568749   
23494   0.346688  -0.621245  -2.083079  -1.548440  -1.893514   0.042008   
...          ...        ...        ...        ...        ...        ...   
45374   0.346688  -0.621245   0.184827   1.047449   1.008529   1.263522   
38857   0.346688   2.275255   2.452733  -1.177599   0.003246   0.042008   
31149   0.346688  -0.476420  -0.098661   0.676608   0.463888   0.042008   
55353   0.346688  -0.186770  -0.382150   0.676608   0.572274   0.042008   
1638   -2.884440  -0.041945   1.318780  -1.548440  -1.893514   0.042008   

       feature_6  feature_7  feature_8  feature_9  ...  feature_65  \
71710  -0.064285  -0.358527   0.671466  -1.748812  ...   -0.289253   
41786  -0.633318  -1.437270  -1.726610   0.571817  ...   -0.735184   
53345   1.073782  -0.718108   0.431658   0.571817  ...    1.048540   
11745   0.504749  -0.358527   0.431658   0.571817  ...    0.305321   
23494  -2.055902  -1.437270  -1.726610   0.571817  ...   -1.199696   
...          ...        ...        ...        ...  ...         ...   
45374   0.220232   1.079797   1.025182   0.571817  ...   -0.010546   
38857   1.358299  -1.077689   0.071947   0.571817  ...    1.475890   
31149   0.220232   0.720216   0.311754   0.571817  ...   -0.010546   
55353  -0.348801   0.720216   0.821345  -1.748812  ...   -0.530799   
1638    1.358299  -1.437270  -1.726610   0.571817  ...    1.475890   

       feature_66  feature_67  feature_68  feature_69  feature_70  feature_71  \
71710   -0.430680    0.268206   -1.185610   -0.639733   -0.309181   -0.908491   
41786   -1.188688   -1.537877   -0.082860   -1.031124   -1.370414   -0.908491   
53345   -0.394584    1.016440    1.240441   -0.857173   -0.733674   -0.206090   
11745   -0.214106    0.552019    0.799341   -0.639733   -0.415305    0.145111   
23494   -1.188688   -1.537877   -1.185610   -1.031124   -1.370414   -0.908491   
...           ...         ...         ...         ...         ...         ...   
45374    0.832668    0.830672    0.578791    1.099783    1.471036    1.549912   
38857   -0.755541    0.784229    1.460991   -0.987636   -1.105106   -0.557290   
31149    0.543902    0.216603    0.578791    0.534440    0.433681    1.198712   
55353    0.110755    0.106948   -1.185610    0.534440    0.884705   -0.908491   
1638    -1.188688   -1.537877    1.460991   -1.031124   -1.370414   -0.908491   

       feature_72  feature_73  feature_74  
71710    0.724720   -1.032953   -1.748812  
41786   -1.630463   -1.032953    0.571817  
53345    0.277235    0.866023    0.571817  
11745    0.277235    0.866023    0.571817  
23494   -1.630463   -1.032953    0.571817  
...           ...         ...         ...  
45374    1.470739    1.388242    0.571817  
38857   -0.305673    0.549527    0.571817  
31149    0.071157    0.760525    0.571817  
55353    1.028318   -1.032953   -1.748812  
1638    -1.630463   -1.032953    0.571817  

[53562 rows x 75 columns]
2024-09-06 21:55:38,266:INFO:get_config() successfully completed......................................
2024-09-06 21:55:38,266:INFO:Initializing predict_model()
2024-09-06 21:55:38,266:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024B5930AB00>)
2024-09-06 21:55:38,267:INFO:Checking exceptions
2024-09-06 21:55:38,267:INFO:Preloading libraries
2024-09-06 21:55:38,269:INFO:Set up data.
2024-09-06 21:55:38,306:INFO:Set up index.
2024-09-06 21:55:38,870:INFO:Initializing get_config()
2024-09-06 21:55:38,870:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, variable=y_train)
2024-09-06 21:55:38,870:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-06 21:55:38,897:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-06 21:55:38,898:INFO:get_config() successfully completed......................................
2024-09-06 21:55:38,898:INFO:Initializing get_config()
2024-09-06 21:55:38,898:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, variable=y_test)
2024-09-06 21:55:38,898:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-06 21:55:38,918:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-06 21:55:38,918:INFO:get_config() successfully completed......................................
2024-09-06 21:55:38,923:INFO:Initializing finalize_model()
2024-09-06 21:55:38,923:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 21:55:38,923:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 21:55:38,994:INFO:Initializing create_model()
2024-09-06 21:55:38,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.05, max_depth=4,
               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 21:55:38,994:INFO:Checking exceptions
2024-09-06 21:55:38,995:INFO:Importing libraries
2024-09-06 21:55:38,995:INFO:Copying training dataset
2024-09-06 21:55:39,008:INFO:Defining folds
2024-09-06 21:55:39,008:INFO:Declaring metric variables
2024-09-06 21:55:39,008:INFO:Importing untrained model
2024-09-06 21:55:39,008:INFO:Declaring custom model
2024-09-06 21:55:39,009:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 21:55:39,010:INFO:Cross validation set to False
2024-09-06 21:55:39,010:INFO:Fitting Model
2024-09-06 21:55:39,270:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016093 seconds.
2024-09-06 21:55:39,270:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 21:55:39,271:INFO:[LightGBM] [Info] Total Bins 9320
2024-09-06 21:55:39,271:INFO:[LightGBM] [Info] Number of data points in the train set: 76518, number of used features: 75
2024-09-06 21:55:39,273:INFO:[LightGBM] [Info] Start training from score -1.106880
2024-09-06 21:55:39,273:INFO:[LightGBM] [Info] Start training from score -1.633484
2024-09-06 21:55:39,273:INFO:[LightGBM] [Info] Start training from score -0.746204
2024-09-06 21:55:39,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 21:55:40,914:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.05, max_depth=4,
                                min_child_samples=10, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 21:55:40,914:INFO:create_model() successfully completed......................................
2024-09-06 21:55:41,001:INFO:_master_model_container: 3
2024-09-06 21:55:41,001:INFO:_display_container: 5
2024-09-06 21:55:41,007:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.05, max_depth=4,
                                min_child_samples=10, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 21:55:41,007:INFO:finalize_model() successfully completed......................................
2024-09-06 21:55:41,086:INFO:Initializing predict_model()
2024-09-06 21:55:41,086:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.05, max_depth=4,
                                min_child_samples=10, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024B5930AB00>)
2024-09-06 21:55:41,086:INFO:Checking exceptions
2024-09-06 21:55:41,086:INFO:Preloading libraries
2024-09-06 21:55:41,088:INFO:Set up data.
2024-09-06 21:55:41,124:INFO:Set up index.
2024-09-06 23:00:57,716:INFO:Initializing predict_model()
2024-09-06 23:00:57,720:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.05, max_depth=4,
                                min_child_samples=10, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024B5930A950>)
2024-09-06 23:00:57,720:INFO:Checking exceptions
2024-09-06 23:00:57,720:INFO:Preloading libraries
2024-09-06 23:00:57,774:INFO:Set up data.
2024-09-06 23:00:57,954:INFO:Set up index.
2024-09-06 23:13:50,259:INFO:Initializing predict_model()
2024-09-06 23:13:50,260:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.05, max_depth=4,
                                min_child_samples=10, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024B5930AEF0>)
2024-09-06 23:13:50,260:INFO:Checking exceptions
2024-09-06 23:13:50,260:INFO:Preloading libraries
2024-09-06 23:13:50,262:INFO:Set up data.
2024-09-06 23:13:50,303:INFO:Set up index.
2024-09-06 23:16:03,594:INFO:Initializing predict_model()
2024-09-06 23:16:03,594:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.05, max_depth=4,
                                min_child_samples=10, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024B592CDE10>)
2024-09-06 23:16:03,594:INFO:Checking exceptions
2024-09-06 23:16:03,594:INFO:Preloading libraries
2024-09-06 23:16:03,597:INFO:Set up data.
2024-09-06 23:16:03,633:INFO:Set up index.
2024-09-06 23:16:20,735:INFO:Initializing predict_model()
2024-09-06 23:16:20,736:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024B5766EB60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.05, max_depth=4,
                                min_child_samples=10, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=1.0, reg_lambda=0.1, subsample=0.8,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024B592CDE10>)
2024-09-06 23:16:20,736:INFO:Checking exceptions
2024-09-06 23:16:20,736:INFO:Preloading libraries
2024-09-06 23:16:20,739:INFO:Set up data.
2024-09-06 23:16:20,775:INFO:Set up index.
2024-09-06 23:40:13,914:INFO:Initializing load_model()
2024-09-06 23:40:13,914:INFO:load_model(model_name=SubmitTryPlis, platform=None, authentication=None, verbose=True)
2024-09-06 23:41:44,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 23:41:44,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 23:41:44,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 23:41:44,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 23:42:19,595:INFO:PyCaret ClassificationExperiment
2024-09-06 23:42:19,595:INFO:Logging name: clf-default-name
2024-09-06 23:42:19,595:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-06 23:42:19,595:INFO:version 3.3.2
2024-09-06 23:42:19,595:INFO:Initializing setup()
2024-09-06 23:42:19,595:INFO:self.USI: 55af
2024-09-06 23:42:19,595:INFO:self._variable_keys: {'_available_plots', 'y', 'n_jobs_param', 'seed', 'exp_id', 'fix_imbalance', 'html_param', 'X_test', 'memory', 'X_train', 'X', 'target_param', 'is_multiclass', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'gpu_n_jobs_param', '_ml_usecase', 'exp_name_log', 'idx', 'fold_generator', 'y_test', 'USI', 'pipeline', 'log_plots_param', 'y_train', 'data', 'fold_groups_param'}
2024-09-06 23:42:19,595:INFO:Checking environment
2024-09-06 23:42:19,595:INFO:python_version: 3.10.11
2024-09-06 23:42:19,595:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-06 23:42:19,595:INFO:machine: AMD64
2024-09-06 23:42:19,595:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-06 23:42:19,595:INFO:Memory: svmem(total=17128263680, available=7805767680, percent=54.4, used=9322496000, free=7805767680)
2024-09-06 23:42:19,595:INFO:Physical Core: 6
2024-09-06 23:42:19,595:INFO:Logical Core: 12
2024-09-06 23:42:19,595:INFO:Checking libraries
2024-09-06 23:42:19,595:INFO:System:
2024-09-06 23:42:19,596:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-06 23:42:19,596:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-06 23:42:19,596:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-06 23:42:19,596:INFO:PyCaret required dependencies:
2024-09-06 23:42:19,626:INFO:                 pip: 24.2
2024-09-06 23:42:19,626:INFO:          setuptools: 72.1.0
2024-09-06 23:42:19,626:INFO:             pycaret: 3.3.2
2024-09-06 23:42:19,627:INFO:             IPython: 8.27.0
2024-09-06 23:42:19,627:INFO:          ipywidgets: 8.1.5
2024-09-06 23:42:19,627:INFO:                tqdm: 4.66.5
2024-09-06 23:42:19,627:INFO:               numpy: 1.26.4
2024-09-06 23:42:19,627:INFO:              pandas: 2.2.2
2024-09-06 23:42:19,627:INFO:              jinja2: 3.1.4
2024-09-06 23:42:19,627:INFO:               scipy: 1.11.4
2024-09-06 23:42:19,627:INFO:              joblib: 1.3.2
2024-09-06 23:42:19,627:INFO:             sklearn: 1.4.2
2024-09-06 23:42:19,627:INFO:                pyod: 2.0.1
2024-09-06 23:42:19,627:INFO:            imblearn: 0.12.3
2024-09-06 23:42:19,627:INFO:   category_encoders: 2.6.3
2024-09-06 23:42:19,627:INFO:            lightgbm: 4.5.0
2024-09-06 23:42:19,627:INFO:               numba: 0.60.0
2024-09-06 23:42:19,627:INFO:            requests: 2.32.3
2024-09-06 23:42:19,627:INFO:          matplotlib: 3.7.5
2024-09-06 23:42:19,627:INFO:          scikitplot: 0.3.7
2024-09-06 23:42:19,628:INFO:         yellowbrick: 1.5
2024-09-06 23:42:19,628:INFO:              plotly: 5.24.0
2024-09-06 23:42:19,628:INFO:    plotly-resampler: Not installed
2024-09-06 23:42:19,628:INFO:             kaleido: 0.2.1
2024-09-06 23:42:19,628:INFO:           schemdraw: 0.15
2024-09-06 23:42:19,628:INFO:         statsmodels: 0.14.2
2024-09-06 23:42:19,628:INFO:              sktime: 0.26.0
2024-09-06 23:42:19,628:INFO:               tbats: 1.1.3
2024-09-06 23:42:19,628:INFO:            pmdarima: 2.0.4
2024-09-06 23:42:19,628:INFO:              psutil: 6.0.0
2024-09-06 23:42:19,628:INFO:          markupsafe: 2.1.5
2024-09-06 23:42:19,628:INFO:             pickle5: Not installed
2024-09-06 23:42:19,628:INFO:         cloudpickle: 3.0.0
2024-09-06 23:42:19,628:INFO:         deprecation: 2.1.0
2024-09-06 23:42:19,628:INFO:              xxhash: 3.5.0
2024-09-06 23:42:19,628:INFO:           wurlitzer: Not installed
2024-09-06 23:42:19,628:INFO:PyCaret optional dependencies:
2024-09-06 23:42:19,643:INFO:                shap: Not installed
2024-09-06 23:42:19,643:INFO:           interpret: Not installed
2024-09-06 23:42:19,643:INFO:                umap: Not installed
2024-09-06 23:42:19,643:INFO:     ydata_profiling: Not installed
2024-09-06 23:42:19,643:INFO:  explainerdashboard: Not installed
2024-09-06 23:42:19,644:INFO:             autoviz: Not installed
2024-09-06 23:42:19,644:INFO:           fairlearn: Not installed
2024-09-06 23:42:19,644:INFO:          deepchecks: Not installed
2024-09-06 23:42:19,644:INFO:             xgboost: 2.1.1
2024-09-06 23:42:19,644:INFO:            catboost: Not installed
2024-09-06 23:42:19,644:INFO:              kmodes: Not installed
2024-09-06 23:42:19,644:INFO:             mlxtend: Not installed
2024-09-06 23:42:19,644:INFO:       statsforecast: Not installed
2024-09-06 23:42:19,644:INFO:        tune_sklearn: Not installed
2024-09-06 23:42:19,644:INFO:                 ray: Not installed
2024-09-06 23:42:19,644:INFO:            hyperopt: 0.2.7
2024-09-06 23:42:19,644:INFO:              optuna: 4.0.0
2024-09-06 23:42:19,644:INFO:               skopt: 0.10.2
2024-09-06 23:42:19,644:INFO:              mlflow: Not installed
2024-09-06 23:42:19,644:INFO:              gradio: Not installed
2024-09-06 23:42:19,644:INFO:             fastapi: Not installed
2024-09-06 23:42:19,644:INFO:             uvicorn: Not installed
2024-09-06 23:42:19,644:INFO:              m2cgen: Not installed
2024-09-06 23:42:19,644:INFO:           evidently: Not installed
2024-09-06 23:42:19,644:INFO:               fugue: Not installed
2024-09-06 23:42:19,644:INFO:           streamlit: Not installed
2024-09-06 23:42:19,644:INFO:             prophet: Not installed
2024-09-06 23:42:19,644:INFO:None
2024-09-06 23:42:19,645:INFO:Set up data.
2024-09-06 23:42:20,124:INFO:Set up folding strategy.
2024-09-06 23:42:20,125:INFO:Set up train/test split.
2024-09-06 23:42:20,691:INFO:Set up index.
2024-09-06 23:42:20,709:INFO:Assigning column types.
2024-09-06 23:42:21,343:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-06 23:42:21,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 23:42:21,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 23:42:21,438:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 23:42:21,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 23:42:21,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 23:42:21,492:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 23:42:21,522:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 23:42:21,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 23:42:21,526:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-06 23:42:21,576:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 23:42:21,606:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 23:42:21,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 23:42:21,659:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 23:42:21,690:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 23:42:21,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 23:42:21,693:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-06 23:42:21,773:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 23:42:21,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 23:42:21,857:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 23:42:21,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 23:42:21,861:INFO:Preparing preprocessing pipeline...
2024-09-06 23:42:21,966:INFO:Set up simple imputation.
2024-09-06 23:42:21,966:INFO:Set up imbalanced handling.
2024-09-06 23:42:23,446:INFO:Finished creating preprocessing pipeline.
2024-09-06 23:42:23,456:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-06 23:42:23,456:INFO:Creating final display dataframe.
2024-09-06 23:42:32,541:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 429)
4        Transformed data shape      (99147, 429)
5   Transformed train set shape      (76191, 429)
6    Transformed test set shape      (22956, 429)
7              Numeric features               428
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              55af
2024-09-06 23:42:32,633:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 23:42:32,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 23:42:32,719:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 23:42:32,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-06 23:42:32,723:INFO:setup() successfully completed in 13.16s...............
2024-09-06 23:42:32,728:INFO:Initializing compare_models()
2024-09-06 23:42:32,729:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-06 23:42:32,729:INFO:Checking exceptions
2024-09-06 23:42:33,229:INFO:Preparing display monitor
2024-09-06 23:42:33,252:INFO:Initializing Logistic Regression
2024-09-06 23:42:33,252:INFO:Total runtime is 0.0 minutes
2024-09-06 23:42:33,256:INFO:SubProcess create_model() called ==================================
2024-09-06 23:42:33,256:INFO:Initializing create_model()
2024-09-06 23:42:33,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:42:33,257:INFO:Checking exceptions
2024-09-06 23:42:33,257:INFO:Importing libraries
2024-09-06 23:42:33,257:INFO:Copying training dataset
2024-09-06 23:42:33,961:INFO:Defining folds
2024-09-06 23:42:33,961:INFO:Declaring metric variables
2024-09-06 23:42:33,965:INFO:Importing untrained model
2024-09-06 23:42:33,969:INFO:Logistic Regression Imported successfully
2024-09-06 23:42:33,976:INFO:Starting cross validation
2024-09-06 23:42:33,981:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:45:49,693:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:45:58,116:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:46:01,522:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:46:02,294:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:46:04,339:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:46:04,520:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:46:05,135:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:46:05,778:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:46:05,912:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:46:07,843:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:46:07,875:INFO:Calculating mean and std
2024-09-06 23:46:07,877:INFO:Creating metrics dataframe
2024-09-06 23:46:07,880:INFO:Uploading results into container
2024-09-06 23:46:07,881:INFO:Uploading model into container now
2024-09-06 23:46:07,882:INFO:_master_model_container: 1
2024-09-06 23:46:07,882:INFO:_display_container: 2
2024-09-06 23:46:07,883:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-06 23:46:07,883:INFO:create_model() successfully completed......................................
2024-09-06 23:46:08,054:INFO:SubProcess create_model() end ==================================
2024-09-06 23:46:08,054:INFO:Creating metrics dataframe
2024-09-06 23:46:08,061:INFO:Initializing K Neighbors Classifier
2024-09-06 23:46:08,061:INFO:Total runtime is 3.580144965648651 minutes
2024-09-06 23:46:08,064:INFO:SubProcess create_model() called ==================================
2024-09-06 23:46:08,064:INFO:Initializing create_model()
2024-09-06 23:46:08,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:46:08,065:INFO:Checking exceptions
2024-09-06 23:46:08,065:INFO:Importing libraries
2024-09-06 23:46:08,065:INFO:Copying training dataset
2024-09-06 23:46:08,758:INFO:Defining folds
2024-09-06 23:46:08,758:INFO:Declaring metric variables
2024-09-06 23:46:08,762:INFO:Importing untrained model
2024-09-06 23:46:08,766:INFO:K Neighbors Classifier Imported successfully
2024-09-06 23:46:08,773:INFO:Starting cross validation
2024-09-06 23:46:08,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:46:58,771:INFO:Calculating mean and std
2024-09-06 23:46:58,772:INFO:Creating metrics dataframe
2024-09-06 23:46:58,774:INFO:Uploading results into container
2024-09-06 23:46:58,775:INFO:Uploading model into container now
2024-09-06 23:46:58,775:INFO:_master_model_container: 2
2024-09-06 23:46:58,775:INFO:_display_container: 2
2024-09-06 23:46:58,776:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-06 23:46:58,776:INFO:create_model() successfully completed......................................
2024-09-06 23:46:58,870:INFO:SubProcess create_model() end ==================================
2024-09-06 23:46:58,870:INFO:Creating metrics dataframe
2024-09-06 23:46:58,877:INFO:Initializing Naive Bayes
2024-09-06 23:46:58,877:INFO:Total runtime is 4.42708223660787 minutes
2024-09-06 23:46:58,881:INFO:SubProcess create_model() called ==================================
2024-09-06 23:46:58,881:INFO:Initializing create_model()
2024-09-06 23:46:58,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:46:58,882:INFO:Checking exceptions
2024-09-06 23:46:58,882:INFO:Importing libraries
2024-09-06 23:46:58,882:INFO:Copying training dataset
2024-09-06 23:46:59,550:INFO:Defining folds
2024-09-06 23:46:59,550:INFO:Declaring metric variables
2024-09-06 23:46:59,554:INFO:Importing untrained model
2024-09-06 23:46:59,558:INFO:Naive Bayes Imported successfully
2024-09-06 23:46:59,566:INFO:Starting cross validation
2024-09-06 23:46:59,571:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:47:18,928:INFO:Calculating mean and std
2024-09-06 23:47:18,929:INFO:Creating metrics dataframe
2024-09-06 23:47:18,931:INFO:Uploading results into container
2024-09-06 23:47:18,931:INFO:Uploading model into container now
2024-09-06 23:47:18,932:INFO:_master_model_container: 3
2024-09-06 23:47:18,932:INFO:_display_container: 2
2024-09-06 23:47:18,932:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-06 23:47:18,932:INFO:create_model() successfully completed......................................
2024-09-06 23:47:19,013:INFO:SubProcess create_model() end ==================================
2024-09-06 23:47:19,014:INFO:Creating metrics dataframe
2024-09-06 23:47:19,021:INFO:Initializing Decision Tree Classifier
2024-09-06 23:47:19,021:INFO:Total runtime is 4.762807043393453 minutes
2024-09-06 23:47:19,025:INFO:SubProcess create_model() called ==================================
2024-09-06 23:47:19,025:INFO:Initializing create_model()
2024-09-06 23:47:19,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:47:19,025:INFO:Checking exceptions
2024-09-06 23:47:19,026:INFO:Importing libraries
2024-09-06 23:47:19,026:INFO:Copying training dataset
2024-09-06 23:47:19,672:INFO:Defining folds
2024-09-06 23:47:19,672:INFO:Declaring metric variables
2024-09-06 23:47:19,675:INFO:Importing untrained model
2024-09-06 23:47:19,680:INFO:Decision Tree Classifier Imported successfully
2024-09-06 23:47:19,686:INFO:Starting cross validation
2024-09-06 23:47:19,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:48:12,661:INFO:Calculating mean and std
2024-09-06 23:48:12,662:INFO:Creating metrics dataframe
2024-09-06 23:48:12,665:INFO:Uploading results into container
2024-09-06 23:48:12,665:INFO:Uploading model into container now
2024-09-06 23:48:12,666:INFO:_master_model_container: 4
2024-09-06 23:48:12,666:INFO:_display_container: 2
2024-09-06 23:48:12,666:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-06 23:48:12,666:INFO:create_model() successfully completed......................................
2024-09-06 23:48:12,749:INFO:SubProcess create_model() end ==================================
2024-09-06 23:48:12,749:INFO:Creating metrics dataframe
2024-09-06 23:48:12,757:INFO:Initializing SVM - Linear Kernel
2024-09-06 23:48:12,757:INFO:Total runtime is 5.658407823244731 minutes
2024-09-06 23:48:12,760:INFO:SubProcess create_model() called ==================================
2024-09-06 23:48:12,760:INFO:Initializing create_model()
2024-09-06 23:48:12,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:48:12,761:INFO:Checking exceptions
2024-09-06 23:48:12,761:INFO:Importing libraries
2024-09-06 23:48:12,761:INFO:Copying training dataset
2024-09-06 23:48:13,433:INFO:Defining folds
2024-09-06 23:48:13,433:INFO:Declaring metric variables
2024-09-06 23:48:13,437:INFO:Importing untrained model
2024-09-06 23:48:13,441:INFO:SVM - Linear Kernel Imported successfully
2024-09-06 23:48:13,448:INFO:Starting cross validation
2024-09-06 23:48:13,454:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:48:48,686:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:50,646:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:51,253:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:51,511:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:52,219:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:52,547:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:52,874:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:52,986:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:53,165:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:53,434:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:48:53,462:INFO:Calculating mean and std
2024-09-06 23:48:53,463:INFO:Creating metrics dataframe
2024-09-06 23:48:53,465:INFO:Uploading results into container
2024-09-06 23:48:53,465:INFO:Uploading model into container now
2024-09-06 23:48:53,466:INFO:_master_model_container: 5
2024-09-06 23:48:53,466:INFO:_display_container: 2
2024-09-06 23:48:53,466:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-06 23:48:53,467:INFO:create_model() successfully completed......................................
2024-09-06 23:48:53,542:INFO:SubProcess create_model() end ==================================
2024-09-06 23:48:53,542:INFO:Creating metrics dataframe
2024-09-06 23:48:53,550:INFO:Initializing Ridge Classifier
2024-09-06 23:48:53,551:INFO:Total runtime is 6.338306228319804 minutes
2024-09-06 23:48:53,554:INFO:SubProcess create_model() called ==================================
2024-09-06 23:48:53,554:INFO:Initializing create_model()
2024-09-06 23:48:53,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:48:53,555:INFO:Checking exceptions
2024-09-06 23:48:53,555:INFO:Importing libraries
2024-09-06 23:48:53,555:INFO:Copying training dataset
2024-09-06 23:48:54,193:INFO:Defining folds
2024-09-06 23:48:54,193:INFO:Declaring metric variables
2024-09-06 23:48:54,197:INFO:Importing untrained model
2024-09-06 23:48:54,201:INFO:Ridge Classifier Imported successfully
2024-09-06 23:48:54,210:INFO:Starting cross validation
2024-09-06 23:48:54,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:49:10,437:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:10,982:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:11,254:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:11,809:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:12,045:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:12,318:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:12,634:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:12,808:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:13,009:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:13,283:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:49:13,308:INFO:Calculating mean and std
2024-09-06 23:49:13,309:INFO:Creating metrics dataframe
2024-09-06 23:49:13,312:INFO:Uploading results into container
2024-09-06 23:49:13,313:INFO:Uploading model into container now
2024-09-06 23:49:13,313:INFO:_master_model_container: 6
2024-09-06 23:49:13,313:INFO:_display_container: 2
2024-09-06 23:49:13,314:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-06 23:49:13,314:INFO:create_model() successfully completed......................................
2024-09-06 23:49:13,389:INFO:SubProcess create_model() end ==================================
2024-09-06 23:49:13,389:INFO:Creating metrics dataframe
2024-09-06 23:49:13,397:INFO:Initializing Random Forest Classifier
2024-09-06 23:49:13,397:INFO:Total runtime is 6.669078878561656 minutes
2024-09-06 23:49:13,400:INFO:SubProcess create_model() called ==================================
2024-09-06 23:49:13,401:INFO:Initializing create_model()
2024-09-06 23:49:13,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:49:13,401:INFO:Checking exceptions
2024-09-06 23:49:13,401:INFO:Importing libraries
2024-09-06 23:49:13,401:INFO:Copying training dataset
2024-09-06 23:49:14,020:INFO:Defining folds
2024-09-06 23:49:14,020:INFO:Declaring metric variables
2024-09-06 23:49:14,024:INFO:Importing untrained model
2024-09-06 23:49:14,028:INFO:Random Forest Classifier Imported successfully
2024-09-06 23:49:14,036:INFO:Starting cross validation
2024-09-06 23:49:14,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:50:56,871:INFO:Calculating mean and std
2024-09-06 23:50:56,873:INFO:Creating metrics dataframe
2024-09-06 23:50:56,876:INFO:Uploading results into container
2024-09-06 23:50:56,877:INFO:Uploading model into container now
2024-09-06 23:50:56,878:INFO:_master_model_container: 7
2024-09-06 23:50:56,878:INFO:_display_container: 2
2024-09-06 23:50:56,879:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-06 23:50:56,879:INFO:create_model() successfully completed......................................
2024-09-06 23:50:56,971:INFO:SubProcess create_model() end ==================================
2024-09-06 23:50:56,971:INFO:Creating metrics dataframe
2024-09-06 23:50:56,982:INFO:Initializing Quadratic Discriminant Analysis
2024-09-06 23:50:56,982:INFO:Total runtime is 8.395493968327841 minutes
2024-09-06 23:50:56,987:INFO:SubProcess create_model() called ==================================
2024-09-06 23:50:56,987:INFO:Initializing create_model()
2024-09-06 23:50:56,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:50:56,987:INFO:Checking exceptions
2024-09-06 23:50:56,988:INFO:Importing libraries
2024-09-06 23:50:56,988:INFO:Copying training dataset
2024-09-06 23:50:57,811:INFO:Defining folds
2024-09-06 23:50:57,811:INFO:Declaring metric variables
2024-09-06 23:50:57,817:INFO:Importing untrained model
2024-09-06 23:50:57,824:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-06 23:50:57,835:INFO:Starting cross validation
2024-09-06 23:50:57,844:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:51:15,304:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:16,244:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:17,946:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:18,737:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:20,483:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:22,371:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:23,220:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:23,688:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:23,756:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:24,675:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:25,007:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-06 23:51:25,234:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:27,469:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:28,368:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:29,095:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:29,790:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:30,107:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:30,187:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:30,519:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:30,638:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:51:30,676:INFO:Calculating mean and std
2024-09-06 23:51:30,677:INFO:Creating metrics dataframe
2024-09-06 23:51:30,679:INFO:Uploading results into container
2024-09-06 23:51:30,681:INFO:Uploading model into container now
2024-09-06 23:51:30,681:INFO:_master_model_container: 8
2024-09-06 23:51:30,681:INFO:_display_container: 2
2024-09-06 23:51:30,682:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-06 23:51:30,682:INFO:create_model() successfully completed......................................
2024-09-06 23:51:30,762:INFO:SubProcess create_model() end ==================================
2024-09-06 23:51:30,762:INFO:Creating metrics dataframe
2024-09-06 23:51:30,773:INFO:Initializing Ada Boost Classifier
2024-09-06 23:51:30,773:INFO:Total runtime is 8.958673075834911 minutes
2024-09-06 23:51:30,777:INFO:SubProcess create_model() called ==================================
2024-09-06 23:51:30,777:INFO:Initializing create_model()
2024-09-06 23:51:30,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:51:30,777:INFO:Checking exceptions
2024-09-06 23:51:30,778:INFO:Importing libraries
2024-09-06 23:51:30,778:INFO:Copying training dataset
2024-09-06 23:51:31,448:INFO:Defining folds
2024-09-06 23:51:31,448:INFO:Declaring metric variables
2024-09-06 23:51:31,452:INFO:Importing untrained model
2024-09-06 23:51:31,456:INFO:Ada Boost Classifier Imported successfully
2024-09-06 23:51:31,464:INFO:Starting cross validation
2024-09-06 23:51:31,470:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:51:47,223:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:51:47,804:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:51:48,129:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:51:48,532:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:51:48,923:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:51:49,592:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:51:49,753:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:51:50,126:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:51:50,443:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:51:50,737:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:53:06,613:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:07,211:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:07,276:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:07,549:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:07,939:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:08,452:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:08,545:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:08,700:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:08,887:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:09,003:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-06 23:53:09,028:INFO:Calculating mean and std
2024-09-06 23:53:09,029:INFO:Creating metrics dataframe
2024-09-06 23:53:09,031:INFO:Uploading results into container
2024-09-06 23:53:09,032:INFO:Uploading model into container now
2024-09-06 23:53:09,033:INFO:_master_model_container: 9
2024-09-06 23:53:09,033:INFO:_display_container: 2
2024-09-06 23:53:09,033:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-06 23:53:09,033:INFO:create_model() successfully completed......................................
2024-09-06 23:53:09,112:INFO:SubProcess create_model() end ==================================
2024-09-06 23:53:09,112:INFO:Creating metrics dataframe
2024-09-06 23:53:09,123:INFO:Initializing Gradient Boosting Classifier
2024-09-06 23:53:09,124:INFO:Total runtime is 10.597858663400014 minutes
2024-09-06 23:53:09,128:INFO:SubProcess create_model() called ==================================
2024-09-06 23:53:09,128:INFO:Initializing create_model()
2024-09-06 23:53:09,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:53:09,128:INFO:Checking exceptions
2024-09-06 23:53:09,129:INFO:Importing libraries
2024-09-06 23:53:09,129:INFO:Copying training dataset
2024-09-06 23:53:09,761:INFO:Defining folds
2024-09-06 23:53:09,761:INFO:Declaring metric variables
2024-09-06 23:53:09,765:INFO:Importing untrained model
2024-09-06 23:53:09,769:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 23:53:09,776:INFO:Starting cross validation
2024-09-06 23:53:09,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 00:13:16,138:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:17,582:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:17,675:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:20,093:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:21,575:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:21,593:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:22,057:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:22,331:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:22,498:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:25,014:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:25,071:INFO:Calculating mean and std
2024-09-07 00:13:25,081:INFO:Creating metrics dataframe
2024-09-07 00:13:25,088:INFO:Uploading results into container
2024-09-07 00:13:25,090:INFO:Uploading model into container now
2024-09-07 00:13:25,092:INFO:_master_model_container: 10
2024-09-07 00:13:25,092:INFO:_display_container: 2
2024-09-07 00:13:25,094:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-07 00:13:25,094:INFO:create_model() successfully completed......................................
2024-09-07 00:13:25,221:INFO:SubProcess create_model() end ==================================
2024-09-07 00:13:25,221:INFO:Creating metrics dataframe
2024-09-07 00:13:25,236:INFO:Initializing Linear Discriminant Analysis
2024-09-07 00:13:25,236:INFO:Total runtime is 30.86639025211334 minutes
2024-09-07 00:13:25,241:INFO:SubProcess create_model() called ==================================
2024-09-07 00:13:25,241:INFO:Initializing create_model()
2024-09-07 00:13:25,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 00:13:25,242:INFO:Checking exceptions
2024-09-07 00:13:25,242:INFO:Importing libraries
2024-09-07 00:13:25,242:INFO:Copying training dataset
2024-09-07 00:13:25,974:INFO:Defining folds
2024-09-07 00:13:25,974:INFO:Declaring metric variables
2024-09-07 00:13:25,978:INFO:Importing untrained model
2024-09-07 00:13:25,982:INFO:Linear Discriminant Analysis Imported successfully
2024-09-07 00:13:25,989:INFO:Starting cross validation
2024-09-07 00:13:26,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 00:13:47,547:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:49,448:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:50,116:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:51,784:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:53,720:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:54,392:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:54,556:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:54,779:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:55,034:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:55,311:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 00:13:55,340:INFO:Calculating mean and std
2024-09-07 00:13:55,341:INFO:Creating metrics dataframe
2024-09-07 00:13:55,344:INFO:Uploading results into container
2024-09-07 00:13:55,345:INFO:Uploading model into container now
2024-09-07 00:13:55,346:INFO:_master_model_container: 11
2024-09-07 00:13:55,346:INFO:_display_container: 2
2024-09-07 00:13:55,347:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-07 00:13:55,347:INFO:create_model() successfully completed......................................
2024-09-07 00:13:55,430:INFO:SubProcess create_model() end ==================================
2024-09-07 00:13:55,431:INFO:Creating metrics dataframe
2024-09-07 00:13:55,443:INFO:Initializing Extra Trees Classifier
2024-09-07 00:13:55,443:INFO:Total runtime is 31.369843061765035 minutes
2024-09-07 00:13:55,448:INFO:SubProcess create_model() called ==================================
2024-09-07 00:13:55,448:INFO:Initializing create_model()
2024-09-07 00:13:55,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 00:13:55,449:INFO:Checking exceptions
2024-09-07 00:13:55,449:INFO:Importing libraries
2024-09-07 00:13:55,449:INFO:Copying training dataset
2024-09-07 00:13:56,093:INFO:Defining folds
2024-09-07 00:13:56,093:INFO:Declaring metric variables
2024-09-07 00:13:56,098:INFO:Importing untrained model
2024-09-07 00:13:56,102:INFO:Extra Trees Classifier Imported successfully
2024-09-07 00:13:56,110:INFO:Starting cross validation
2024-09-07 00:13:56,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 00:15:38,865:INFO:Calculating mean and std
2024-09-07 00:15:38,866:INFO:Creating metrics dataframe
2024-09-07 00:15:38,869:INFO:Uploading results into container
2024-09-07 00:15:38,870:INFO:Uploading model into container now
2024-09-07 00:15:38,871:INFO:_master_model_container: 12
2024-09-07 00:15:38,871:INFO:_display_container: 2
2024-09-07 00:15:38,872:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-07 00:15:38,872:INFO:create_model() successfully completed......................................
2024-09-07 00:15:38,981:INFO:SubProcess create_model() end ==================================
2024-09-07 00:15:38,981:INFO:Creating metrics dataframe
2024-09-07 00:15:38,993:INFO:Initializing Extreme Gradient Boosting
2024-09-07 00:15:38,993:INFO:Total runtime is 33.0956808924675 minutes
2024-09-07 00:15:38,998:INFO:SubProcess create_model() called ==================================
2024-09-07 00:15:38,998:INFO:Initializing create_model()
2024-09-07 00:15:38,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 00:15:38,998:INFO:Checking exceptions
2024-09-07 00:15:38,998:INFO:Importing libraries
2024-09-07 00:15:38,999:INFO:Copying training dataset
2024-09-07 00:15:39,826:INFO:Defining folds
2024-09-07 00:15:39,826:INFO:Declaring metric variables
2024-09-07 00:15:39,832:INFO:Importing untrained model
2024-09-07 00:15:39,838:INFO:Extreme Gradient Boosting Imported successfully
2024-09-07 00:15:39,849:INFO:Starting cross validation
2024-09-07 00:15:39,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 00:17:10,754:INFO:Calculating mean and std
2024-09-07 00:17:10,755:INFO:Creating metrics dataframe
2024-09-07 00:17:10,758:INFO:Uploading results into container
2024-09-07 00:17:10,759:INFO:Uploading model into container now
2024-09-07 00:17:10,759:INFO:_master_model_container: 13
2024-09-07 00:17:10,759:INFO:_display_container: 2
2024-09-07 00:17:10,761:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-07 00:17:10,761:INFO:create_model() successfully completed......................................
2024-09-07 00:17:10,843:INFO:SubProcess create_model() end ==================================
2024-09-07 00:17:10,843:INFO:Creating metrics dataframe
2024-09-07 00:17:10,855:INFO:Initializing Light Gradient Boosting Machine
2024-09-07 00:17:10,855:INFO:Total runtime is 34.62670944531759 minutes
2024-09-07 00:17:10,858:INFO:SubProcess create_model() called ==================================
2024-09-07 00:17:10,858:INFO:Initializing create_model()
2024-09-07 00:17:10,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 00:17:10,860:INFO:Checking exceptions
2024-09-07 00:17:10,860:INFO:Importing libraries
2024-09-07 00:17:10,860:INFO:Copying training dataset
2024-09-07 00:17:11,484:INFO:Defining folds
2024-09-07 00:17:11,484:INFO:Declaring metric variables
2024-09-07 00:17:11,489:INFO:Importing untrained model
2024-09-07 00:17:11,493:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 00:17:11,501:INFO:Starting cross validation
2024-09-07 00:17:11,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 00:19:38,713:INFO:Calculating mean and std
2024-09-07 00:19:38,715:INFO:Creating metrics dataframe
2024-09-07 00:19:38,719:INFO:Uploading results into container
2024-09-07 00:19:38,720:INFO:Uploading model into container now
2024-09-07 00:19:38,720:INFO:_master_model_container: 14
2024-09-07 00:19:38,720:INFO:_display_container: 2
2024-09-07 00:19:38,727:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 00:19:38,727:INFO:create_model() successfully completed......................................
2024-09-07 00:19:38,821:INFO:SubProcess create_model() end ==================================
2024-09-07 00:19:38,821:INFO:Creating metrics dataframe
2024-09-07 00:19:38,836:INFO:Initializing Dummy Classifier
2024-09-07 00:19:38,836:INFO:Total runtime is 37.0930534640948 minutes
2024-09-07 00:19:38,840:INFO:SubProcess create_model() called ==================================
2024-09-07 00:19:38,841:INFO:Initializing create_model()
2024-09-07 00:19:38,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE121CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 00:19:38,841:INFO:Checking exceptions
2024-09-07 00:19:38,841:INFO:Importing libraries
2024-09-07 00:19:38,842:INFO:Copying training dataset
2024-09-07 00:19:39,585:INFO:Defining folds
2024-09-07 00:19:39,585:INFO:Declaring metric variables
2024-09-07 00:19:39,589:INFO:Importing untrained model
2024-09-07 00:19:39,600:INFO:Dummy Classifier Imported successfully
2024-09-07 00:19:39,609:INFO:Starting cross validation
2024-09-07 00:19:39,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 00:19:56,164:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:56,781:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:57,260:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:57,598:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:58,330:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:58,549:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:58,847:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:59,233:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:59,412:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:59,666:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-07 00:19:59,680:INFO:Calculating mean and std
2024-09-07 00:19:59,681:INFO:Creating metrics dataframe
2024-09-07 00:19:59,683:INFO:Uploading results into container
2024-09-07 00:19:59,685:INFO:Uploading model into container now
2024-09-07 00:19:59,685:INFO:_master_model_container: 15
2024-09-07 00:19:59,685:INFO:_display_container: 2
2024-09-07 00:19:59,686:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-07 00:19:59,686:INFO:create_model() successfully completed......................................
2024-09-07 00:19:59,775:INFO:SubProcess create_model() end ==================================
2024-09-07 00:19:59,775:INFO:Creating metrics dataframe
2024-09-07 00:19:59,800:INFO:Initializing create_model()
2024-09-07 00:19:59,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 00:19:59,801:INFO:Checking exceptions
2024-09-07 00:19:59,806:INFO:Importing libraries
2024-09-07 00:19:59,806:INFO:Copying training dataset
2024-09-07 00:20:00,482:INFO:Defining folds
2024-09-07 00:20:00,482:INFO:Declaring metric variables
2024-09-07 00:20:00,482:INFO:Importing untrained model
2024-09-07 00:20:00,482:INFO:Declaring custom model
2024-09-07 00:20:00,483:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 00:20:00,489:INFO:Cross validation set to False
2024-09-07 00:20:00,489:INFO:Fitting Model
2024-09-07 00:20:05,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129886 seconds.
2024-09-07 00:20:05,344:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 00:20:05,351:INFO:[LightGBM] [Info] Total Bins 102853
2024-09-07 00:20:05,356:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 427
2024-09-07 00:20:05,356:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:20:05,356:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:20:05,356:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:20:16,147:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 00:20:16,147:INFO:create_model() successfully completed......................................
2024-09-07 00:20:16,270:INFO:_master_model_container: 15
2024-09-07 00:20:16,270:INFO:_display_container: 2
2024-09-07 00:20:16,270:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 00:20:16,270:INFO:compare_models() successfully completed......................................
2024-09-07 00:20:16,281:INFO:Initializing create_model()
2024-09-07 00:20:16,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 00:20:16,282:INFO:Checking exceptions
2024-09-07 00:20:16,301:INFO:Importing libraries
2024-09-07 00:20:16,301:INFO:Copying training dataset
2024-09-07 00:20:16,971:INFO:Defining folds
2024-09-07 00:20:16,971:INFO:Declaring metric variables
2024-09-07 00:20:16,975:INFO:Importing untrained model
2024-09-07 00:20:16,979:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 00:20:16,987:INFO:Starting cross validation
2024-09-07 00:20:16,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 00:23:07,157:INFO:Calculating mean and std
2024-09-07 00:23:07,159:INFO:Creating metrics dataframe
2024-09-07 00:23:07,163:INFO:Finalizing model
2024-09-07 00:23:12,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138471 seconds.
2024-09-07 00:23:12,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 00:23:12,375:INFO:[LightGBM] [Info] Total Bins 102853
2024-09-07 00:23:12,379:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 427
2024-09-07 00:23:12,381:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:23:12,381:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:23:12,382:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:23:22,890:INFO:Uploading results into container
2024-09-07 00:23:22,891:INFO:Uploading model into container now
2024-09-07 00:23:22,906:INFO:_master_model_container: 16
2024-09-07 00:23:22,907:INFO:_display_container: 3
2024-09-07 00:23:22,907:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 00:23:22,908:INFO:create_model() successfully completed......................................
2024-09-07 00:23:23,019:INFO:Initializing tune_model()
2024-09-07 00:23:23,019:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5], 'num_leaves': [20, 31, 40], 'min_child_samples': [10, 20, 30], 'subsample': [0.7, 0.8, 0.9], 'colsample_bytree': [0.7, 0.8], 'reg_alpha': [0.1, 0.5, 1.0], 'reg_lambda': [0.1, 0.5, 1.0]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=True, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>)
2024-09-07 00:23:23,019:INFO:Checking exceptions
2024-09-07 00:23:23,019:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-07 00:23:23,414:INFO:Copying training dataset
2024-09-07 00:23:23,805:INFO:Checking base model
2024-09-07 00:23:23,806:INFO:Base model : Light Gradient Boosting Machine
2024-09-07 00:23:23,806:INFO:Declaring metric variables
2024-09-07 00:23:23,807:INFO:Defining Hyperparameters
2024-09-07 00:23:23,885:INFO:custom_grid: {'actual_estimator__learning_rate': CategoricalDistribution(values=[0.01, 0.05, 0.1]), 'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 4, 5]), 'actual_estimator__num_leaves': CategoricalDistribution(values=[20, 31, 40]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[10, 20, 30]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.7, 0.8, 0.9]), 'actual_estimator__colsample_bytree': CategoricalDistribution(values=[0.7, 0.8]), 'actual_estimator__reg_alpha': CategoricalDistribution(values=[0.1, 0.5, 1.0]), 'actual_estimator__reg_lambda': CategoricalDistribution(values=[0.1, 0.5, 1.0])}
2024-09-07 00:23:23,885:INFO:Tuning with n_jobs=-1
2024-09-07 00:23:23,890:INFO:Initializing skopt.BayesSearchCV
2024-09-07 00:31:22,339:INFO:best_params: OrderedDict([('actual_estimator__colsample_bytree', 0.7), ('actual_estimator__learning_rate', 0.1), ('actual_estimator__max_depth', 4), ('actual_estimator__min_child_samples', 30), ('actual_estimator__n_estimators', 200), ('actual_estimator__num_leaves', 20), ('actual_estimator__reg_alpha', 0.1), ('actual_estimator__reg_lambda', 0.5), ('actual_estimator__subsample', 0.7)])
2024-09-07 00:31:22,339:INFO:Hyperparameter search completed
2024-09-07 00:31:22,339:INFO:SubProcess create_model() called ==================================
2024-09-07 00:31:22,339:INFO:Initializing create_model()
2024-09-07 00:31:22,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021FBE213BB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_samples': 30, 'n_estimators': 200, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'subsample': 0.7})
2024-09-07 00:31:22,339:INFO:Checking exceptions
2024-09-07 00:31:22,339:INFO:Importing libraries
2024-09-07 00:31:22,339:INFO:Copying training dataset
2024-09-07 00:31:23,070:INFO:Defining folds
2024-09-07 00:31:23,070:INFO:Declaring metric variables
2024-09-07 00:31:23,071:INFO:Importing untrained model
2024-09-07 00:31:23,071:INFO:Declaring custom model
2024-09-07 00:31:23,071:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 00:31:23,072:INFO:Starting cross validation
2024-09-07 00:31:23,079:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 00:32:35,203:INFO:Calculating mean and std
2024-09-07 00:32:35,204:INFO:Creating metrics dataframe
2024-09-07 00:32:35,206:INFO:Finalizing model
2024-09-07 00:32:40,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.137923 seconds.
2024-09-07 00:32:40,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 00:32:40,289:INFO:[LightGBM] [Info] Total Bins 102853
2024-09-07 00:32:40,291:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 427
2024-09-07 00:32:40,294:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:32:40,294:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:32:40,294:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:32:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:40,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:41,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:42,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:43,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:44,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:45,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:46,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:47,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:48,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:49,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:49,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:49,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:49,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:49,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:49,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:32:49,123:INFO:Uploading results into container
2024-09-07 00:32:49,123:INFO:Uploading model into container now
2024-09-07 00:32:49,123:INFO:_master_model_container: 17
2024-09-07 00:32:49,123:INFO:_display_container: 4
2024-09-07 00:32:49,126:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.1, max_depth=4,
               min_child_samples=30, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 00:32:49,126:INFO:create_model() successfully completed......................................
2024-09-07 00:32:49,236:INFO:SubProcess create_model() end ==================================
2024-09-07 00:32:49,236:INFO:choose_better activated
2024-09-07 00:32:49,236:INFO:SubProcess create_model() called ==================================
2024-09-07 00:32:49,239:INFO:Initializing create_model()
2024-09-07 00:32:49,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 00:32:49,239:INFO:Checking exceptions
2024-09-07 00:32:49,240:INFO:Importing libraries
2024-09-07 00:32:49,240:INFO:Copying training dataset
2024-09-07 00:32:49,931:INFO:Defining folds
2024-09-07 00:32:49,931:INFO:Declaring metric variables
2024-09-07 00:32:49,931:INFO:Importing untrained model
2024-09-07 00:32:49,931:INFO:Declaring custom model
2024-09-07 00:32:49,932:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 00:32:49,933:INFO:Starting cross validation
2024-09-07 00:32:49,939:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 00:33:58,546:INFO:Calculating mean and std
2024-09-07 00:33:58,547:INFO:Creating metrics dataframe
2024-09-07 00:33:58,550:INFO:Finalizing model
2024-09-07 00:34:03,317:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.150445 seconds.
2024-09-07 00:34:03,317:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 00:34:03,324:INFO:[LightGBM] [Info] Total Bins 102853
2024-09-07 00:34:03,325:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 427
2024-09-07 00:34:03,332:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:34:03,332:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:34:03,332:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:34:14,103:INFO:Uploading results into container
2024-09-07 00:34:14,103:INFO:Uploading model into container now
2024-09-07 00:34:14,103:INFO:_master_model_container: 18
2024-09-07 00:34:14,103:INFO:_display_container: 5
2024-09-07 00:34:14,103:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 00:34:14,103:INFO:create_model() successfully completed......................................
2024-09-07 00:34:14,209:INFO:SubProcess create_model() end ==================================
2024-09-07 00:34:14,209:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8278
2024-09-07 00:34:14,209:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.1, max_depth=4,
               min_child_samples=30, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8292
2024-09-07 00:34:14,211:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.1, max_depth=4,
               min_child_samples=30, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-07 00:34:14,211:INFO:choose_better completed
2024-09-07 00:34:14,211:INFO:_master_model_container: 18
2024-09-07 00:34:14,211:INFO:_display_container: 4
2024-09-07 00:34:14,212:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.1, max_depth=4,
               min_child_samples=30, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 00:34:14,212:INFO:tune_model() successfully completed......................................
2024-09-07 00:35:27,771:INFO:Initializing predict_model()
2024-09-07 00:35:27,771:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.1, max_depth=4,
               min_child_samples=30, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021FC6D4BE20>)
2024-09-07 00:35:27,772:INFO:Checking exceptions
2024-09-07 00:35:27,772:INFO:Preloading libraries
2024-09-07 00:35:27,775:INFO:Set up data.
2024-09-07 00:35:28,227:INFO:Set up index.
2024-09-07 00:35:29,333:INFO:Initializing get_config()
2024-09-07 00:35:29,333:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, variable=X_train)
2024-09-07 00:35:29,333:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-07 00:35:29,591:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.903637   2.736559   0.372071   0.304834  -0.307305   
41786   1.144238   1.373649  -0.522903   0.083904   0.304834   1.787297   
53345  -0.499730  -0.903637  -0.522903   0.083904   0.304834  -0.307305   
11745  -0.742247   0.055220  -0.522903   0.049743   0.304834  -0.307305   
23494   0.829220  -0.903637  -0.522903   0.134044   0.304834  -0.307305   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.903637  -0.522903   0.278403   0.304834  -0.307305   
38857  -1.387282   1.373649  -0.522903  -0.540365  -3.280477   1.787297   
31149   0.765373  -0.903637   0.291962   0.428822   0.304834  -0.307305   
55353   0.715438  -0.903637  -0.522903   0.134044   0.304834  -0.307305   
1638   -0.827527   0.055220  -0.522903   0.428822   0.304834  -0.307305   

       feature_6  feature_7  feature_8  feature_9  ...  feature_418  \
71710  -0.216109   1.112682   0.908807  -0.037036  ...    -0.086278   
41786   0.066573  -1.226048  -1.505896  -2.020844  ...    -0.086278   
53345  -1.127987   1.112682   0.908807  -0.554897  ...    -0.086278   
11745  -0.854424  -0.056683   0.975882  -0.969187  ...     6.167595   
23494   3.249027  -0.056683   1.042958   2.839088  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374   1.516459   1.112682   0.908807   1.126161  ...    -0.086278   
38857  -2.039865  -0.056683   0.707582  -1.502983  ...    -0.086278   
31149  -0.033734  -0.056683   0.975882   0.560497  ...    -0.086278   
55353  -0.216109  -0.056683   0.975882   0.608300  ...    -0.086278   
1638   -0.854424  -0.056683   0.908807  -0.825779  ...    -0.086278   

       feature_419  feature_420  feature_421  feature_422  feature_423  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_424  feature_425  feature_426  feature_427  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 428 columns]
2024-09-07 00:35:29,591:INFO:get_config() successfully completed......................................
2024-09-07 00:35:29,592:INFO:Initializing predict_model()
2024-09-07 00:35:29,592:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.1, max_depth=4,
               min_child_samples=30, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021FBC719000>)
2024-09-07 00:35:29,592:INFO:Checking exceptions
2024-09-07 00:35:29,592:INFO:Preloading libraries
2024-09-07 00:35:29,594:INFO:Set up data.
2024-09-07 00:35:29,867:INFO:Set up index.
2024-09-07 00:35:31,430:INFO:Initializing get_config()
2024-09-07 00:35:31,430:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, variable=y_train)
2024-09-07 00:35:31,430:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-07 00:35:31,588:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-07 00:35:31,588:INFO:get_config() successfully completed......................................
2024-09-07 00:35:31,588:INFO:Initializing get_config()
2024-09-07 00:35:31,588:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, variable=y_test)
2024-09-07 00:35:31,588:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-07 00:35:31,705:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-07 00:35:31,705:INFO:get_config() successfully completed......................................
2024-09-07 00:35:31,712:INFO:Initializing finalize_model()
2024-09-07 00:35:31,712:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.1, max_depth=4,
               min_child_samples=30, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-07 00:35:31,713:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.1, max_depth=4,
               min_child_samples=30, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 00:35:32,155:INFO:Initializing create_model()
2024-09-07 00:35:32,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,
               importance_type='split', learning_rate=0.1, max_depth=4,
               min_child_samples=30, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=20, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 00:35:32,155:INFO:Checking exceptions
2024-09-07 00:35:32,156:INFO:Importing libraries
2024-09-07 00:35:32,156:INFO:Copying training dataset
2024-09-07 00:35:32,241:INFO:Defining folds
2024-09-07 00:35:32,241:INFO:Declaring metric variables
2024-09-07 00:35:32,241:INFO:Importing untrained model
2024-09-07 00:35:32,241:INFO:Declaring custom model
2024-09-07 00:35:32,243:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 00:35:32,250:INFO:Cross validation set to False
2024-09-07 00:35:32,250:INFO:Fitting Model
2024-09-07 00:35:39,892:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204254 seconds.
2024-09-07 00:35:39,892:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 00:35:39,906:INFO:[LightGBM] [Info] Total Bins 103969
2024-09-07 00:35:39,908:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 427
2024-09-07 00:35:39,910:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:35:39,910:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:35:39,910:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 00:35:39,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:39,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:39,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:40,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:41,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:42,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:44,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:45,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:46,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:47,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:48,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:49,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:50,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 00:35:51,015:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.1, max_depth=4,
                                min_child_samples=30, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-07 00:35:51,015:INFO:create_model() successfully completed......................................
2024-09-07 00:35:51,128:INFO:_master_model_container: 18
2024-09-07 00:35:51,128:INFO:_display_container: 5
2024-09-07 00:35:51,140:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.1, max_depth=4,
                                min_child_samples=30, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-07 00:35:51,141:INFO:finalize_model() successfully completed......................................
2024-09-07 00:36:46,393:INFO:Initializing predict_model()
2024-09-07 00:36:46,393:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.1, max_depth=4,
                                min_child_samples=30, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021FBC719000>)
2024-09-07 00:36:46,394:INFO:Checking exceptions
2024-09-07 00:36:46,394:INFO:Preloading libraries
2024-09-07 00:36:46,397:INFO:Set up data.
2024-09-07 00:36:46,687:INFO:Set up index.
2024-09-07 00:39:43,767:INFO:Initializing predict_model()
2024-09-07 00:39:43,767:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021FBC7246A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=0.7, importance_type='split',
                                learning_rate=0.1, max_depth=4,
                                min_child_samples=30, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=200, n_jobs=-1,
                                num_leaves=20, objective=None, random_state=123,
                                reg_alpha=0.1, reg_lambda=0.5, subsample=0.7,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021FC3CFFF40>)
2024-09-07 00:39:43,767:INFO:Checking exceptions
2024-09-07 00:39:43,767:INFO:Preloading libraries
2024-09-07 00:39:43,770:INFO:Set up data.
2024-09-07 00:39:44,021:INFO:Set up index.
2024-09-07 15:11:50,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:11:50,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:11:50,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:11:50,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:16:23,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:16:23,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:16:23,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:16:23,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:17:01,617:INFO:PyCaret ClassificationExperiment
2024-09-07 15:17:01,617:INFO:Logging name: clf-default-name
2024-09-07 15:17:01,617:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 15:17:01,617:INFO:version 3.3.2
2024-09-07 15:17:01,617:INFO:Initializing setup()
2024-09-07 15:17:01,617:INFO:self.USI: 13b3
2024-09-07 15:17:01,617:INFO:self._variable_keys: {'X_train', 'exp_name_log', 'exp_id', 'y', 'USI', 'idx', 'target_param', 'seed', 'pipeline', 'fold_shuffle_param', 'y_test', 'is_multiclass', 'html_param', 'gpu_n_jobs_param', 'data', 'log_plots_param', 'memory', 'fold_groups_param', 'fold_generator', 'logging_param', 'X', 'gpu_param', 'n_jobs_param', 'X_test', '_available_plots', 'fix_imbalance', 'y_train', '_ml_usecase'}
2024-09-07 15:17:01,617:INFO:Checking environment
2024-09-07 15:17:01,617:INFO:python_version: 3.10.11
2024-09-07 15:17:01,617:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 15:17:01,617:INFO:machine: AMD64
2024-09-07 15:17:01,617:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 15:17:01,617:INFO:Memory: svmem(total=17128263680, available=3955568640, percent=76.9, used=13172695040, free=3955568640)
2024-09-07 15:17:01,617:INFO:Physical Core: 6
2024-09-07 15:17:01,617:INFO:Logical Core: 12
2024-09-07 15:17:01,617:INFO:Checking libraries
2024-09-07 15:17:01,617:INFO:System:
2024-09-07 15:17:01,617:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 15:17:01,618:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 15:17:01,618:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 15:17:01,618:INFO:PyCaret required dependencies:
2024-09-07 15:17:01,647:INFO:                 pip: 24.2
2024-09-07 15:17:01,647:INFO:          setuptools: 72.1.0
2024-09-07 15:17:01,647:INFO:             pycaret: 3.3.2
2024-09-07 15:17:01,647:INFO:             IPython: 8.27.0
2024-09-07 15:17:01,647:INFO:          ipywidgets: 8.1.5
2024-09-07 15:17:01,647:INFO:                tqdm: 4.66.5
2024-09-07 15:17:01,647:INFO:               numpy: 1.26.4
2024-09-07 15:17:01,647:INFO:              pandas: 2.2.2
2024-09-07 15:17:01,647:INFO:              jinja2: 3.1.4
2024-09-07 15:17:01,647:INFO:               scipy: 1.11.4
2024-09-07 15:17:01,647:INFO:              joblib: 1.3.2
2024-09-07 15:17:01,647:INFO:             sklearn: 1.4.2
2024-09-07 15:17:01,647:INFO:                pyod: 2.0.1
2024-09-07 15:17:01,647:INFO:            imblearn: 0.12.3
2024-09-07 15:17:01,647:INFO:   category_encoders: 2.6.3
2024-09-07 15:17:01,649:INFO:            lightgbm: 4.5.0
2024-09-07 15:17:01,649:INFO:               numba: 0.60.0
2024-09-07 15:17:01,649:INFO:            requests: 2.32.3
2024-09-07 15:17:01,649:INFO:          matplotlib: 3.7.5
2024-09-07 15:17:01,649:INFO:          scikitplot: 0.3.7
2024-09-07 15:17:01,649:INFO:         yellowbrick: 1.5
2024-09-07 15:17:01,649:INFO:              plotly: 5.24.0
2024-09-07 15:17:01,649:INFO:    plotly-resampler: Not installed
2024-09-07 15:17:01,649:INFO:             kaleido: 0.2.1
2024-09-07 15:17:01,649:INFO:           schemdraw: 0.15
2024-09-07 15:17:01,649:INFO:         statsmodels: 0.14.2
2024-09-07 15:17:01,649:INFO:              sktime: 0.26.0
2024-09-07 15:17:01,649:INFO:               tbats: 1.1.3
2024-09-07 15:17:01,649:INFO:            pmdarima: 2.0.4
2024-09-07 15:17:01,649:INFO:              psutil: 6.0.0
2024-09-07 15:17:01,649:INFO:          markupsafe: 2.1.5
2024-09-07 15:17:01,649:INFO:             pickle5: Not installed
2024-09-07 15:17:01,649:INFO:         cloudpickle: 3.0.0
2024-09-07 15:17:01,649:INFO:         deprecation: 2.1.0
2024-09-07 15:17:01,649:INFO:              xxhash: 3.5.0
2024-09-07 15:17:01,649:INFO:           wurlitzer: Not installed
2024-09-07 15:17:01,649:INFO:PyCaret optional dependencies:
2024-09-07 15:17:01,663:INFO:                shap: Not installed
2024-09-07 15:17:01,663:INFO:           interpret: Not installed
2024-09-07 15:17:01,663:INFO:                umap: Not installed
2024-09-07 15:17:01,663:INFO:     ydata_profiling: Not installed
2024-09-07 15:17:01,663:INFO:  explainerdashboard: Not installed
2024-09-07 15:17:01,663:INFO:             autoviz: Not installed
2024-09-07 15:17:01,663:INFO:           fairlearn: Not installed
2024-09-07 15:17:01,663:INFO:          deepchecks: Not installed
2024-09-07 15:17:01,663:INFO:             xgboost: 2.1.1
2024-09-07 15:17:01,663:INFO:            catboost: Not installed
2024-09-07 15:17:01,663:INFO:              kmodes: Not installed
2024-09-07 15:17:01,663:INFO:             mlxtend: Not installed
2024-09-07 15:17:01,663:INFO:       statsforecast: Not installed
2024-09-07 15:17:01,663:INFO:        tune_sklearn: Not installed
2024-09-07 15:17:01,663:INFO:                 ray: Not installed
2024-09-07 15:17:01,663:INFO:            hyperopt: 0.2.7
2024-09-07 15:17:01,664:INFO:              optuna: 4.0.0
2024-09-07 15:17:01,664:INFO:               skopt: 0.10.2
2024-09-07 15:17:01,664:INFO:              mlflow: Not installed
2024-09-07 15:17:01,664:INFO:              gradio: Not installed
2024-09-07 15:17:01,664:INFO:             fastapi: Not installed
2024-09-07 15:17:01,664:INFO:             uvicorn: Not installed
2024-09-07 15:17:01,664:INFO:              m2cgen: Not installed
2024-09-07 15:17:01,664:INFO:           evidently: Not installed
2024-09-07 15:17:01,664:INFO:               fugue: Not installed
2024-09-07 15:17:01,664:INFO:           streamlit: Not installed
2024-09-07 15:17:01,664:INFO:             prophet: Not installed
2024-09-07 15:17:01,664:INFO:None
2024-09-07 15:17:01,664:INFO:Set up data.
2024-09-07 15:17:02,441:INFO:Set up folding strategy.
2024-09-07 15:17:02,441:INFO:Set up train/test split.
2024-09-07 15:17:03,046:INFO:Set up index.
2024-09-07 15:17:03,069:INFO:Assigning column types.
2024-09-07 15:17:03,724:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-07 15:17:03,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 15:17:03,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 15:17:03,817:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:17:03,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:17:03,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 15:17:03,869:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 15:17:03,901:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:17:03,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:17:03,904:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-07 15:17:03,955:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 15:17:03,987:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:17:03,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:17:04,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 15:17:04,072:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:17:04,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:17:04,075:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-07 15:17:04,154:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:17:04,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:17:04,237:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:17:04,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:17:04,242:INFO:Preparing preprocessing pipeline...
2024-09-07 15:17:04,361:INFO:Set up simple imputation.
2024-09-07 15:17:04,361:INFO:Set up imbalanced handling.
2024-09-07 15:17:05,369:INFO:Finished creating preprocessing pipeline.
2024-09-07 15:17:05,386:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-07 15:17:05,386:INFO:Creating final display dataframe.
2024-09-07 15:17:08,687:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 429)
4        Transformed data shape      (99147, 429)
5   Transformed train set shape      (76191, 429)
6    Transformed test set shape      (22956, 429)
7              Numeric features               428
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              13b3
2024-09-07 15:17:08,774:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:17:08,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:17:08,857:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:17:08,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:17:08,862:INFO:setup() successfully completed in 7.34s...............
2024-09-07 15:17:08,872:INFO:Initializing compare_models()
2024-09-07 15:17:08,872:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-07 15:17:08,873:INFO:Checking exceptions
2024-09-07 15:17:09,353:INFO:Preparing display monitor
2024-09-07 15:17:09,377:INFO:Initializing Logistic Regression
2024-09-07 15:17:09,377:INFO:Total runtime is 0.0 minutes
2024-09-07 15:17:09,382:INFO:SubProcess create_model() called ==================================
2024-09-07 15:17:09,382:INFO:Initializing create_model()
2024-09-07 15:17:09,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C35891D80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 15:17:09,383:INFO:Checking exceptions
2024-09-07 15:17:09,383:INFO:Importing libraries
2024-09-07 15:17:09,383:INFO:Copying training dataset
2024-09-07 15:17:10,109:INFO:Defining folds
2024-09-07 15:17:10,109:INFO:Declaring metric variables
2024-09-07 15:17:10,114:INFO:Importing untrained model
2024-09-07 15:17:10,117:INFO:Logistic Regression Imported successfully
2024-09-07 15:17:10,125:INFO:Starting cross validation
2024-09-07 15:17:10,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 15:18:32,896:INFO:Initializing create_model()
2024-09-07 15:18:32,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 15:18:32,897:INFO:Checking exceptions
2024-09-07 15:18:32,914:INFO:Importing libraries
2024-09-07 15:18:32,914:INFO:Copying training dataset
2024-09-07 15:18:33,733:INFO:Defining folds
2024-09-07 15:18:33,733:INFO:Declaring metric variables
2024-09-07 15:18:33,737:INFO:Importing untrained model
2024-09-07 15:18:33,741:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 15:18:33,751:INFO:Starting cross validation
2024-09-07 15:18:33,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 15:21:34,216:INFO:Calculating mean and std
2024-09-07 15:21:34,219:INFO:Creating metrics dataframe
2024-09-07 15:21:34,231:INFO:Finalizing model
2024-09-07 15:21:39,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181291 seconds.
2024-09-07 15:21:39,847:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 15:21:39,856:INFO:[LightGBM] [Info] Total Bins 102853
2024-09-07 15:21:39,860:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 427
2024-09-07 15:21:39,863:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:21:39,863:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:21:39,863:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:21:49,327:INFO:Uploading results into container
2024-09-07 15:21:49,328:INFO:Uploading model into container now
2024-09-07 15:21:49,343:INFO:_master_model_container: 1
2024-09-07 15:21:49,343:INFO:_display_container: 2
2024-09-07 15:21:49,344:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 15:21:49,344:INFO:create_model() successfully completed......................................
2024-09-07 15:22:15,443:INFO:Initializing tune_model()
2024-09-07 15:22:15,443:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'min_child_samples': [50, 150, 200]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=True, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>)
2024-09-07 15:22:15,443:INFO:Checking exceptions
2024-09-07 15:22:15,443:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-07 15:22:15,794:INFO:Copying training dataset
2024-09-07 15:22:16,197:INFO:Checking base model
2024-09-07 15:22:16,197:INFO:Base model : Light Gradient Boosting Machine
2024-09-07 15:22:16,198:INFO:Declaring metric variables
2024-09-07 15:22:16,198:INFO:Defining Hyperparameters
2024-09-07 15:22:16,301:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[50, 150, 200])}
2024-09-07 15:22:16,301:INFO:Tuning with n_jobs=-1
2024-09-07 15:22:16,303:INFO:Initializing skopt.BayesSearchCV
2024-09-07 15:32:14,632:INFO:best_params: OrderedDict([('actual_estimator__max_depth', 5), ('actual_estimator__min_child_samples', 150), ('actual_estimator__n_estimators', 100)])
2024-09-07 15:32:14,633:INFO:Hyperparameter search completed
2024-09-07 15:32:14,633:INFO:SubProcess create_model() called ==================================
2024-09-07 15:32:14,634:INFO:Initializing create_model()
2024-09-07 15:32:14,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C419B9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'max_depth': 5, 'min_child_samples': 150, 'n_estimators': 100})
2024-09-07 15:32:14,634:INFO:Checking exceptions
2024-09-07 15:32:14,634:INFO:Importing libraries
2024-09-07 15:32:14,634:INFO:Copying training dataset
2024-09-07 15:32:15,441:INFO:Defining folds
2024-09-07 15:32:15,441:INFO:Declaring metric variables
2024-09-07 15:32:15,442:INFO:Importing untrained model
2024-09-07 15:32:15,442:INFO:Declaring custom model
2024-09-07 15:32:15,443:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 15:32:15,443:INFO:Starting cross validation
2024-09-07 15:32:15,446:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 15:32:59,774:INFO:Calculating mean and std
2024-09-07 15:32:59,775:INFO:Creating metrics dataframe
2024-09-07 15:32:59,777:INFO:Finalizing model
2024-09-07 15:33:04,608:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147473 seconds.
2024-09-07 15:33:04,608:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 15:33:04,615:INFO:[LightGBM] [Info] Total Bins 102853
2024-09-07 15:33:04,620:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 427
2024-09-07 15:33:04,622:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:33:04,622:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:33:04,622:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:33:04,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:04,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:04,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:04,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:04,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:04,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:04,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:04,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:04,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:05,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:06,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:07,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:08,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:09,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:10,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:33:11,897:INFO:Uploading results into container
2024-09-07 15:33:11,899:INFO:Uploading model into container now
2024-09-07 15:33:11,899:INFO:_master_model_container: 2
2024-09-07 15:33:11,899:INFO:_display_container: 3
2024-09-07 15:33:11,900:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-09-07 15:33:11,900:INFO:create_model() successfully completed......................................
2024-09-07 15:33:12,073:INFO:SubProcess create_model() end ==================================
2024-09-07 15:33:12,073:INFO:choose_better activated
2024-09-07 15:33:12,074:INFO:SubProcess create_model() called ==================================
2024-09-07 15:33:12,074:INFO:Initializing create_model()
2024-09-07 15:33:12,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 15:33:12,075:INFO:Checking exceptions
2024-09-07 15:33:12,076:INFO:Importing libraries
2024-09-07 15:33:12,076:INFO:Copying training dataset
2024-09-07 15:33:12,739:INFO:Defining folds
2024-09-07 15:33:12,740:INFO:Declaring metric variables
2024-09-07 15:33:12,740:INFO:Importing untrained model
2024-09-07 15:33:12,740:INFO:Declaring custom model
2024-09-07 15:33:12,741:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 15:33:12,741:INFO:Starting cross validation
2024-09-07 15:33:12,744:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 15:34:19,863:INFO:Calculating mean and std
2024-09-07 15:34:19,864:INFO:Creating metrics dataframe
2024-09-07 15:34:19,866:INFO:Finalizing model
2024-09-07 15:34:24,309:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140536 seconds.
2024-09-07 15:34:24,309:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 15:34:24,317:INFO:[LightGBM] [Info] Total Bins 102853
2024-09-07 15:34:24,321:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 427
2024-09-07 15:34:24,325:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:34:24,325:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:34:24,325:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:34:33,789:INFO:Uploading results into container
2024-09-07 15:34:33,790:INFO:Uploading model into container now
2024-09-07 15:34:33,790:INFO:_master_model_container: 3
2024-09-07 15:34:33,790:INFO:_display_container: 4
2024-09-07 15:34:33,791:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 15:34:33,791:INFO:create_model() successfully completed......................................
2024-09-07 15:34:33,925:INFO:SubProcess create_model() end ==================================
2024-09-07 15:34:33,926:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8278
2024-09-07 15:34:33,926:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8288
2024-09-07 15:34:33,927:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-07 15:34:33,927:INFO:choose_better completed
2024-09-07 15:34:33,927:INFO:_master_model_container: 3
2024-09-07 15:34:33,928:INFO:_display_container: 3
2024-09-07 15:34:33,928:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-09-07 15:34:33,928:INFO:tune_model() successfully completed......................................
2024-09-07 15:34:49,924:INFO:Initializing predict_model()
2024-09-07 15:34:49,924:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C35DA8160>)
2024-09-07 15:34:49,925:INFO:Checking exceptions
2024-09-07 15:34:49,925:INFO:Preloading libraries
2024-09-07 15:34:49,928:INFO:Set up data.
2024-09-07 15:34:50,401:INFO:Set up index.
2024-09-07 15:34:51,331:INFO:Initializing get_config()
2024-09-07 15:34:51,331:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, variable=X_train)
2024-09-07 15:34:51,331:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-07 15:34:51,716:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.903637   2.736559   0.372071   0.304834  -0.307305   
41786   1.144238   1.373649  -0.522903   0.083904   0.304834   1.787297   
53345  -0.499730  -0.903637  -0.522903   0.083904   0.304834  -0.307305   
11745  -0.742247   0.055220  -0.522903   0.049743   0.304834  -0.307305   
23494   0.829220  -0.903637  -0.522903   0.134044   0.304834  -0.307305   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.903637  -0.522903   0.278403   0.304834  -0.307305   
38857  -1.387282   1.373649  -0.522903  -0.540365  -3.280477   1.787297   
31149   0.765373  -0.903637   0.291962   0.428822   0.304834  -0.307305   
55353   0.715438  -0.903637  -0.522903   0.134044   0.304834  -0.307305   
1638   -0.827527   0.055220  -0.522903   0.428822   0.304834  -0.307305   

       feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \
71710  -0.216109   1.112682   0.908807  -0.037036    0.346688   -0.621245   
41786   0.066573  -1.226048  -1.505896  -2.020844    0.346688    0.247705   
53345  -1.127987   1.112682   0.908807  -0.554897    0.346688   -0.476420   
11745  -0.854424  -0.056683   0.975882  -0.969187    0.346688   -0.331595   
23494   3.249027  -0.056683   1.042958   2.839088    0.346688   -0.621245   
...          ...        ...        ...        ...         ...         ...   
45374   1.516459   1.112682   0.908807   1.126161    0.346688   -0.621245   
38857  -2.039865  -0.056683   0.707582  -1.502983    0.346688    2.275255   
31149  -0.033734  -0.056683   0.975882   0.560497    0.346688   -0.476420   
55353  -0.216109  -0.056683   0.975882   0.608300    0.346688   -0.186770   
1638   -0.854424  -0.056683   0.908807  -0.825779   -2.884440   -0.041945   

       feature_12  feature_13  feature_14  feature_15  feature_16  feature_17  \
71710   -0.162261   -0.527968    0.751803   -0.065075    0.287760   -0.142716   
41786   -0.162261   -0.527968    1.885756   -1.548440   -1.893514   -0.142716   
53345   -0.162261   -0.527968    1.035291   -0.065075    0.192922   -0.142716   
11745   -0.162261   -0.527968    0.184827   -0.435916    0.256147   -0.142716   
23494   -0.162261    0.064610   -2.083079   -1.548440   -1.893514   -0.142716   
...           ...         ...         ...         ...         ...         ...   
45374   -0.162261    1.249768    0.184827    1.047449    1.008529   -0.142716   
38857   -0.162261    0.064610    2.452733   -1.177599    0.003246   -0.142716   
31149   -0.162261    0.064610   -0.098661    0.676608    0.463888   -0.142716   
55353   -0.162261    0.064610   -0.382150    0.676608    0.572274   -0.142716   
1638    -0.162261    0.064610    1.318780   -1.548440   -1.893514   -0.142716   

       feature_18  feature_19  feature_20  feature_21  feature_22  feature_23  \
71710   -0.147634   -0.568749   -0.064285   -0.358527    0.671466   -0.134686   
41786   -0.147634   -0.568749   -0.633318   -1.437270   -1.726610   -0.134686   
53345   -0.147634   -0.568749    1.073782   -0.718108    0.431658   -0.134686   
11745   -0.147634   -0.568749    0.504749   -0.358527    0.431658    8.456010   
23494   -0.147634    0.042008   -2.055902   -1.437270   -1.726610   -0.134686   
...           ...         ...         ...         ...         ...         ...   
45374   -0.147634    1.263522    0.220232    1.079797    1.025182   -0.134686   
38857   -0.147634    0.042008    1.358299   -1.077689    0.071947   -0.134686   
31149   -0.147634    0.042008    0.220232    0.720216    0.311754   -0.134686   
55353   -0.147634    0.042008   -0.348801    0.720216    0.821345   -0.134686   
1638    -0.147634    0.042008    1.358299   -1.437270   -1.726610   -0.134686   

       feature_24  feature_25  feature_26  feature_27  feature_28  feature_29  \
71710   -0.799378   -1.452591   -1.350408    0.300238   -0.272643    0.081567   
41786    1.759764   -0.665633   -0.373072    0.300238   -0.272643    0.081567   
53345   -0.799378   -1.452591   -1.350408    0.300238   -0.272643    0.081567   
11745   -1.476798    0.979825    0.177790    0.300238   -0.272643    0.081567   
23494    1.759764   -0.665633   -0.373072    0.300238   -0.272643    0.081567   
...           ...         ...         ...         ...         ...         ...   
45374    0.442558    1.766783   -0.719582    0.300238   -0.272643    0.081567   
38857   -1.476798    0.979825    0.177790   -3.330687    3.667803    0.081567   
31149    1.496323    1.122908   -1.767997    0.300238   -0.272643    0.081567   
55353    0.329655   -0.522550    0.830828    0.300238   -0.272643    0.081567   
1638    -0.799378   -1.452591   -1.350408    0.300238   -0.272643    0.081567   

       feature_30  feature_31  feature_32  feature_33  feature_34  feature_35  \
71710   -0.514999    1.165868   -0.285660   -0.253826   -0.237416   -0.372907   
41786    1.941751   -0.857730   -0.285660   -0.253826   -0.237416   -0.372907   
53345   -0.514999    1.165868   -0.285660   -0.253826   -0.237416   -0.372907   
11745   -0.514999   -0.857730   -0.285660   -0.253826   -0.237416    2.681634   
23494   -0.514999    1.165868   -0.285660   -0.253826   -0.237416   -0.372907   
...           ...         ...         ...         ...         ...         ...   
45374   -0.514999    1.165868   -0.285660   -0.253826   -0.237416   -0.372907   
38857   -0.514999   -0.857730    3.500663   -0.253826   -0.237416   -0.372907   
31149   -0.514999    1.165868   -0.285660   -0.253826   -0.237416   -0.372907   
55353   -0.514999    1.165868   -0.285660   -0.253826   -0.237416   -0.372907   
1638     1.941751   -0.857730   -0.285660   -0.253826   -0.237416   -0.372907   

       feature_36  feature_37  feature_38  feature_39  feature_40  feature_41  \
71710   -0.379213    -0.26538   -0.239515   -0.449976   -0.281703    1.555804   
41786   -0.379213    -0.26538   -0.239515   -0.449976   -0.281703   -0.642755   
53345   -0.379213    -0.26538   -0.239515   -0.449976   -0.281703    1.555804   
11745    2.637037    -0.26538   -0.239515   -0.449976   -0.281703   -0.642755   
23494   -0.379213    -0.26538   -0.239515   -0.449976    3.549834   -0.642755   
...           ...         ...         ...         ...         ...         ...   
45374   -0.379213    -0.26538   -0.239515   -0.449976   -0.281703    1.555804   
38857   -0.379213    -0.26538   -0.239515   -0.449976   -0.281703   -0.642755   
31149   -0.379213    -0.26538   -0.239515    2.222340   -0.281703   -0.642755   
55353   -0.379213    -0.26538   -0.239515    2.222340   -0.281703   -0.642755   
1638     2.637037    -0.26538   -0.239515   -0.449976   -0.281703   -0.642755   

       feature_42  feature_43  feature_44  feature_45  feature_46  feature_47  \
71710   -0.391896   -0.870618    0.061067    0.278914   -1.473890   -1.748812   
41786   -0.391896    1.148610    0.061067    0.278914   -1.473890    0.571817   
53345   -0.391896    1.148610    0.061067    0.278914   -1.473890    0.571817   
11745   -0.391896   -0.870618    0.061067    0.278914    0.678477    0.571817   
23494   -0.391896   -0.870618    0.061067    0.278914    0.678477    0.571817   
...           ...         ...         ...         ...         ...         ...   
45374   -0.391896    1.148610    0.061067    0.278914   -1.473890    0.571817   
38857    2.551695    1.148610    0.061067    0.278914    0.678477    0.571817   
31149   -0.391896   -0.870618    0.061067    0.278914    0.678477    0.571817   
55353   -0.391896   -0.870618    0.061067    0.278914    0.678477   -1.748812   
1638    -0.391896   -0.870618    0.061067    0.278914    0.678477    0.571817   

       feature_48  feature_49  feature_50  feature_51  feature_52  feature_53  \
71710    0.081798    0.373669    0.003269   -0.903637    2.736559    0.372071   
41786    0.081798    0.056548    0.003269    1.373649   -0.522903    0.083904   
53345    0.081798    0.077487    0.003269   -0.903637   -0.522903    0.083904   
11745    0.081798    0.044694    0.003269    0.055220   -0.522903    0.049743   
23494    0.081798    0.146389    0.003269   -0.903637   -0.522903    0.134044   
...           ...         ...         ...         ...         ...         ...   
45374    0.081798    0.311502    0.003269   -0.903637   -0.522903    0.278403   
38857    0.081798   -0.523204    0.003269    1.373649   -0.522903   -0.540365   
31149    0.081798    0.431876    0.003269   -0.903637    0.291962    0.428822   
55353    0.081798    0.138867    0.003269   -0.903637   -0.522903    0.134044   
1638     0.081798    0.406704    0.003269    0.055220   -0.522903    0.428822   

       feature_54  feature_55  feature_56  feature_57  feature_58  feature_59  \
71710    0.304834   -0.307305   -0.216109    1.112682    0.908807   -0.037036   
41786    0.304834    1.787297    0.066573   -1.226048   -1.505896   -2.020844   
53345    0.304834   -0.307305   -1.127987    1.112682    0.908807   -0.554897   
11745    0.304834   -0.307305   -0.854424   -0.056683    0.975882   -0.969187   
23494    0.304834   -0.307305    3.249027   -0.056683    1.042958    2.839088   
...           ...         ...         ...         ...         ...         ...   
45374    0.304834   -0.307305    1.516459    1.112682    0.908807    1.126161   
38857   -3.280477    1.787297   -2.039865   -0.056683    0.707582   -1.502983   
31149    0.304834   -0.307305   -0.033734   -0.056683    0.975882    0.560497   
55353    0.304834   -0.307305   -0.216109   -0.056683    0.975882    0.608300   
1638     0.304834   -0.307305   -0.854424   -0.056683    0.908807   -0.825779   

       feature_60  feature_61  feature_62  feature_63  feature_64  feature_65  \
71710    0.346688   -0.621245   -0.162261   -0.527968    0.751803   -0.065075   
41786    0.346688    0.247705   -0.162261   -0.527968    1.885756   -1.548440   
53345    0.346688   -0.476420   -0.162261   -0.527968    1.035291   -0.065075   
11745    0.346688   -0.331595   -0.162261   -0.527968    0.184827   -0.435916   
23494    0.346688   -0.621245   -0.162261    0.064610   -2.083079   -1.548440   
...           ...         ...         ...         ...         ...         ...   
45374    0.346688   -0.621245   -0.162261    1.249768    0.184827    1.047449   
38857    0.346688    2.275255   -0.162261    0.064610    2.452733   -1.177599   
31149    0.346688   -0.476420   -0.162261    0.064610   -0.098661    0.676608   
55353    0.346688   -0.186770   -0.162261    0.064610   -0.382150    0.676608   
1638    -2.884440   -0.041945   -0.162261    0.064610    1.318780   -1.548440   

       feature_66  feature_67  feature_68  feature_69  feature_70  feature_71  \
71710    0.287760   -0.142716   -0.147634   -0.568749   -0.064285   -0.358527   
41786   -1.893514   -0.142716   -0.147634   -0.568749   -0.633318   -1.437270   
53345    0.192922   -0.142716   -0.147634   -0.568749    1.073782   -0.718108   
11745    0.256147   -0.142716   -0.147634   -0.568749    0.504749   -0.358527   
23494   -1.893514   -0.142716   -0.147634    0.042008   -2.055902   -1.437270   
...           ...         ...         ...         ...         ...         ...   
45374    1.008529   -0.142716   -0.147634    1.263522    0.220232    1.079797   
38857    0.003246   -0.142716   -0.147634    0.042008    1.358299   -1.077689   
31149    0.463888   -0.142716   -0.147634    0.042008    0.220232    0.720216   
55353    0.572274   -0.142716   -0.147634    0.042008   -0.348801    0.720216   
1638    -1.893514   -0.142716   -0.147634    0.042008    1.358299   -1.437270   

       feature_72  feature_73  feature_74  feature_75  feature_76  feature_77  \
71710    0.671466   -0.134686   -0.799378   -1.452591   -1.350408   -0.740102   
41786   -1.726610   -0.134686    1.759764   -0.665633   -0.373072    1.358849   
53345    0.431658   -0.134686   -0.799378   -1.452591   -1.350408   -0.740102   
11745    0.431658    8.456010   -1.476798    0.979825    0.177790   -0.342406   
23494   -1.726610   -0.134686    1.759764   -0.665633   -0.373072   -0.740102   
...           ...         ...         ...         ...         ...         ...   
45374    1.025182   -0.134686    0.442558    1.766783   -0.719582   -0.740102   
38857    0.071947   -0.134686   -1.476798    0.979825    0.177790    1.358849   
31149    0.311754   -0.134686    1.496323    1.122908   -1.767997   -0.740102   
55353    0.821345   -0.134686    0.329655   -0.522550    0.830828   -0.740102   
1638    -1.726610   -0.134686   -0.799378   -1.452591   -1.350408   -0.342406   

       feature_78  feature_79  feature_80  feature_81  feature_82  feature_83  \
71710   -0.697003   -0.881273   -0.765317   -0.326855   -0.894929   -0.608103   
41786    0.737966    1.364075    1.646051    1.657211    1.384236   -0.604353   
53345   -0.865822   -0.884657   -0.765317   -0.326855   -0.899433   -0.608103   
11745   -0.190543    0.055359    0.249996   -0.283956   -0.011797   -0.071853   
23494   -0.865822   -0.884068   -0.765317   -0.326855   -0.877816   -0.641853   
...           ...         ...         ...         ...         ...         ...   
45374   -0.865822   -0.882373   -0.765317   -0.326855   -0.886373   -0.608103   
38857    0.737966    1.078204   -0.828774    1.657211    0.978517    0.711897   
31149   -0.823618   -0.880607   -0.765317   -0.326855   -0.894029   -0.641853   
55353   -0.865822   -0.884068   -0.765317   -0.326855   -0.894929   -0.641853   
1638    -0.190543    0.131027    0.249996   -0.283956   -0.011797   -0.071853   

       feature_84  feature_85  feature_86  feature_87  feature_88  feature_89  \
71710   -0.666377   -0.886708   -0.762344   -0.778246    -0.14869   -0.825224   
41786   -0.662727    0.897563    1.606086    0.969473    -0.14869    0.895658   
53345   -0.666377   -0.889780   -0.762344   -0.776342    -0.14869   -0.825224   
11745    0.445125   -0.036188    0.234890   -0.165212    -0.14869   -0.100643   
23494   -0.662727   -0.869645   -0.762344   -0.778246    -0.14869   -0.816167   
...           ...         ...         ...         ...         ...         ...   
45374   -0.666377   -0.879807   -0.762344   -0.778246    -0.14869   -0.798053   
38857    1.686212    1.017378    1.606086    2.008967    -0.14869    1.248891   
31149   -0.664552   -0.883163   -0.762344   -0.776342    -0.14869   -0.816167   
55353   -0.664552   -0.882879   -0.762344   -0.772535    -0.14869   -0.816167   
1638     0.414098   -0.021725   -0.824671   -0.100481    -0.14869    0.053331   

       feature_90  feature_91  feature_92  feature_93  feature_94  feature_95  \
71710   -0.683691   -0.581331   -0.665960   -0.095766   -0.136734   -0.847503   
41786    2.525285   -0.625804   -0.726086   -0.095766   -0.136734    0.924930   
53345   -0.677704   -0.581331   -0.668574   -0.095766   -0.136734   -0.847503   
11745    0.070658   -0.058781    0.281244   -0.095766   -0.136734   -0.101215   
23494   -0.743560   -0.625804   -0.726086   -0.095766   -0.136734   -0.838174   
...           ...         ...         ...         ...         ...         ...   
45374   -0.695665   -0.547977   -0.646092   -0.095766   -0.136734   -0.819517   
38857    2.992263   -0.192198    1.312974   -0.095766   -0.136734    1.288745   
31149   -0.701652   -0.559095   -0.661105   -0.095766   -0.136734   -0.838174   
55353   -0.707639   -0.559095   -0.658117   -0.095766   -0.136734   -0.838174   
1638     0.477767   -0.625804   -0.726086   -0.095766   -0.136734    0.057371   

       feature_96  feature_97  feature_98  feature_99  feature_100  \
71710   -0.705624   -0.575598   -0.618956   -0.098247    -0.861176   
41786    0.477217   -0.611025   -0.690092   -0.098247     2.114151   
53345   -0.680457   -0.587407   -0.626070   -0.098247    -0.861176   
11745    0.212966   -0.008759    0.398285    4.901270    -0.288483   
23494   -0.749666   -0.611025   -0.690092   -0.098247    -0.828669   
...           ...         ...         ...         ...          ...   
45374   -0.699333   -0.528361   -0.608464   -0.098247    -0.845401   
38857    2.194854   -0.150468    1.390629   -0.098247     0.510802   
31149   -0.699333   -0.540170   -0.629627   -0.098247    -0.832016   
55353   -0.711916   -0.540170   -0.614510   -0.098247    -0.846835   
1638     0.533843   -0.611025   -0.690092   -0.098247    -0.142202   

       feature_101  feature_102  feature_103  feature_104  feature_105  \
71710    -0.537489     0.009322     2.848145     2.818196     2.651329   
41786    -0.213698    -0.610014    -0.438367    -0.484038    -0.425238   
53345    -0.537489     0.009322    -0.438367    -0.484038    -0.425238   
11745     0.628158     0.171151    -0.438367    -0.489260    -0.425238   
23494    -0.508995     0.050914    -0.438367    -0.476373    -0.425238   
...            ...          ...          ...          ...          ...   
45374    -0.420924     0.036168    -0.438367    -0.454303    -0.425238   
38857     2.109824     0.304244    -0.438367    -0.579475    -1.194379   
31149    -0.444237    -0.008449    -0.027553     0.391914     0.343904   
55353    -0.503815     0.102147    -0.438367    -0.476373    -0.425238   
1638     -0.869051    -0.934428    -0.438367    -0.431307    -0.425238   

       feature_106  feature_107  feature_108  feature_109  feature_110  \
71710     0.073426     2.643421     4.091877     3.632439     2.727479   
41786     1.669363    -0.513212    -0.810763    -0.901538    -0.684790   
53345    -0.382556    -0.593211     0.148450    -0.014456    -0.565084   
11745    -0.382556    -0.574891    -0.331156     0.010185    -0.598914   
23494    -0.382556    -0.300082    -0.331156     0.034827    -0.287939   
...            ...          ...          ...          ...          ...   
45374    -0.382556    -0.416113     0.148450    -0.014456    -0.427812   
38857     1.669363    -0.654280    -0.331156    -0.088379    -0.642502   
31149    -0.268560     0.286175     0.175094     0.946550     0.387359   
55353    -0.382556    -0.532143    -0.331156     0.010185    -0.470100   
1638     -0.382556    -0.574891    -0.331156    -0.014456    -0.587203   

       feature_111  feature_112  feature_113  feature_114  feature_115  \
71710     2.732559     2.416763    -0.147993     1.755432     3.540634   
41786    -0.380717    -0.460323    -0.147993    -0.568949     0.191376   
53345    -0.380717    -0.678285    -0.147993    -0.568949    -0.087729   
11745    -0.380717    -0.634692    -0.147993    -0.568949    -0.366833   
23494    -0.380717    -0.721877    -0.147993    -0.452730    -1.111113   
...            ...          ...          ...          ...          ...   
45374    -0.380717    -0.721877    -0.147993    -0.220292    -0.366833   
38857    -0.380717     0.149968    -0.147993    -0.452730     0.377446   
31149     0.397602     0.149968    -0.147993     0.244585     0.191376   
55353    -0.380717    -0.591100    -0.147993    -0.452730    -0.552903   
1638     -1.159036    -0.547508    -0.147993    -0.452730     0.005306   

       feature_116  feature_117  feature_118  feature_119  feature_120  \
71710     1.510954     2.349165     -0.11674    -0.128913     1.674914   
41786    -0.873392    -0.988460     -0.11674    -0.128913    -0.564118   
53345    -0.396523    -0.349958     -0.11674    -0.128913    -0.564118   
11745    -0.515740    -0.330610     -0.11674    -0.128913    -0.564118   
23494    -0.873392    -0.988460     -0.11674    -0.128913    -0.452166   
...            ...          ...          ...          ...          ...   
45374    -0.038871    -0.100362     -0.11674    -0.128913    -0.228263   
38857    -0.754175    -0.408004     -0.11674    -0.128913    -0.452166   
31149     0.557215     0.454389     -0.11674    -0.128913     0.219543   
55353    -0.158088    -0.233867     -0.11674    -0.128913    -0.452166   
1638     -0.873392    -0.988460     -0.11674    -0.128913    -0.452166   

       feature_121  feature_122  feature_123  feature_124  feature_125  \
71710     2.091921     0.904248     2.873723    -0.109471     1.955156   
41786    -0.619290    -0.818623    -0.944464    -0.109471    -0.173420   
53345    -0.077048    -0.588907    -0.257190    -0.109471    -0.643366   
11745    -0.257795    -0.474048    -0.257190     4.723418    -0.767763   
23494    -1.071158    -0.818623    -0.944464    -0.109471    -0.173420   
...            ...          ...          ...          ...          ...   
45374    -0.348169    -0.014616    -0.068190    -0.109471    -0.415304   
38857     0.013326    -0.703765    -0.371736    -0.109471    -0.767763   
31149     0.374821     0.559674     0.353720    -0.109471     0.849402   
55353    -0.528916    -0.129474    -0.133099    -0.109471    -0.436037   
1638      0.013326    -0.818623    -0.944464    -0.109471    -0.643366   

       feature_126  feature_127  feature_128  feature_129  feature_130  \
71710    -1.826735    -3.389496     0.508947     0.474568    -0.295481   
41786    -0.520330    -0.192158    -0.029046     0.304616     1.821316   
53345    -0.854527    -0.671323    -0.029046     0.304616    -0.302227   
11745     0.178444     0.077916    -0.090841     0.284469    -0.303026   
23494    -0.520330    -0.192158     0.062414     0.334187    -0.301053   
...            ...          ...          ...          ...          ...   
45374     0.512641    -0.362044     0.330793     0.419326    -0.297674   
38857     0.178444     0.077916    -1.091958    -2.667753     1.543669   
31149     1.089890    -1.760335     0.618424     0.508039    -0.294153   
55353    -0.459567     0.398086     0.062414     0.334187    -0.301053   
1638     -0.854527    -0.671323     0.618424     0.508039    -0.294153   

       feature_131  feature_132  feature_133  feature_134  feature_135  \
71710     0.261070     1.226391     1.024199     0.323015     0.499942   
41786     0.108538    -1.168176    -1.418253    -0.828314     0.339816   
53345    -0.352609     1.093483     0.888634    -0.167156     0.339816   
11745    -0.276352    -0.045437     0.936209    -0.381576     0.320834   
23494     1.395925    -0.025471     1.041657     1.421124     0.367677   
...            ...          ...          ...          ...          ...   
45374     0.870669     1.183189     0.980134     0.784466     0.447893   
38857    -1.184266    -0.185199     0.426524    -1.068764    -0.007072   
31149     0.387823     0.044345     1.119363     0.661490     0.531477   
55353     0.044939    -0.025471     0.976939     0.405004     0.367677   
1638      0.049322     0.044345     1.050897    -0.006525    -2.460699   

       feature_136  feature_137  feature_138  feature_139  feature_140  \
71710    -0.358680    -0.155678    -0.403529     0.871978    -0.006073   
41786     0.251627    -0.155678    -0.568400     1.831183    -1.544531   
53345    -0.362264    -0.155678    -0.568400     0.991795    -0.089280   
11745    -0.256130    -0.155678    -0.587945     0.137234    -0.460491   
23494    -0.463056    -0.155678     0.042725    -2.085964    -1.544531   
...            ...          ...          ...          ...          ...   
45374    -0.399754    -0.155678     1.339749     0.238789     1.100440   
38857     1.392618    -0.155678    -0.420300     1.836261    -1.225782   
31149    -0.202613    -0.155678     0.245109     0.006650     0.787737   
55353    -0.091057    -0.155678     0.042725    -0.390485     0.660062   
1638      0.190929    -0.155678     0.245109     1.501374    -1.544531   

       feature_141  feature_142  feature_143  feature_144  feature_145  \
71710     0.362787     -0.14179    -0.141395    -0.436207     0.017890   
41786    -1.866682     -0.14179    -0.141395    -0.603288    -0.653749   
53345     0.150516     -0.14179    -0.141395    -0.603288     1.025180   
11745     0.197555     -0.14179    -0.141395    -0.623095     0.448467   
23494    -1.866682     -0.14179    -0.141395     0.016031    -2.052857   
...            ...          ...          ...          ...          ...   
45374     1.047335     -0.14179    -0.141395     1.330447     0.272106   
38857    -0.260013     -0.14179    -0.141395    -0.453202     0.889078   
31149     0.568471     -0.14179    -0.141395     0.221129     0.338918   
55353     0.540996     -0.14179    -0.141395     0.016031    -0.357225   
1638     -1.866682     -0.14179    -0.141395     0.221129     1.534806   

       feature_146  feature_147  feature_148  feature_149  feature_150  \
71710    -0.315021     0.749732    -0.134215    -0.398492    -1.446223   
41786    -1.428993    -1.705105    -0.134215     1.392964    -0.640700   
53345    -0.726511     0.384756    -0.134215    -0.552239    -1.414064   
11745    -0.382412     0.370590     8.301993    -1.081882     0.963944   
23494    -1.428993    -1.705105    -0.134215     1.439067    -0.638601   
...            ...          ...          ...          ...          ...   
45374     1.124581     1.062299    -0.134215     0.531959     1.850088   
38857    -1.121259    -0.179273    -0.134215    -1.336436     0.749914   
31149     0.822683     0.403732    -0.134215     1.496170     1.251670   
55353     0.699420     0.786637    -0.134215     0.341228    -0.496591   
1638     -1.428993    -1.705105    -0.134215    -0.368213    -1.452556   

       feature_151  feature_152  feature_153  feature_154  feature_155  \
71710    -1.432579     0.304834    -0.267831     0.226067     1.264854   
41786    -0.378056     0.304834     1.918440     0.306805    -1.049044   
53345    -1.353483     0.304834    -0.267831    -0.034379     1.264854   
11745     0.170768     0.304834    -0.267831     0.043755     0.107905   
23494    -0.382115     0.304834    -0.267831     1.215759     0.107905   
...            ...          ...          ...          ...          ...   
45374    -0.752978     0.304834    -0.267831     0.720913     1.264854   
38857     0.154155    -3.280477    -0.389291    -3.159723    -1.113319   
31149    -1.893452     0.304834    -0.267831     0.278156     0.107905   
55353     0.831388     0.304834    -0.267831     0.226067     0.107905   
1638     -1.448156     0.304834    -0.267831     0.043755     0.107905   

       feature_156  feature_157  feature_158  feature_159  feature_160  \
71710     1.030462     0.274936     0.459632    -0.179344    -0.141288   
41786    -1.265034    -0.400036     0.459632     0.563322    -0.141288   
53345     1.030462     0.098739     0.459632    -0.055566    -0.141288   
11745     1.094226    -0.042219     0.459632     0.068212    -0.141288   
23494     1.157989     1.253510     0.459632    -0.179344    -0.141288   
...            ...          ...          ...          ...          ...   
45374     1.030462     0.670703     0.459632    -0.179344    -0.141288   
38857    -1.328797    -3.110765    -2.175652    -2.407343    -0.141288   
31149     1.094226     0.478241     0.459632    -0.055566    -0.141288   
55353     1.094226     0.494505     0.459632     0.191989    -0.141288   
1638      1.030462     0.006574    -2.175652     0.315767    -0.141288   

       feature_161  feature_162  feature_163  feature_164  feature_165  \
71710    -0.174799     0.834304     0.033742     0.386127    -0.141059   
41786    -0.174799     1.850461    -1.392401    -1.625242    -0.141059   
53345    -0.174799     1.088343     0.033742     0.298676    -0.141059   
11745    -0.174799     0.326226    -0.322794     0.356976    -0.141059   
23494     0.258694    -1.706087    -1.392401    -1.625242    -0.141059   
...            ...          ...          ...          ...          ...   
45374     1.125681     0.326226     1.103349     1.050753    -0.141059   
38857    -2.342266    -1.706087    -1.392401    -1.625242    -0.141059   
31149     0.258694     0.072187     0.746813     0.548535    -0.141059   
55353     0.258694    -0.181852     0.746813     0.648479    -0.141059   
1638      0.258694     1.342382    -1.392401    -1.625242    -0.141059   

       feature_166  feature_167  feature_168  feature_169  feature_170  \
71710    -0.128119    -0.197062     0.092862    -0.260958     0.741392   
41786    -0.128119    -0.197062    -0.415478    -1.304597    -1.516121   
53345    -0.128119    -0.197062     1.109541    -0.608838     0.515640   
11745    -0.128119    -0.197062     0.601201    -0.260958     0.515640   
23494    -0.128119     0.237767    -1.686327    -1.304597    -1.516121   
...            ...          ...          ...          ...          ...   
45374    -0.128119     1.107424     0.347031     1.130560     1.074375   
38857    -0.128119    -2.371204    -1.686327    -1.304597    -1.516121   
31149    -0.128119     0.237767     0.347031     0.782680     0.402765   
55353    -0.128119     0.237767    -0.161308     0.782680     0.882486   
1638     -0.128119     0.237767     1.363711    -1.304597    -1.516121   

       feature_171  feature_172  feature_173  feature_174  feature_175  \
71710    -0.126352    -0.291337    -1.393922    -1.416056    -0.264116   
41786    -0.126352     1.365977    -0.590659    -0.400537     0.840149   
53345    -0.126352    -0.291337    -1.393922    -1.416056    -0.264116   
11745     8.876185    -0.730037     1.088891     0.171846    -0.264116   
23494    -0.126352     1.365977    -0.590659    -0.400537    -0.264116   
...            ...          ...          ...          ...          ...   
45374    -0.126352     0.512948     1.892154    -0.760585    -0.264116   
38857    -0.126352    -2.582329    -0.809731     0.024134     0.840149   
31149    -0.126352     1.195371     1.234939    -1.849959    -0.264116   
55353    -0.126352     0.439831    -0.444611     0.850397    -0.264116   
1638     -0.126352    -0.291337    -1.393922    -1.416056    -0.264116   

       feature_176  feature_177  feature_178  feature_179  feature_180  \
71710    -0.305241    -0.165376    -0.201895    -0.297169    -0.254005   
41786     1.718554    -0.249695    -0.277969     1.223450     1.982208   
53345    -0.313677    -0.165376    -0.201895    -0.302737    -0.254005   
11745    -0.311146    -0.249695    -0.197669    -0.307192    -0.254005   
23494    -0.273183    -0.249695    -0.193443    -0.266245    -0.254005   
...            ...          ...          ...          ...          ...   
45374    -0.289212    -0.165376    -0.201895    -0.284662    -0.254005   
38857     1.348283     1.352366     2.371942     1.329245     1.982208   
31149    -0.303553    -0.249695    -0.197669    -0.290745    -0.254005   
55353    -0.305241    -0.249695    -0.197669    -0.290231    -0.254005   
1638     -0.311146    -0.249695    -0.201895    -0.305650    -0.378239   

       feature_181  feature_182  feature_183  feature_184  feature_185  \
71710    -0.334242    -0.107626    -0.300865    -0.227929    -0.219889   
41786     1.638982    -0.107626     1.271080     2.789267    -0.305609   
53345    -0.329737    -0.107626    -0.300865    -0.216143    -0.219889   
11745    -0.325232    -0.107626    -0.300865    -0.251501    -0.241319   
23494    -0.334242    -0.107626    -0.283399    -0.345788    -0.305609   
...            ...          ...          ...          ...          ...   
45374    -0.334242    -0.107626    -0.248467    -0.251501    -0.155600   
38857     2.837333    -0.107626     1.602936     3.237132     0.101558   
31149    -0.329737    -0.107626    -0.283399    -0.263286    -0.177030   
55353    -0.320727    -0.107626    -0.283399    -0.275072    -0.177030   
1638     -0.316221    -0.107626    -0.283399    -0.204357    -0.305609   

       feature_186  feature_187  feature_188  feature_189  feature_190  \
71710    -0.226160    -0.058678    -0.100799    -0.307839    -0.258028   
41786    -0.340762    -0.058678    -0.100799     1.318255     0.791064   
53345    -0.231143    -0.058678    -0.100799    -0.307839    -0.210342   
11745    -0.227821    -0.058678    -0.100799    -0.307839    -0.234185   
23494    -0.340762    -0.058678    -0.100799    -0.289771    -0.341478   
...            ...          ...          ...          ...          ...   
45374    -0.188292    -0.058678    -0.100799    -0.253636    -0.246106   
38857     1.552648    -0.058678    -0.100799     1.661541     2.376624   
31149    -0.216907    -0.058678    -0.100799    -0.289771    -0.246106   
55353    -0.211213    -0.058678    -0.100799    -0.289771    -0.269949   
1638     -0.340762    -0.058678    -0.100799    -0.289771    -0.198420   

       feature_191  feature_192  feature_193  feature_194  feature_195  \
71710    -0.232559    -0.192184    -0.063922    -0.312960    -0.344947   
41786    -0.302526    -0.329124    -0.063922     2.319541     0.130170   
53345    -0.255881    -0.205878    -0.063922    -0.312960    -0.344947   
11745    -0.232559    -0.205878     1.036893    -0.328840    -0.096424   
23494    -0.302526    -0.329124    -0.063922    -0.252970    -0.264543   
...            ...          ...          ...          ...          ...   
45374    -0.139269    -0.171986    -0.063922    -0.283847    -0.016020   
38857     0.140601     1.622263    -0.063922     0.878017     3.324422   
31149    -0.162591    -0.212725    -0.063922    -0.259146    -0.081805   
55353    -0.162591    -0.183626    -0.063922    -0.286494    -0.249924   
1638     -0.302526    -0.329124    -0.063922    -0.312960    -0.344947   

       feature_196  feature_197  feature_198  feature_199  feature_200  \
71710    -0.141973    -0.252631     1.066115     0.854272    -0.158001   
41786    -0.797316     0.025039    -1.215156    -1.485432    -1.222265   
53345    -0.141973    -1.103741     0.885638     0.669173    -0.895750   
11745     0.015018    -0.855557    -0.140151     0.786236    -0.999159   
23494    -0.041572     3.602558     0.276896     1.725740     3.772903   
...            ...          ...          ...          ...          ...   
45374    -0.077169     1.552063     1.409020     1.205961     1.495844   
38857     0.277885    -1.886762    -0.260631     0.318986    -1.802211   
31149    -0.184871    -0.074238    -0.056741     0.957328     0.292793   
55353     0.082104    -0.252631    -0.075277     0.919307     0.224872   
1638     -0.141973    -0.855557    -0.140151     0.724703    -0.918657   

       feature_201  feature_202  feature_203  feature_204  feature_205  \
71710     0.273454    -0.659209    -0.161842    -0.546441     0.702153   
41786     0.346667     0.275566    -0.161842    -0.481353     1.901976   
53345     0.037284    -0.724854    -0.161842    -0.756401     0.744746   
11745     0.108135    -0.527921    -0.161842    -0.693413     0.029197   
23494     1.170902     0.089136    -0.161842     0.956872    -2.066339   
...            ...          ...          ...          ...          ...   
45374     0.722178    -0.285037    -0.161842     1.729524     0.472155   
38857    -0.198887     1.353884    -0.161842    -0.504449     1.681774   
31149     0.320688    -0.475405    -0.161842     0.049845    -0.098580   
55353     0.273454    -0.232521    -0.161842    -0.000545    -0.405244   
1638     -2.796762    -0.258779    -0.161842    -0.176912     1.076965   

       feature_206  feature_207  feature_208  feature_209  feature_210  \
71710    -0.097494     0.234948    -0.142427    -0.147123    -0.582309   
41786    -1.514601    -1.843818    -0.142427    -0.147123    -0.515785   
53345    -0.206502    -0.008386    -0.142427    -0.147123    -0.796901   
11745    -0.509000     0.094509    -0.142427    -0.147123    -0.732523   
23494    -1.514601    -1.843818    -0.142427    -0.147123     0.954168   
...            ...          ...          ...          ...          ...   
45374     1.327789     1.326056    -0.142427    -0.147123     1.743866   
38857    -1.214828    -0.314291    -0.142427    -0.147123    -0.539390   
31149     0.643762     0.437362    -0.142427    -0.147123     0.027132   
55353     0.611060     0.506091    -0.142427    -0.147123    -0.024370   
1638     -1.514601    -1.843818    -0.142427    -0.147123    -0.204627   

       feature_211  feature_212  feature_213  feature_214  feature_215  \
71710    -0.095218    -0.377162     0.604577    -0.134205    -0.799437   
41786    -0.617246    -1.407002    -1.687814    -0.134205     1.649338   
53345     0.780165    -0.773255     0.216634    -0.134205    -1.045830   
11745     0.325393    -0.432615     0.264245     7.875573    -1.552245   
23494    -2.038143    -1.407002    -1.687814    -0.134205     3.131311   
...            ...          ...          ...          ...          ...   
45374     0.506875     1.347159     1.327165    -0.134205     0.957551   
38857     0.780165    -1.116534    -0.233027    -0.134205    -1.811220   
31149     0.216504     0.684365     0.290696    -0.134205     1.360430   
55353    -0.372779     0.652677     0.747851    -0.134205     0.222830   
1638      1.113238    -1.407002    -1.687814    -0.134205    -0.971912   

       feature_216  feature_217  feature_218  feature_219  feature_220  \
71710    -1.424796    -1.318793     1.196044     1.315993     1.098114   
41786    -0.657605    -0.370235    -1.023601    -1.014391    -1.222741   
53345    -1.382153    -1.214272     1.196044     1.315993     0.974661   
11745     0.834186     0.171842    -0.439484     0.213830    -0.170033   
23494    -0.601797    -0.477798    -0.439484     0.246197     0.296160   
...            ...          ...          ...          ...          ...   
45374     2.068151    -0.808582     1.196044     1.315993     1.375407   
38857     0.654022     0.157906    -0.439484     0.084364    -0.235378   
31149     1.099635    -1.755371    -0.439484     0.213830     0.017225   
55353    -0.523975     0.819539    -0.439484     0.213830     0.023076   
1638     -1.394946    -1.245628    -0.439484     0.181464    -0.152478   

       feature_221  feature_222  feature_223  feature_224  feature_225  \
71710     1.244910     0.430861    -0.124705     0.674539     1.513160   
41786    -1.041980    -1.013552    -0.124705    -1.116221    -0.908184   
53345     1.244910     0.514106    -0.124705     0.674539     1.764817   
11745     0.101465    -0.212601    -0.124705    -0.220841     0.030427   
23494     0.101465    -0.298095    -0.124705    -0.031816    -1.003406   
...            ...          ...          ...          ...          ...   
45374     1.244910     0.430861    -0.124705     1.778841     1.009847   
38857     0.101465     0.556853    -0.124705    -0.031816     1.064259   
31149     0.101465    -0.255348    -0.124705    -0.031816    -0.098802   
55353     0.101465    -0.169853    -0.124705    -0.031816    -0.228031   
1638     -1.105505    -0.127106    -0.124705    -0.031816     0.547343   

       feature_226  feature_227  feature_228  feature_229  feature_230  \
71710     0.739439     1.164257    -0.108561    -0.113984     0.676547   
41786    -0.862965    -0.961388    -0.108561    -0.113984    -1.131889   
53345     0.739439     1.071837    -0.108561    -0.113984     0.676547   
11745    -0.245823     0.114339    -0.108561    -0.113984    -0.227671   
23494    -0.862965    -0.961388    -0.108561    -0.113984    -0.036780   
...            ...          ...          ...          ...          ...   
45374     1.941243     1.866644    -0.108561    -0.113984     1.791749   
38857    -0.657251    -0.012217    -0.108561    -0.113984    -0.036780   
31149     0.371319     0.218296    -0.108561    -0.113984    -0.036780   
55353     0.371319     0.272535    -0.108561    -0.113984    -0.036780   
1638     -0.862965    -0.961388    -0.108561    -0.113984    -0.036780   

       feature_231  feature_232  feature_233  feature_234  feature_235  \
71710     0.803637     0.384004     1.545077    -0.104827     0.676857   
41786    -0.969402    -0.831422    -0.917412    -0.104827    -1.132968   
53345     1.836746    -0.021138     1.298828    -0.104827     0.676857   
11745     0.189356    -0.207284     0.220657     5.713491    -0.433271   
23494    -1.004304    -0.831422    -0.917412    -0.104827     0.458543   
...            ...          ...          ...          ...          ...   
45374     1.061914     2.004572     1.908294    -0.104827     1.343261   
38857     0.587242    -0.623376     0.030979    -0.104827    -0.433271   
31149     0.056727     0.416853     0.157431    -0.104827     0.385953   
55353    -0.208531     0.416853     0.426142    -0.104827     0.064486   
1638      0.587242    -0.831422    -0.917412    -0.104827    -0.246612   

       feature_236  feature_237  feature_238  feature_239  feature_240  \
71710    -1.323798    -2.007607     0.967656     0.886982     1.024512   
41786    -0.611251     0.073351    -1.250477    -1.491665    -1.252628   
53345    -1.323798    -2.007607     0.967656     0.760455     1.024512   
11745     0.558850     0.200549     1.089264     0.718788     1.087766   
23494    -0.482564    -0.227563     1.214115     1.759094     1.151020   
...            ...          ...          ...          ...          ...   
45374     2.644061    -1.052896     0.967656     1.171180     1.024512   
38857     0.558850     0.200549     0.622289     0.360726     0.834750   
31149     0.649408    -1.311653     1.089264     1.102629     1.087766   
55353    -0.392006     0.708068     1.089264     1.114624     1.087766   
1638     -0.980631    -0.987117     0.967656     0.694272    -1.315882   

       feature_241  feature_242  feature_243  feature_244  feature_245  \
71710     0.287506    -0.133834     0.465153     1.318091     0.523034   
41786    -1.226423    -0.133834    -1.332042    -1.077518    -0.997259   
53345     0.374757    -0.133834     0.465153     1.567073     0.523034   
11745     0.509171    -0.133834     0.515075     0.873961     0.173778   
23494     0.372399    -0.133834     0.954389    -1.171728    -0.997259   
...            ...          ...          ...          ...          ...   
45374     0.287506    -0.133834     1.573423     0.820127     1.663254   
38857     1.763704    -0.133834     0.654857     2.488979    -0.648002   
31149     0.419562    -0.133834     0.894483     0.618250     1.344814   
55353     0.598781    -0.133834     0.894483     0.362539     1.344814   
1638      0.636511    -0.133834     0.834576     1.816055    -0.997259   

       feature_246  feature_247  feature_248  feature_249  feature_250  \
71710     0.929827    -0.118864    -0.121654     0.461943     0.605694   
41786    -1.126945    -0.118864    -0.121654    -1.349402    -1.135861   
53345     0.840402    -0.118864    -0.121654     0.461943     1.620458   
11745     0.954802    -0.118864    -0.121654     0.512258     1.174784   
23494    -1.126945    -0.118864    -0.121654     0.955031    -1.170143   
...            ...          ...          ...          ...          ...   
45374     1.609456    -0.118864    -0.121654     1.578939     0.859385   
38857     0.516539    -0.118864    -0.121654     0.653140     1.627314   
31149     1.155979    -0.118864    -0.121654     0.894653     0.914237   
55353     1.260941    -0.118864    -0.121654     0.894653     0.393142   
1638     -1.126945    -0.118864    -0.121654     0.834275     1.874149   

       feature_251  feature_252  feature_253  feature_254  feature_255  \
71710     0.186151     1.291764    -0.111687     0.445732    -1.338799   
41786    -0.956704    -1.072732    -0.111687    -1.367845    -0.669565   
53345    -0.194801     1.055314    -0.111687     0.445732    -1.338799   
11745     0.217039     1.112829    11.215502     0.123051     1.535105   
23494    -0.956704    -1.072732    -0.111687     1.998977    -0.414405   
...            ...          ...          ...          ...          ...   
45374     1.709958     1.640527    -0.111687     1.113518     2.387876   
38857    -0.606640     0.556853    -0.111687    -0.043212     1.302328   
31149     1.390782     0.991409    -0.111687     1.764896     1.705211   
55353     1.390782     1.507444    -0.111687     1.120628    -0.251013   
1638     -0.956704    -1.072732    -0.111687     0.445732    -1.338799   

       feature_256  feature_257  feature_258  feature_259  feature_260  \
71710    -1.808291    -0.085060     0.310484    -0.607884    -0.162115   
41786     0.053851    -1.824262    -0.302216    -0.436021    -0.162115   
53345    -1.808291    -0.576213     0.150542    -0.606299    -0.162115   
11745     0.266538    -0.950240     0.022589    -0.589996    -0.162115   
23494    -0.514613     3.120344     1.198776     0.127799    -0.162115   
...            ...          ...          ...          ...          ...   
45374    -0.953969     1.113820     0.669738    -0.310350    -0.162115   
38857     0.245724    -1.407398    -0.142274     1.428661    -0.162115   
31149    -2.439846     0.514266     0.495032    -0.305142    -0.162115   
55353     1.174845     0.563721     0.509796     0.008921    -0.162115   
1638     -1.808291    -0.822670    -2.762857    -0.288839    -0.162115   

       feature_261  feature_262  feature_263  feature_264  feature_265  \
71710    -0.493860     0.740630    -0.081504     0.257668    -0.142179   
41786    -1.034882     1.078729    -1.506492    -1.832165    -0.142179   
53345    -0.635091     0.860196    -0.155662     0.062776    -0.142179   
11745    -0.748075    -0.028263    -0.537865     0.034452    -0.142179   
23494     0.990147    -2.055956    -1.506492    -1.832165    -0.142179   
...            ...          ...          ...          ...          ...   
45374     1.641981     0.442835     1.278739     1.273230    -0.142179   
38857    -0.430850     1.759403    -1.202727    -0.282632    -0.142179   
31149     0.244450     0.019205     0.759342     0.562035    -0.142179   
55353     0.260094    -0.269186     0.769611     0.683462    -0.142179   
1638     -0.209226     1.033947    -1.506492    -1.832165    -0.142179   

       feature_266  feature_267  feature_268  feature_269  feature_270  \
71710     -0.14748    -0.530404    -0.065967    -0.365057     0.626653   
41786     -0.14748    -1.086695    -0.904531    -1.403098    -1.679612   
53345     -0.14748    -0.675620     0.893129    -0.747085     0.288007   
11745     -0.14748    -0.791794     0.257764    -0.462296     0.201591   
23494     -0.14748     0.995487    -2.024707    -1.403098    -1.679612   
...            ...          ...          ...          ...          ...   
45374     -0.14748     1.665717     0.475527     1.302124     1.276178   
38857     -0.14748    -0.465615     0.838464    -1.108058    -0.204729   
31149     -0.14748     0.228744     0.348275     0.797648     0.398427   
55353     -0.14748     0.244829    -0.236906     0.807621     0.929708   
1638      -0.14748    -0.237737     1.066980    -1.403098    -1.679612   

       feature_271  feature_272  feature_273  feature_274  feature_275  \
71710    -0.133819    -0.734320    -1.434575    -1.339271     0.346688   
41786    -0.133819     0.471492    -0.700394    -0.287736     0.346688   
53345    -0.133819    -0.899533    -1.405190    -1.267635     0.346688   
11745     7.640434    -1.582666     0.793284     0.165194     0.346688   
23494    -0.133819     3.143562    -0.596981    -0.485971     0.346688   
...            ...          ...          ...          ...          ...   
45374    -0.133819     0.881550     2.046849    -0.800455     0.346688   
38857    -0.133819    -1.720352     0.694843     0.157621     0.346688   
31149    -0.133819     1.640151     1.225022    -1.861548     0.346688   
55353    -0.133819     0.550448    -0.494132     0.878182     0.346688   
1638     -0.133819    -0.985952    -1.389819    -1.230164    -2.884440   

       feature_276  feature_277  feature_278  feature_279  feature_280  \
71710    -0.151106    -0.152987    -0.122481     0.853999    -0.004641   
41786     0.514601    -0.152987    -0.122481     1.866777    -1.435385   
53345    -0.040155    -0.152987    -0.122481     1.107193    -0.004641   
11745     0.070796    -0.152987    -0.122481     0.347610    -0.362327   
23494    -0.151106    -0.152987     0.287796    -1.677947    -1.435385   
...            ...          ...          ...          ...          ...   
45374    -0.151106    -0.152987     1.108349     0.347610     1.068416   
38857     2.067917    -0.152987     0.287796     2.373166    -1.077699   
31149    -0.040155    -0.152987     0.287796     0.094415     0.710731   
55353     0.181747    -0.152987     0.287796    -0.158780     0.710731   
1638     -2.148227    -0.152987    -2.173863    -1.677947    -1.435385   

       feature_281  feature_282  feature_283  feature_284  feature_285  \
71710     0.361180    -0.135643    -0.139813    -0.140349     0.111433   
41786    -1.682832    -0.135643    -0.139813    -0.140349    -0.397851   
53345     0.272310    -0.135643    -0.139813    -0.140349     1.130000   
11745     0.331557    -0.135643    -0.139813    -0.140349     0.620717   
23494    -1.682832    -0.135643    -0.139813     0.272829    -1.671061   
...            ...          ...          ...          ...          ...   
45374     1.036593    -0.135643    -0.139813     1.099184     0.366075   
38857     0.094570    -0.135643    -0.139813     0.272829     1.384642   
31149     0.526225    -0.135643    -0.139813     0.272829     0.366075   
55353     0.627791    -0.135643    -0.139813     0.272829    -0.143209   
1638     -1.682832    -0.135643    -0.139813    -2.206236    -1.671061   

       feature_286  feature_287  feature_288  feature_289  feature_290  \
71710    -0.311308     0.709604    -0.124899    -0.203110    -1.389142   
41786    -1.364730    -1.594176    -0.124899     1.355497    -0.583015   
53345    -0.662448     0.479226    -0.124899    -0.203110    -1.389142   
11745    -0.311308     0.479226    10.175092    -0.615682     1.102523   
23494    -1.364730    -1.594176    -0.124899     1.355497    -0.583015   
...            ...          ...          ...          ...          ...   
45374     1.093255     1.049412    -0.124899     0.553273     1.908650   
38857    -1.013589     0.133659    -0.124899    -0.615682     1.102523   
31149     0.742114     0.364037    -0.124899     1.195053     1.249092   
55353     0.742114     0.853591    -0.124899     0.484511    -0.436447   
1638     -1.364730    -1.594176    -0.124899    -2.357655    -0.802868   

       feature_291  feature_292  feature_293  feature_294  feature_295  \
71710    -1.470325    -0.517072    -0.149861    -0.710052     0.150355   
41786    -0.422676     0.073854    -0.149861    -0.195912     1.637062   
53345    -1.470325    -0.430309    -0.149861    -0.624362     0.426730   
11745     0.167816    -0.338856    -0.149861    -0.538672    -0.040249   
23494    -0.422676    -0.517072    -0.149861    -0.401568    -1.565077   
...            ...          ...          ...          ...          ...   
45374    -0.794115    -0.517072    -0.149861     0.215401    -0.192732   
38857     0.167816     2.109267    -0.149861     1.654995     4.229269   
31149    -1.917956    -0.430309    -0.149861    -0.298740    -0.297564   
55353     0.867836    -0.242713    -0.149861    -0.093084    -0.364275   
1638      0.015431    -0.141881    -0.149861     0.009745     0.950889   

       feature_296  feature_297  feature_298  feature_299  feature_300  \
71710    -0.244392    -0.038506    -0.128882     -0.13807    -0.766848   
41786    -1.350323    -1.650526    -0.128882     -0.13807    -0.218470   
53345    -0.182951    -0.022931    -0.128882     -0.13807    -0.675451   
11745    -0.428714     0.114648    -0.128882     -0.13807    -0.584055   
23494    -1.350323    -1.650526    -0.128882     -0.13807    -0.437821   
...            ...          ...          ...          ...          ...   
45374     0.585057     0.494161    -0.128882     -0.13807     0.220231   
38857    -0.766637     1.308737    -0.128882     -0.13807     1.755687   
31149     0.400735     0.188445    -0.128882     -0.13807    -0.328146   
55353     0.585057     0.475471    -0.128882     -0.13807    -0.108795   
1638     -1.350323    -1.650526    -0.128882     -0.13807     0.000880   

       feature_301  feature_302  feature_303  feature_304  feature_305  \
71710    -0.347688    -0.458588     0.286374    -0.124272    -0.854320   
41786    -0.409085    -1.299437    -1.531652    -0.124272     1.280250   
53345     0.501634    -0.707728     0.195473    -0.124272    -0.762950   
11745     0.204883    -0.365160     0.286374     6.335924    -1.021509   
23494    -1.637020    -1.299437    -1.531652    -0.124272     0.335440   
...            ...          ...          ...          ...          ...   
45374    -0.163498     0.662544     0.554533    -0.124272    -0.276937   
38857     3.029135    -0.707728     1.346890    -0.124272     0.308223   
31149    -0.081635     0.475689     0.099522    -0.124272     0.363629   
55353    -0.347688     0.662544     0.721943    -0.124272     0.032168   
1638      1.064438    -1.299437    -1.531652    -0.124272    -0.488838   

       feature_306  feature_307  feature_308  feature_309  feature_310  \
71710    -1.211020    -1.006398    -0.112511    -0.132075    -0.133158   
41786    -0.593035    -0.358786    -0.112511    -0.132075    -0.133158   
53345    -1.233908    -1.065687    -0.112511    -0.132075    -0.133158   
11745     0.688709     0.182411    -0.112511    -0.132075    -0.133158   
23494    -0.644534    -0.253891    -0.112511    -0.132075    -0.133158   
...            ...          ...          ...          ...          ...   
45374     1.106421    -0.520689    -0.112511    -0.132075    -0.133158   
38857     2.027675     0.291867    -0.112511    -0.132075    -0.133158   
31149     0.723042    -1.405075    -0.112511    -0.132075    -0.133158   
55353    -0.498621     0.775106    -0.112511    -0.132075    -0.133158   
1638     -1.302573    -1.243552    -0.112511    -0.132075    -0.133158   

       feature_311  feature_312  feature_313  feature_314  feature_315  \
71710    -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   
41786    -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   
53345    -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   
11745    -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   
23494    -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   
...            ...          ...          ...          ...          ...   
45374    -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   
38857    -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   
31149    -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   
55353    -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   
1638     -0.126235    -0.161547    -0.029925    -0.102589    -0.136141   

       feature_316  feature_317  feature_318  feature_319  feature_320  \
71710    -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   
41786    -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   
53345    -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   
11745    -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   
23494    -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   
...            ...          ...          ...          ...          ...   
45374    -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   
38857    -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   
31149    -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   
55353    -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   
1638     -0.139368    -0.127733    -0.159578    -0.023999    -0.155623   

       feature_321  feature_322  feature_323  feature_324  feature_325  \
71710    -0.109223     0.011921    -0.532456     0.113844    -0.287930   
41786    -0.109223     0.011921    -0.532456     0.716230    -1.072602   
53345    -0.109223     0.011921    -0.532456     0.264441    -0.287930   
11745    -0.109223     0.011921    -0.532456    -0.187349    -0.484098   
23494    -0.109223     0.011921    -0.065809    -1.392121    -1.072602   
...            ...          ...          ...          ...          ...   
45374    -0.109223     0.011921     1.122018     0.535514     1.124478   
38857    -0.109223     0.011921    -0.065809     1.499332    -0.837200   
31149    -0.109223     0.011921    -0.065809    -0.127110     0.339807   
55353    -0.109223     0.011921    -0.065809    -0.307826     0.339807   
1638     -0.109223     0.011921    -0.065809     0.776469    -1.072602   

       feature_326  feature_327  feature_328  feature_329  feature_330  \
71710    -0.129544    -0.117286    -0.120887    -0.605324    -0.340875   
41786    -1.691403    -0.117286    -0.120887    -0.605324    -0.670815   
53345    -0.197451    -0.117286    -0.120887    -0.605324     0.319004   
11745    -0.152180    -0.117286    -0.120887    -0.605324    -0.010936   
23494    -1.691403    -0.117286    -0.120887    -0.076126    -1.495664   
...            ...          ...          ...          ...          ...   
45374     1.633319    -0.117286    -0.120887     1.270922     0.615949   
38857    -0.061637    -0.117286    -0.120887    -0.076126     0.879901   
31149     0.334163    -0.117286    -0.120887    -0.076126     0.088046   
55353     0.427293    -0.117286    -0.120887    -0.076126    -0.307881   
1638     -1.691403    -0.117286    -0.120887    -0.076126     0.879901   

       feature_331  feature_332  feature_333  feature_334  feature_335  \
71710    -0.463268     0.171212    -0.116647    -0.802585    -1.269546   
41786    -1.087924    -1.560105    -0.116647     0.481419    -0.651036   
53345    -0.671487    -0.001920    -0.116647    -0.802585    -1.269546   
11745    -0.463268    -0.001920     6.048576    -1.142468     0.642212   
23494    -1.087924    -1.560105    -0.116647     1.093209    -0.617299   
...            ...          ...          ...          ...          ...   
45374     1.244124     1.618593    -0.116647     1.259374     2.508988   
38857    -0.838062    -0.001920    -0.116647    -0.855455     0.934599   
31149     0.411250     0.205838    -0.116647     0.934597     1.069546   
55353     0.411250     0.647324    -0.116647     0.232171    -0.482352   
1638     -1.087924    -1.560105    -0.116647    -0.447595    -1.359511   

       feature_336  feature_337  feature_338  feature_339  feature_340  \
71710    -1.077608     0.554669     0.169787     0.640400    -0.122024   
41786    -0.296522     2.141169    -1.115334    -1.636033    -0.122024   
53345    -1.077608     0.901716     0.298299     0.759171    -0.122024   
11745     0.143727    -0.040268    -0.344261     0.158720    -0.122024   
23494    -0.361849    -1.097934    -1.115334    -1.636033    -0.122024   
...            ...          ...          ...          ...          ...   
45374    -0.935592    -0.040268     0.683835     0.786884    -0.122024   
38857     0.166449     3.132732    -0.601286     1.531178    -0.122024   
31149    -1.699636    -0.288159     0.234043     0.086138    -0.122024   
55353     0.792738    -0.502997     0.041275    -0.092017    -0.122024   
1638     -1.299152     1.281815    -1.115334    -1.636033    -0.122024   

       feature_341  feature_342  feature_343  feature_344  feature_345  \
71710    -0.121251     0.128754     0.144762    -0.098901     1.048275   
41786    -0.121251     0.796895     0.144762    -1.129821    -1.521320   
53345    -0.121251     0.295789     1.177958    -0.373813     1.022579   
11745    -0.121251    -0.205317     0.185279    -0.305085     0.328788   
23494    -0.121251    -1.541599    -1.273350    -1.129821    -1.521320   
...            ...          ...          ...          ...          ...   
45374    -0.121251     0.596453     0.023209     0.794564     0.837568   
38857    -0.121251     1.665479     2.616329    -0.579997     1.562194   
31149    -0.121251    -0.138503    -0.138861     0.313468     0.007589   
55353    -0.121251    -0.338945    -0.544036     0.107283     0.116797   
1638     -0.121251     0.863709     1.643909    -1.129821    -1.521320   

       feature_346  feature_347  feature_348  feature_349  feature_350  \
71710    -0.123723     0.187531    -1.377424    -1.602678    -0.352700   
41786    -0.123723     2.944048    -0.383766    -0.632368    -1.000887   
53345    -0.123723     0.382646    -1.442582    -1.767927    -0.352700   
11745     6.578740    -0.501599     0.968261     0.185404    -0.636282   
23494    -0.123723    -1.763619    -0.725845     0.049815    -1.000887   
...            ...          ...          ...          ...          ...   
45374    -0.123723     0.345283     1.684998    -0.670502     0.984187   
38857    -0.123723     0.760421     2.662367     0.320994    -0.960375   
31149    -0.123723     0.488506     0.870524    -1.455436     0.457535   
55353    -0.123723    -0.219305    -0.481502     0.618654     0.457535   
1638     -0.123723     0.577761    -1.507740    -1.933176    -1.000887   

       feature_351  feature_352  feature_353  feature_354  feature_355  \
71710    -0.210569    -0.093559    -0.115964    -0.312596    -0.234201   
41786    -1.484323    -0.093559    -0.115964    -1.159712    -1.198354   
53345    -0.265950    -0.093559    -0.115964    -0.312596     0.316743   
11745    -0.542853    -0.093559    -0.115964    -0.524375    -0.268635   
23494    -1.484323    -0.093559    -0.115964    -1.159712    -1.198354   
...            ...          ...          ...          ...          ...   
45374     1.481308    -0.093559    -0.115964     1.212212     0.729952   
38857    -1.207420    -0.093559    -0.115964    -0.905578    -0.785146   
31149     0.580582    -0.093559    -0.115964     0.365096     0.454479   
55353     0.675520    -0.093559    -0.115964     0.365096     0.041271   
1638     -1.484323    -0.093559    -0.115964    -1.159712    -1.198354   

       feature_356  feature_357  feature_358  feature_359  feature_360  \
71710    -0.504564     0.021942    -0.089908    -0.316078    -1.084720   
41786    -1.026446    -1.409085    -0.089908    -1.404539    -0.660505   
53345    -0.678525    -0.121161    -0.089908    -0.316078    -1.084720   
11745    -0.635035    -0.443142     5.746055    -0.744515     0.373517   
23494    -1.026446    -1.409085    -0.089908    -1.404539    -0.660505   
...            ...          ...          ...          ...          ...   
45374     1.104571     1.464596    -0.089908     1.168977     2.772979   
38857    -0.982956    -1.140768    -0.089908    -1.184531    -0.315831   
31149     0.539199     0.415474    -0.089908     1.287666     1.566620   
55353     0.539199     0.871614    -0.089908     0.749225    -0.262804   
1638     -1.026446    -1.409085    -0.089908    -1.404539    -0.660505   

       feature_361  feature_362  feature_363  feature_364  feature_365  \
71710    -1.102521     0.066995    -0.140251    -0.147137    -0.141131   
41786    -0.018307    -1.780228    -0.140251    -0.147137    -1.706399   
53345    -1.102521    -0.090142    -0.140251    -0.147137    -0.209186   
11745     0.065095     0.013840    -0.140251    -0.147137    -0.163816   
23494    -0.018307    -1.780228    -0.140251    -0.147137    -1.706399   
...            ...          ...          ...          ...          ...   
45374    -1.052133     1.489461    -0.140251    -0.147137     1.625581   
38857     0.009494    -0.383462    -0.140251    -0.147137    -0.073076   
31149    -2.134610     0.377347    -0.140251    -0.147137     0.323589   
55353     0.914743     0.580306    -0.140251    -0.147137     0.416921   
1638     -0.018307    -1.780228    -0.140251    -0.147137    -1.706399   

       feature_366  feature_367  feature_368  feature_369  feature_370  \
71710    -0.037450    -0.451583     0.421157    -0.124616    -0.103495   
41786    -1.635402    -1.372345    -1.630521    -0.124616    -1.694973   
53345     0.766488    -0.785192     0.135706    -0.124616    -0.172690   
11745     0.389332    -0.464927     0.189228    10.799422    -0.426894   
23494    -1.635402    -1.372345    -1.630521    -0.124616    -1.694973   
...            ...          ...          ...          ...          ...   
45374     0.794279     1.486020     1.501722    -0.124616     1.165713   
38857     0.746638    -1.105457    -0.292470    -0.124616    -0.576080   
31149     0.338288     0.617873     0.254219    -0.124616     1.141169   
55353    -0.087076     0.709378     0.833722    -0.124616     0.678258   
1638     -1.635402    -1.372345    -1.630521    -0.124616    -1.694973   

       feature_371  feature_372  feature_373  feature_374  feature_375  \
71710    -1.269526    -1.428125    -0.074801    -0.024974    -0.120436   
41786    -0.717615    -0.013976    -0.074801    -0.024974    -0.120436   
53345    -1.245530    -1.366640    -0.074801    -0.024974    -0.120436   
11745     1.050099     0.128963    -0.074801    -0.024974    -0.120436   
23494    -0.717615    -0.013976    -0.074801    -0.024974    -0.120436   
...            ...          ...          ...          ...          ...   
45374     2.678436    -1.039116    -0.074801    -0.024974    -0.120436   
38857     0.842133     0.112147    -0.074801    -0.024974    -0.120436   
31149     1.370047    -2.002771    -0.074801    -0.024974    -0.120436   
55353    -0.327678     0.903172    -0.074801    -0.024974    -0.120436   
1638     -0.717615    -0.013976    -0.074801    -0.024974    -0.120436   

       feature_376  feature_377  feature_378  feature_379  feature_380  \
71710    -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   
41786    -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   
53345    -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   
11745    -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   
23494    -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   
...            ...          ...          ...          ...          ...   
45374    -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   
38857    -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   
31149    -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   
55353    -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   
1638     -0.125299    -0.097157    -0.136038    -0.046277    -0.136231   

       feature_381  feature_382  feature_383  feature_384  feature_385  \
71710    -0.045436     0.105586    -0.095486    -0.122948    -0.125707   
41786    -0.045436     0.105586    -0.095486    -0.122948    -0.125707   
53345    -0.045436     0.105586    -0.095486    -0.122948    -0.125707   
11745    -0.045436     0.105586    -0.095486    -0.122948    -0.125707   
23494    -0.045436     0.105586    -0.095486    -0.122948    -0.125707   
...            ...          ...          ...          ...          ...   
45374    -0.045436     0.105586    -0.095486    -0.122948    -0.125707   
38857    -0.045436     0.105586    -0.095486    -0.122948    -0.125707   
31149    -0.045436     0.105586    -0.095486    -0.122948    -0.125707   
55353    -0.045436     0.105586    -0.095486    -0.122948    -0.125707   
1638     -0.045436     0.105586    -0.095486    -0.122948    -0.125707   

       feature_386  feature_387  feature_388  feature_389  feature_390  \
71710    -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   
41786    -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   
53345    -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   
11745    -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   
23494    -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   
...            ...          ...          ...          ...          ...   
45374    -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   
38857    -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   
31149    -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   
55353    -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   
1638     -0.116103    -0.146816    -0.022139    -0.141591    -0.099872   

       feature_391  feature_392  feature_393  feature_394  feature_395  \
71710     0.013264    -0.649556    -0.363651    -0.483893     0.159443   
41786     0.013264    -0.649556    -0.711408    -1.125094    -1.569933   
53345     0.013264    -0.649556     0.331862    -0.697627    -0.013494   
11745     0.013264    -0.649556    -0.015895    -0.483893    -0.013494   
23494     0.013264    -0.093955    -1.580799    -1.125094    -1.569933   
...            ...          ...          ...          ...          ...   
45374     0.013264     1.320301     0.644843     1.268721     1.605203   
38857     0.013264    -0.093955     0.923048    -0.868614    -0.013494   
31149     0.013264    -0.093955     0.088432     0.413787     0.194031   
55353     0.013264    -0.093955    -0.328875     0.413787     0.635022   
1638      0.013264    -0.093955     0.923048    -1.125094    -1.569933   

       feature_396  feature_397  feature_398  feature_399  feature_400  \
71710    -0.118667    -0.827113    -1.278585    -1.081634    -0.289253   
41786    -0.118667     0.460282    -0.657093    -0.298069    -0.735184   
53345    -0.118667    -0.827113    -1.278585    -1.081634     1.048540   
11745     6.209241    -1.167894     0.642391     0.143576     0.305321   
23494    -0.118667     1.073687    -0.623193    -0.363604    -1.199696   
...            ...          ...          ...          ...          ...   
45374    -0.118667     1.240291     2.518167    -0.939168    -0.010546   
38857    -0.118667    -0.880123     0.936187     0.166371     1.475890   
31149    -0.118667     0.914656     1.071785    -1.705637    -0.010546   
55353    -0.118667     0.210376    -0.487595     0.794647    -0.530799   
1638     -0.118667    -0.471186    -1.368983    -1.303882     1.475890   

       feature_401  feature_402  feature_403  feature_404  feature_405  \
71710    -0.430680     0.268206    -0.125425    -0.376195    -1.213960   
41786    -1.188688    -1.537877    -0.125425    -0.053439    -0.615374   
53345    -0.394584     1.016440    -0.125425     0.422203    -1.483745   
11745    -0.214106     0.552019     7.681708    -0.320987     1.230968   
23494    -1.188688    -1.537877    -0.125425    -1.773392    -0.741836   
...            ...          ...          ...          ...          ...   
45374     0.832668     0.830672    -0.125425     0.383982     1.753676   
38857    -0.755541     0.784229    -0.125425     0.163148     1.888569   
31149     0.543902     0.216603    -0.125425     0.859623     1.146660   
55353     0.110755     0.106948    -0.125425    -0.193583    -0.488912   
1638     -1.188688    -1.537877    -0.125425     0.621802    -1.551191   

       feature_406  feature_407  feature_408  feature_409  feature_410  \
71710    -1.163212    -0.639733    -0.309181    -0.092430    -0.515036   
41786    -0.224658    -1.031124    -1.370414    -0.092430    -1.308768   
53345    -1.842629    -0.857173    -0.733674    -0.092430    -0.779614   
11745     0.182556    -0.639733    -0.415305     6.474232    -0.667027   
23494     0.025768    -1.031124    -1.370414    -0.092430    -1.308768   
...            ...          ...          ...          ...          ...   
45374    -0.714622     1.099783     1.471036    -0.092430     1.193458   
38857     0.234819    -0.987636    -1.105106    -0.092430    -1.094855   
31149    -1.742458     0.534440     0.433681    -0.092430     1.308858   
55353     0.610458     0.534440     0.884705    -0.092430     0.785333   
1638     -2.012483    -1.031124    -1.370414    -0.092430    -1.308768   

       feature_411  feature_412  feature_413  feature_414  feature_415  \
71710    -0.965091    -0.855924     0.724720    -0.124966     0.206311   
41786    -0.641455    -0.019161    -1.630463    -0.124966    -1.564021   
53345    -0.857212    -0.577003     0.277235    -0.124966     0.029278   
11745     0.410362     0.066661     0.277235    12.126328    -0.275822   
23494    -0.641455    -0.019161    -1.630463    -0.124966    -1.564021   
...            ...          ...          ...          ...          ...   
45374     2.851115    -1.082994     1.470739    -0.124966     1.180605   
38857    -0.290849     0.009447    -0.305673    -0.124966    -0.490522   
31149     1.623996    -2.196890     0.071157    -0.124966     0.917269   
55353    -0.236910     0.940971     1.028318    -0.124966     0.917269   
1638     -0.641455    -0.019161    -1.630463    -0.124966    -1.564021   

       feature_416  feature_417  feature_418  feature_419  feature_420  \
71710    -1.342547    -1.698102    -0.086278    -0.129104    -0.082721   
41786    -0.695520    -0.021815    -0.086278    -0.129104    -0.082721   
53345    -1.277845    -1.530473    -0.086278    -0.129104    -0.082721   
11745     1.197034     0.132920     6.167595     5.438956    13.379660   
23494    -0.695520    -0.021815    -0.086278    -0.129104    -0.082721   
...            ...          ...          ...          ...          ...   
45374     2.738374    -1.069897    -0.086278    -0.129104    -0.082721   
38857     0.881608     0.107130    -0.086278    -0.129104    -0.082721   
31149     1.229385    -1.875939    -0.086278    -0.129104    -0.082721   
55353    -0.265854     1.000009    -0.086278    -0.129104    -0.082721   
1638     -0.695520    -0.021815    -0.086278    -0.129104    -0.082721   

       feature_421  feature_422  feature_423  feature_424  feature_425  \
71710     0.049159    -0.814324    -1.269576    -0.978704    -0.657480   
41786     0.049159     1.938017    -0.543544    -0.447987    -0.785362   
53345     0.049159    -0.814324    -1.269576    -0.978704    -0.657480   
11745     1.386740    -1.298134     0.330275     0.189874     0.765493   
23494     0.049159     1.938017    -0.543544    -0.447987    -0.785362   
...            ...          ...          ...          ...          ...   
45374     0.049159     0.338756     1.927194    -0.693992     2.376801   
38857     0.049159    -1.298134     0.330275     0.189874     0.765493   
31149     0.049159     1.587176     1.716656    -2.215057     1.016606   
55353     0.049159     0.219701    -0.464959     0.917071    -0.748160   
1638      0.049159    -0.814324    -1.269576    -0.978704    -0.657480   

       feature_426  feature_427  
71710     0.665040     0.918771  
41786     0.023022    -0.833264  
53345     0.665040     0.918771  
11745     0.279644    -0.979924  
23494     0.023022    -0.833264  
...            ...          ...  
45374    -1.369871    -0.430422  
38857     0.279644    -0.979924  
31149    -2.545979     2.249198  
55353     0.294235    -0.368505  
1638      0.665040     0.918771  

[53562 rows x 428 columns]
2024-09-07 15:34:51,718:INFO:get_config() successfully completed......................................
2024-09-07 15:34:51,718:INFO:Initializing predict_model()
2024-09-07 15:34:51,718:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C41E67C70>)
2024-09-07 15:34:51,718:INFO:Checking exceptions
2024-09-07 15:34:51,718:INFO:Preloading libraries
2024-09-07 15:34:51,720:INFO:Set up data.
2024-09-07 15:34:52,086:INFO:Set up index.
2024-09-07 15:34:53,302:INFO:Initializing get_config()
2024-09-07 15:34:53,302:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, variable=y_train)
2024-09-07 15:34:53,303:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-07 15:34:53,460:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-07 15:34:53,460:INFO:get_config() successfully completed......................................
2024-09-07 15:34:53,461:INFO:Initializing get_config()
2024-09-07 15:34:53,461:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, variable=y_test)
2024-09-07 15:34:53,461:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-07 15:34:53,578:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-07 15:34:53,578:INFO:get_config() successfully completed......................................
2024-09-07 15:34:53,584:INFO:Initializing finalize_model()
2024-09-07 15:34:53,584:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-07 15:34:53,585:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-09-07 15:34:54,012:INFO:Initializing create_model()
2024-09-07 15:34:54,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 15:34:54,012:INFO:Checking exceptions
2024-09-07 15:34:54,014:INFO:Importing libraries
2024-09-07 15:34:54,014:INFO:Copying training dataset
2024-09-07 15:34:54,086:INFO:Defining folds
2024-09-07 15:34:54,086:INFO:Declaring metric variables
2024-09-07 15:34:54,086:INFO:Importing untrained model
2024-09-07 15:34:54,086:INFO:Declaring custom model
2024-09-07 15:34:54,087:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 15:34:54,090:INFO:Cross validation set to False
2024-09-07 15:34:54,090:INFO:Fitting Model
2024-09-07 15:35:02,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211643 seconds.
2024-09-07 15:35:02,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 15:35:02,153:INFO:[LightGBM] [Info] Total Bins 103969
2024-09-07 15:35:02,157:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 427
2024-09-07 15:35:02,160:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:35:02,161:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:35:02,161:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:35:02,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:02,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:02,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:02,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:02,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:02,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:02,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:02,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:02,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:02,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:03,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:03,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:03,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:03,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:03,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:03,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:03,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:03,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:03,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:05,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:06,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:07,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:08,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:09,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:10,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:35:11,445:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=5,
                                min_child_samples=150, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-07 15:35:11,445:INFO:create_model() successfully completed......................................
2024-09-07 15:35:11,592:INFO:_master_model_container: 3
2024-09-07 15:35:11,592:INFO:_display_container: 4
2024-09-07 15:35:11,604:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=5,
                                min_child_samples=150, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-07 15:35:11,604:INFO:finalize_model() successfully completed......................................
2024-09-07 15:36:00,635:INFO:Initializing predict_model()
2024-09-07 15:36:00,635:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C02307B80>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=5,
                                min_child_samples=150, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C02273910>)
2024-09-07 15:36:00,635:INFO:Checking exceptions
2024-09-07 15:36:00,635:INFO:Preloading libraries
2024-09-07 15:36:00,639:INFO:Set up data.
2024-09-07 15:36:00,917:INFO:Set up index.
2024-09-07 15:44:41,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:44:41,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:44:41,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:44:41,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 15:45:17,812:INFO:PyCaret ClassificationExperiment
2024-09-07 15:45:17,812:INFO:Logging name: clf-default-name
2024-09-07 15:45:17,812:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 15:45:17,812:INFO:version 3.3.2
2024-09-07 15:45:17,812:INFO:Initializing setup()
2024-09-07 15:45:17,813:INFO:self.USI: da18
2024-09-07 15:45:17,813:INFO:self._variable_keys: {'y_test', 'X', 'n_jobs_param', 'USI', 'fold_generator', 'logging_param', 'is_multiclass', 'exp_name_log', 'log_plots_param', 'gpu_n_jobs_param', 'X_train', 'fold_shuffle_param', 'seed', 'y_train', 'idx', '_available_plots', 'memory', 'data', 'exp_id', 'html_param', '_ml_usecase', 'gpu_param', 'target_param', 'X_test', 'fix_imbalance', 'fold_groups_param', 'pipeline', 'y'}
2024-09-07 15:45:17,813:INFO:Checking environment
2024-09-07 15:45:17,813:INFO:python_version: 3.10.11
2024-09-07 15:45:17,813:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 15:45:17,813:INFO:machine: AMD64
2024-09-07 15:45:17,813:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 15:45:17,813:INFO:Memory: svmem(total=17128263680, available=7769387008, percent=54.6, used=9358876672, free=7769387008)
2024-09-07 15:45:17,813:INFO:Physical Core: 6
2024-09-07 15:45:17,813:INFO:Logical Core: 12
2024-09-07 15:45:17,813:INFO:Checking libraries
2024-09-07 15:45:17,813:INFO:System:
2024-09-07 15:45:17,813:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 15:45:17,813:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 15:45:17,813:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 15:45:17,813:INFO:PyCaret required dependencies:
2024-09-07 15:45:17,840:INFO:                 pip: 24.2
2024-09-07 15:45:17,840:INFO:          setuptools: 72.1.0
2024-09-07 15:45:17,840:INFO:             pycaret: 3.3.2
2024-09-07 15:45:17,840:INFO:             IPython: 8.27.0
2024-09-07 15:45:17,840:INFO:          ipywidgets: 8.1.5
2024-09-07 15:45:17,841:INFO:                tqdm: 4.66.5
2024-09-07 15:45:17,841:INFO:               numpy: 1.26.4
2024-09-07 15:45:17,841:INFO:              pandas: 2.2.2
2024-09-07 15:45:17,841:INFO:              jinja2: 3.1.4
2024-09-07 15:45:17,841:INFO:               scipy: 1.11.4
2024-09-07 15:45:17,841:INFO:              joblib: 1.3.2
2024-09-07 15:45:17,841:INFO:             sklearn: 1.4.2
2024-09-07 15:45:17,841:INFO:                pyod: 2.0.1
2024-09-07 15:45:17,841:INFO:            imblearn: 0.12.3
2024-09-07 15:45:17,841:INFO:   category_encoders: 2.6.3
2024-09-07 15:45:17,841:INFO:            lightgbm: 4.5.0
2024-09-07 15:45:17,841:INFO:               numba: 0.60.0
2024-09-07 15:45:17,841:INFO:            requests: 2.32.3
2024-09-07 15:45:17,841:INFO:          matplotlib: 3.7.5
2024-09-07 15:45:17,841:INFO:          scikitplot: 0.3.7
2024-09-07 15:45:17,841:INFO:         yellowbrick: 1.5
2024-09-07 15:45:17,841:INFO:              plotly: 5.24.0
2024-09-07 15:45:17,841:INFO:    plotly-resampler: Not installed
2024-09-07 15:45:17,841:INFO:             kaleido: 0.2.1
2024-09-07 15:45:17,841:INFO:           schemdraw: 0.15
2024-09-07 15:45:17,841:INFO:         statsmodels: 0.14.2
2024-09-07 15:45:17,841:INFO:              sktime: 0.26.0
2024-09-07 15:45:17,842:INFO:               tbats: 1.1.3
2024-09-07 15:45:17,842:INFO:            pmdarima: 2.0.4
2024-09-07 15:45:17,842:INFO:              psutil: 6.0.0
2024-09-07 15:45:17,842:INFO:          markupsafe: 2.1.5
2024-09-07 15:45:17,842:INFO:             pickle5: Not installed
2024-09-07 15:45:17,842:INFO:         cloudpickle: 3.0.0
2024-09-07 15:45:17,842:INFO:         deprecation: 2.1.0
2024-09-07 15:45:17,842:INFO:              xxhash: 3.5.0
2024-09-07 15:45:17,842:INFO:           wurlitzer: Not installed
2024-09-07 15:45:17,842:INFO:PyCaret optional dependencies:
2024-09-07 15:45:17,858:INFO:                shap: Not installed
2024-09-07 15:45:17,858:INFO:           interpret: Not installed
2024-09-07 15:45:17,858:INFO:                umap: Not installed
2024-09-07 15:45:17,858:INFO:     ydata_profiling: Not installed
2024-09-07 15:45:17,858:INFO:  explainerdashboard: Not installed
2024-09-07 15:45:17,858:INFO:             autoviz: Not installed
2024-09-07 15:45:17,858:INFO:           fairlearn: Not installed
2024-09-07 15:45:17,858:INFO:          deepchecks: Not installed
2024-09-07 15:45:17,858:INFO:             xgboost: 2.1.1
2024-09-07 15:45:17,858:INFO:            catboost: Not installed
2024-09-07 15:45:17,858:INFO:              kmodes: Not installed
2024-09-07 15:45:17,858:INFO:             mlxtend: Not installed
2024-09-07 15:45:17,858:INFO:       statsforecast: Not installed
2024-09-07 15:45:17,858:INFO:        tune_sklearn: Not installed
2024-09-07 15:45:17,858:INFO:                 ray: Not installed
2024-09-07 15:45:17,858:INFO:            hyperopt: 0.2.7
2024-09-07 15:45:17,858:INFO:              optuna: 4.0.0
2024-09-07 15:45:17,858:INFO:               skopt: 0.10.2
2024-09-07 15:45:17,859:INFO:              mlflow: Not installed
2024-09-07 15:45:17,859:INFO:              gradio: Not installed
2024-09-07 15:45:17,859:INFO:             fastapi: Not installed
2024-09-07 15:45:17,859:INFO:             uvicorn: Not installed
2024-09-07 15:45:17,859:INFO:              m2cgen: Not installed
2024-09-07 15:45:17,859:INFO:           evidently: Not installed
2024-09-07 15:45:17,859:INFO:               fugue: Not installed
2024-09-07 15:45:17,859:INFO:           streamlit: Not installed
2024-09-07 15:45:17,860:INFO:             prophet: Not installed
2024-09-07 15:45:17,860:INFO:None
2024-09-07 15:45:17,860:INFO:Set up data.
2024-09-07 15:45:18,410:INFO:Set up folding strategy.
2024-09-07 15:45:18,410:INFO:Set up train/test split.
2024-09-07 15:45:19,015:INFO:Set up index.
2024-09-07 15:45:19,033:INFO:Assigning column types.
2024-09-07 15:45:19,713:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-07 15:45:19,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 15:45:19,772:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 15:45:19,810:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:45:19,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:45:19,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 15:45:19,867:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 15:45:19,899:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:45:19,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:45:19,902:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-07 15:45:19,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 15:45:19,988:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:45:19,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:45:20,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 15:45:20,078:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:45:20,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:45:20,081:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-07 15:45:20,162:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:45:20,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:45:20,247:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:45:20,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:45:20,251:INFO:Preparing preprocessing pipeline...
2024-09-07 15:45:20,380:INFO:Set up simple imputation.
2024-09-07 15:45:20,380:INFO:Set up imbalanced handling.
2024-09-07 15:45:21,935:INFO:Finished creating preprocessing pipeline.
2024-09-07 15:45:21,945:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-07 15:45:21,946:INFO:Creating final display dataframe.
2024-09-07 15:45:31,464:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 428)
4        Transformed data shape      (99147, 428)
5   Transformed train set shape      (76191, 428)
6    Transformed test set shape      (22956, 428)
7              Numeric features               427
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              da18
2024-09-07 15:45:31,553:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:45:31,556:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:45:31,637:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 15:45:31,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 15:45:31,642:INFO:setup() successfully completed in 13.87s...............
2024-09-07 15:45:31,674:INFO:Initializing create_model()
2024-09-07 15:45:31,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 15:45:31,675:INFO:Checking exceptions
2024-09-07 15:45:31,695:INFO:Importing libraries
2024-09-07 15:45:31,695:INFO:Copying training dataset
2024-09-07 15:45:32,438:INFO:Defining folds
2024-09-07 15:45:32,438:INFO:Declaring metric variables
2024-09-07 15:45:32,442:INFO:Importing untrained model
2024-09-07 15:45:32,447:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 15:45:32,455:INFO:Starting cross validation
2024-09-07 15:45:32,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 15:48:05,817:INFO:Calculating mean and std
2024-09-07 15:48:05,848:INFO:Creating metrics dataframe
2024-09-07 15:48:05,893:INFO:Finalizing model
2024-09-07 15:48:10,917:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.145552 seconds.
2024-09-07 15:48:10,918:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 15:48:10,925:INFO:[LightGBM] [Info] Total Bins 102580
2024-09-07 15:48:10,929:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 426
2024-09-07 15:48:10,932:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:48:10,933:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:48:10,933:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:48:19,959:INFO:Uploading results into container
2024-09-07 15:48:19,960:INFO:Uploading model into container now
2024-09-07 15:48:19,982:INFO:_master_model_container: 1
2024-09-07 15:48:19,982:INFO:_display_container: 2
2024-09-07 15:48:19,983:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 15:48:19,983:INFO:create_model() successfully completed......................................
2024-09-07 15:48:20,191:INFO:Initializing tune_model()
2024-09-07 15:48:20,192:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'min_child_samples': [50, 150, 200]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=True, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>)
2024-09-07 15:48:20,192:INFO:Checking exceptions
2024-09-07 15:48:20,193:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-07 15:48:20,886:INFO:Copying training dataset
2024-09-07 15:48:21,296:INFO:Checking base model
2024-09-07 15:48:21,296:INFO:Base model : Light Gradient Boosting Machine
2024-09-07 15:48:21,298:INFO:Declaring metric variables
2024-09-07 15:48:21,298:INFO:Defining Hyperparameters
2024-09-07 15:48:21,367:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[50, 150, 200])}
2024-09-07 15:48:21,367:INFO:Tuning with n_jobs=-1
2024-09-07 15:48:21,369:INFO:Initializing skopt.BayesSearchCV
2024-09-07 15:58:03,879:INFO:best_params: OrderedDict([('actual_estimator__max_depth', 7), ('actual_estimator__min_child_samples', 150), ('actual_estimator__n_estimators', 200)])
2024-09-07 15:58:03,880:INFO:Hyperparameter search completed
2024-09-07 15:58:03,880:INFO:SubProcess create_model() called ==================================
2024-09-07 15:58:03,880:INFO:Initializing create_model()
2024-09-07 15:58:03,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026860E04BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'max_depth': 7, 'min_child_samples': 150, 'n_estimators': 200})
2024-09-07 15:58:03,880:INFO:Checking exceptions
2024-09-07 15:58:03,880:INFO:Importing libraries
2024-09-07 15:58:03,881:INFO:Copying training dataset
2024-09-07 15:58:04,663:INFO:Defining folds
2024-09-07 15:58:04,663:INFO:Declaring metric variables
2024-09-07 15:58:04,663:INFO:Importing untrained model
2024-09-07 15:58:04,663:INFO:Declaring custom model
2024-09-07 15:58:04,664:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 15:58:04,664:INFO:Starting cross validation
2024-09-07 15:58:04,674:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 15:59:37,210:INFO:Calculating mean and std
2024-09-07 15:59:37,211:INFO:Creating metrics dataframe
2024-09-07 15:59:37,213:INFO:Finalizing model
2024-09-07 15:59:41,946:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125217 seconds.
2024-09-07 15:59:41,946:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 15:59:41,954:INFO:[LightGBM] [Info] Total Bins 102580
2024-09-07 15:59:41,958:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 426
2024-09-07 15:59:41,962:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:59:41,962:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:59:41,962:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 15:59:46,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:47,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:47,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:47,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:47,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:48,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:49,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:50,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:51,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:52,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:53,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:54,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:55,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:56,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:56,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-07 15:59:56,242:INFO:Uploading results into container
2024-09-07 15:59:56,242:INFO:Uploading model into container now
2024-09-07 15:59:56,243:INFO:_master_model_container: 2
2024-09-07 15:59:56,243:INFO:_display_container: 3
2024-09-07 15:59:56,243:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=7,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=200, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-09-07 15:59:56,243:INFO:create_model() successfully completed......................................
2024-09-07 15:59:56,374:INFO:SubProcess create_model() end ==================================
2024-09-07 15:59:56,374:INFO:choose_better activated
2024-09-07 15:59:56,375:INFO:SubProcess create_model() called ==================================
2024-09-07 15:59:56,376:INFO:Initializing create_model()
2024-09-07 15:59:56,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 15:59:56,376:INFO:Checking exceptions
2024-09-07 15:59:56,377:INFO:Importing libraries
2024-09-07 15:59:56,377:INFO:Copying training dataset
2024-09-07 15:59:57,072:INFO:Defining folds
2024-09-07 15:59:57,072:INFO:Declaring metric variables
2024-09-07 15:59:57,073:INFO:Importing untrained model
2024-09-07 15:59:57,073:INFO:Declaring custom model
2024-09-07 15:59:57,073:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 15:59:57,075:INFO:Starting cross validation
2024-09-07 15:59:57,081:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 16:01:15,140:INFO:Calculating mean and std
2024-09-07 16:01:15,141:INFO:Creating metrics dataframe
2024-09-07 16:01:15,143:INFO:Finalizing model
2024-09-07 16:01:20,141:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.144340 seconds.
2024-09-07 16:01:20,141:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 16:01:20,148:INFO:[LightGBM] [Info] Total Bins 102580
2024-09-07 16:01:20,151:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 426
2024-09-07 16:01:20,156:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 16:01:20,156:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 16:01:20,156:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 16:01:30,090:INFO:Uploading results into container
2024-09-07 16:01:30,090:INFO:Uploading model into container now
2024-09-07 16:01:30,091:INFO:_master_model_container: 3
2024-09-07 16:01:30,091:INFO:_display_container: 4
2024-09-07 16:01:30,091:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 16:01:30,091:INFO:create_model() successfully completed......................................
2024-09-07 16:01:30,184:INFO:SubProcess create_model() end ==================================
2024-09-07 16:01:30,185:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8285
2024-09-07 16:01:30,185:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=7,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=200, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8283
2024-09-07 16:01:30,186:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-07 16:01:30,186:INFO:choose_better completed
2024-09-07 16:01:30,186:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-07 16:01:30,186:INFO:_master_model_container: 3
2024-09-07 16:01:30,186:INFO:_display_container: 3
2024-09-07 16:01:30,187:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 16:01:30,187:INFO:tune_model() successfully completed......................................
2024-09-07 16:01:30,320:INFO:Initializing predict_model()
2024-09-07 16:01:30,321:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026860DE8820>)
2024-09-07 16:01:30,321:INFO:Checking exceptions
2024-09-07 16:01:30,321:INFO:Preloading libraries
2024-09-07 16:01:30,324:INFO:Set up data.
2024-09-07 16:01:30,736:INFO:Set up index.
2024-09-07 16:01:31,576:INFO:Initializing get_config()
2024-09-07 16:01:31,576:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, variable=X_train)
2024-09-07 16:01:31,576:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-07 16:01:31,848:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710  -0.903637   2.736559   0.372071   0.304834  -0.307305  -0.216109   
41786   1.373649  -0.522903   0.083904   0.304834   1.787297   0.066573   
53345  -0.903637  -0.522903   0.083904   0.304834  -0.307305  -1.127987   
11745   0.055220  -0.522903   0.049743   0.304834  -0.307305  -0.854424   
23494  -0.903637  -0.522903   0.134044   0.304834  -0.307305   3.249027   
...          ...        ...        ...        ...        ...        ...   
45374  -0.903637  -0.522903   0.278403   0.304834  -0.307305   1.516459   
38857   1.373649  -0.522903  -0.540365  -3.280477   1.787297  -2.039865   
31149  -0.903637   0.291962   0.428822   0.304834  -0.307305  -0.033734   
55353  -0.903637  -0.522903   0.134044   0.304834  -0.307305  -0.216109   
1638    0.055220  -0.522903   0.428822   0.304834  -0.307305  -0.854424   

       feature_6  feature_7  feature_8  feature_9  ...  feature_417  \
71710   1.112682   0.908807  -0.037036   0.346688  ...    -0.086278   
41786  -1.226048  -1.505896  -2.020844   0.346688  ...    -0.086278   
53345   1.112682   0.908807  -0.554897   0.346688  ...    -0.086278   
11745  -0.056683   0.975882  -0.969187   0.346688  ...     6.167595   
23494  -0.056683   1.042958   2.839088   0.346688  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374   1.112682   0.908807   1.126161   0.346688  ...    -0.086278   
38857  -0.056683   0.707582  -1.502983   0.346688  ...    -0.086278   
31149  -0.056683   0.975882   0.560497   0.346688  ...    -0.086278   
55353  -0.056683   0.975882   0.608300   0.346688  ...    -0.086278   
1638   -0.056683   0.908807  -0.825779  -2.884440  ...    -0.086278   

       feature_418  feature_419  feature_420  feature_421  feature_422  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_423  feature_424  feature_425  feature_426  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 427 columns]
2024-09-07 16:01:31,848:INFO:get_config() successfully completed......................................
2024-09-07 16:01:31,848:INFO:Initializing predict_model()
2024-09-07 16:01:31,849:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002685EC512D0>)
2024-09-07 16:01:31,849:INFO:Checking exceptions
2024-09-07 16:01:31,849:INFO:Preloading libraries
2024-09-07 16:01:31,851:INFO:Set up data.
2024-09-07 16:01:32,093:INFO:Set up index.
2024-09-07 16:01:33,411:INFO:Initializing get_config()
2024-09-07 16:01:33,411:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, variable=y_train)
2024-09-07 16:01:33,411:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-07 16:01:33,613:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-07 16:01:33,613:INFO:get_config() successfully completed......................................
2024-09-07 16:01:33,613:INFO:Initializing get_config()
2024-09-07 16:01:33,613:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, variable=y_test)
2024-09-07 16:01:33,613:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-07 16:01:33,730:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-07 16:01:33,731:INFO:get_config() successfully completed......................................
2024-09-07 16:01:33,735:INFO:Initializing finalize_model()
2024-09-07 16:01:33,735:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-07 16:01:33,735:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 16:01:34,154:INFO:Initializing create_model()
2024-09-07 16:01:34,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 16:01:34,154:INFO:Checking exceptions
2024-09-07 16:01:34,157:INFO:Importing libraries
2024-09-07 16:01:34,157:INFO:Copying training dataset
2024-09-07 16:01:34,228:INFO:Defining folds
2024-09-07 16:01:34,228:INFO:Declaring metric variables
2024-09-07 16:01:34,228:INFO:Importing untrained model
2024-09-07 16:01:34,229:INFO:Declaring custom model
2024-09-07 16:01:34,229:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 16:01:34,235:INFO:Cross validation set to False
2024-09-07 16:01:34,236:INFO:Fitting Model
2024-09-07 16:01:41,904:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210262 seconds.
2024-09-07 16:01:41,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 16:01:41,915:INFO:[LightGBM] [Info] Total Bins 103721
2024-09-07 16:01:41,919:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 427
2024-09-07 16:01:41,923:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 16:01:41,923:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 16:01:41,923:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 16:01:55,128:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-07 16:01:55,128:INFO:create_model() successfully completed......................................
2024-09-07 16:01:55,231:INFO:_master_model_container: 3
2024-09-07 16:01:55,232:INFO:_display_container: 4
2024-09-07 16:01:55,243:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-07 16:01:55,243:INFO:finalize_model() successfully completed......................................
2024-09-07 16:02:18,652:INFO:Initializing predict_model()
2024-09-07 16:02:18,652:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026860DE80D0>)
2024-09-07 16:02:18,652:INFO:Checking exceptions
2024-09-07 16:02:18,652:INFO:Preloading libraries
2024-09-07 16:02:18,655:INFO:Set up data.
2024-09-07 16:02:18,930:INFO:Set up index.
2024-09-07 16:03:08,229:INFO:Initializing predict_model()
2024-09-07 16:03:08,229:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026860DE8430>)
2024-09-07 16:03:08,230:INFO:Checking exceptions
2024-09-07 16:03:08,230:INFO:Preloading libraries
2024-09-07 16:03:08,232:INFO:Set up data.
2024-09-07 16:03:08,538:INFO:Set up index.
2024-09-07 16:38:45,472:INFO:Initializing plot_model()
2024-09-07 16:38:45,475:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002685EC91B10>, system=True)
2024-09-07 16:38:45,476:INFO:Checking exceptions
2024-09-07 16:38:46,464:INFO:Preloading libraries
2024-09-07 16:38:46,502:INFO:Copying training dataset
2024-09-07 16:38:46,502:INFO:Plot type: confusion_matrix
2024-09-07 16:38:48,848:INFO:Fitting Model
2024-09-07 16:38:48,852:INFO:Scoring test/hold-out set
2024-09-07 16:38:49,235:INFO:Visual Rendered Successfully
2024-09-07 16:38:49,423:INFO:plot_model() successfully completed......................................
2024-09-07 16:59:06,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 16:59:06,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 16:59:06,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 16:59:06,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 21:41:29,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 21:41:29,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 21:41:29,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 21:41:29,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 21:42:27,758:INFO:PyCaret ClassificationExperiment
2024-09-07 21:42:27,758:INFO:Logging name: clf-default-name
2024-09-07 21:42:27,758:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 21:42:27,758:INFO:version 3.3.2
2024-09-07 21:42:27,758:INFO:Initializing setup()
2024-09-07 21:42:27,758:INFO:self.USI: 4d81
2024-09-07 21:42:27,758:INFO:self._variable_keys: {'fix_imbalance', 'idx', 'is_multiclass', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'exp_id', 'exp_name_log', 'target_param', 'y_train', 'X', 'fold_groups_param', 'n_jobs_param', 'data', '_ml_usecase', 'seed', 'USI', 'html_param', 'pipeline', 'X_train', 'X_test', '_available_plots', 'fold_generator', 'logging_param', 'fold_shuffle_param', 'memory', 'gpu_param', 'y'}
2024-09-07 21:42:27,758:INFO:Checking environment
2024-09-07 21:42:27,758:INFO:python_version: 3.10.11
2024-09-07 21:42:27,758:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 21:42:27,758:INFO:machine: AMD64
2024-09-07 21:42:27,758:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 21:42:27,758:INFO:Memory: svmem(total=17128263680, available=7189057536, percent=58.0, used=9939206144, free=7189057536)
2024-09-07 21:42:27,758:INFO:Physical Core: 6
2024-09-07 21:42:27,758:INFO:Logical Core: 12
2024-09-07 21:42:27,758:INFO:Checking libraries
2024-09-07 21:42:27,758:INFO:System:
2024-09-07 21:42:27,758:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 21:42:27,758:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 21:42:27,758:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 21:42:27,758:INFO:PyCaret required dependencies:
2024-09-07 21:42:27,789:INFO:                 pip: 24.2
2024-09-07 21:42:27,789:INFO:          setuptools: 72.1.0
2024-09-07 21:42:27,789:INFO:             pycaret: 3.3.2
2024-09-07 21:42:27,789:INFO:             IPython: 8.27.0
2024-09-07 21:42:27,789:INFO:          ipywidgets: 8.1.5
2024-09-07 21:42:27,789:INFO:                tqdm: 4.66.5
2024-09-07 21:42:27,789:INFO:               numpy: 1.26.4
2024-09-07 21:42:27,789:INFO:              pandas: 2.2.2
2024-09-07 21:42:27,789:INFO:              jinja2: 3.1.4
2024-09-07 21:42:27,789:INFO:               scipy: 1.11.4
2024-09-07 21:42:27,789:INFO:              joblib: 1.3.2
2024-09-07 21:42:27,789:INFO:             sklearn: 1.4.2
2024-09-07 21:42:27,789:INFO:                pyod: 2.0.1
2024-09-07 21:42:27,789:INFO:            imblearn: 0.12.3
2024-09-07 21:42:27,789:INFO:   category_encoders: 2.6.3
2024-09-07 21:42:27,789:INFO:            lightgbm: 4.5.0
2024-09-07 21:42:27,789:INFO:               numba: 0.60.0
2024-09-07 21:42:27,789:INFO:            requests: 2.32.3
2024-09-07 21:42:27,789:INFO:          matplotlib: 3.7.5
2024-09-07 21:42:27,789:INFO:          scikitplot: 0.3.7
2024-09-07 21:42:27,789:INFO:         yellowbrick: 1.5
2024-09-07 21:42:27,789:INFO:              plotly: 5.24.0
2024-09-07 21:42:27,789:INFO:    plotly-resampler: Not installed
2024-09-07 21:42:27,789:INFO:             kaleido: 0.2.1
2024-09-07 21:42:27,789:INFO:           schemdraw: 0.15
2024-09-07 21:42:27,789:INFO:         statsmodels: 0.14.2
2024-09-07 21:42:27,789:INFO:              sktime: 0.26.0
2024-09-07 21:42:27,789:INFO:               tbats: 1.1.3
2024-09-07 21:42:27,789:INFO:            pmdarima: 2.0.4
2024-09-07 21:42:27,789:INFO:              psutil: 6.0.0
2024-09-07 21:42:27,789:INFO:          markupsafe: 2.1.5
2024-09-07 21:42:27,789:INFO:             pickle5: Not installed
2024-09-07 21:42:27,789:INFO:         cloudpickle: 3.0.0
2024-09-07 21:42:27,789:INFO:         deprecation: 2.1.0
2024-09-07 21:42:27,789:INFO:              xxhash: 3.5.0
2024-09-07 21:42:27,789:INFO:           wurlitzer: Not installed
2024-09-07 21:42:27,789:INFO:PyCaret optional dependencies:
2024-09-07 21:42:27,805:INFO:                shap: Not installed
2024-09-07 21:42:27,805:INFO:           interpret: Not installed
2024-09-07 21:42:27,805:INFO:                umap: Not installed
2024-09-07 21:42:27,805:INFO:     ydata_profiling: Not installed
2024-09-07 21:42:27,805:INFO:  explainerdashboard: Not installed
2024-09-07 21:42:27,805:INFO:             autoviz: Not installed
2024-09-07 21:42:27,805:INFO:           fairlearn: Not installed
2024-09-07 21:42:27,805:INFO:          deepchecks: Not installed
2024-09-07 21:42:27,805:INFO:             xgboost: 2.1.1
2024-09-07 21:42:27,805:INFO:            catboost: Not installed
2024-09-07 21:42:27,805:INFO:              kmodes: Not installed
2024-09-07 21:42:27,805:INFO:             mlxtend: Not installed
2024-09-07 21:42:27,805:INFO:       statsforecast: Not installed
2024-09-07 21:42:27,805:INFO:        tune_sklearn: Not installed
2024-09-07 21:42:27,805:INFO:                 ray: Not installed
2024-09-07 21:42:27,805:INFO:            hyperopt: 0.2.7
2024-09-07 21:42:27,805:INFO:              optuna: 4.0.0
2024-09-07 21:42:27,805:INFO:               skopt: 0.10.2
2024-09-07 21:42:27,805:INFO:              mlflow: Not installed
2024-09-07 21:42:27,805:INFO:              gradio: Not installed
2024-09-07 21:42:27,805:INFO:             fastapi: Not installed
2024-09-07 21:42:27,805:INFO:             uvicorn: Not installed
2024-09-07 21:42:27,805:INFO:              m2cgen: Not installed
2024-09-07 21:42:27,805:INFO:           evidently: Not installed
2024-09-07 21:42:27,805:INFO:               fugue: Not installed
2024-09-07 21:42:27,805:INFO:           streamlit: Not installed
2024-09-07 21:42:27,805:INFO:             prophet: Not installed
2024-09-07 21:42:27,805:INFO:None
2024-09-07 21:42:27,805:INFO:Set up data.
2024-09-07 21:42:28,270:INFO:Set up folding strategy.
2024-09-07 21:42:28,270:INFO:Set up train/test split.
2024-09-07 21:42:28,908:INFO:Set up index.
2024-09-07 21:42:28,923:INFO:Assigning column types.
2024-09-07 21:42:29,539:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-07 21:42:29,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 21:42:29,602:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 21:42:29,633:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 21:42:29,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 21:42:29,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 21:42:29,696:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 21:42:29,727:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 21:42:29,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 21:42:29,727:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-07 21:42:29,774:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 21:42:29,806:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 21:42:29,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 21:42:29,861:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 21:42:29,893:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 21:42:29,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 21:42:29,893:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-07 21:42:29,974:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 21:42:29,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 21:42:30,049:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 21:42:30,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 21:42:30,049:INFO:Preparing preprocessing pipeline...
2024-09-07 21:42:30,159:INFO:Set up simple imputation.
2024-09-07 21:42:30,159:INFO:Set up imbalanced handling.
2024-09-07 21:42:31,008:INFO:Finished creating preprocessing pipeline.
2024-09-07 21:42:31,008:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-07 21:42:31,008:INFO:Creating final display dataframe.
2024-09-07 21:42:33,601:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 428)
4        Transformed data shape      (99147, 428)
5   Transformed train set shape      (76191, 428)
6    Transformed test set shape      (22956, 428)
7              Numeric features               427
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              4d81
2024-09-07 21:42:33,687:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 21:42:33,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 21:42:33,765:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 21:42:33,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 21:42:33,780:INFO:setup() successfully completed in 6.08s...............
2024-09-07 21:42:33,780:INFO:Initializing compare_models()
2024-09-07 21:42:33,780:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, include=['lightgbm', 'xgboost', 'rf', 'lr'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, 'include': ['lightgbm', 'xgboost', 'rf', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-07 21:42:33,780:INFO:Checking exceptions
2024-09-07 21:42:34,229:INFO:Preparing display monitor
2024-09-07 21:42:34,229:INFO:Initializing Light Gradient Boosting Machine
2024-09-07 21:42:34,229:INFO:Total runtime is 0.0 minutes
2024-09-07 21:42:34,229:INFO:SubProcess create_model() called ==================================
2024-09-07 21:42:34,229:INFO:Initializing create_model()
2024-09-07 21:42:34,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E04688FC70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 21:42:34,229:INFO:Checking exceptions
2024-09-07 21:42:34,229:INFO:Importing libraries
2024-09-07 21:42:34,229:INFO:Copying training dataset
2024-09-07 21:42:34,930:INFO:Defining folds
2024-09-07 21:42:34,930:INFO:Declaring metric variables
2024-09-07 21:42:34,930:INFO:Importing untrained model
2024-09-07 21:42:34,930:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 21:42:34,930:INFO:Starting cross validation
2024-09-07 21:42:34,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 21:45:04,966:INFO:Calculating mean and std
2024-09-07 21:45:04,967:INFO:Creating metrics dataframe
2024-09-07 21:45:04,971:INFO:Uploading results into container
2024-09-07 21:45:04,972:INFO:Uploading model into container now
2024-09-07 21:45:04,973:INFO:_master_model_container: 1
2024-09-07 21:45:04,973:INFO:_display_container: 2
2024-09-07 21:45:04,974:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 21:45:04,974:INFO:create_model() successfully completed......................................
2024-09-07 21:45:05,143:INFO:SubProcess create_model() end ==================================
2024-09-07 21:45:05,143:INFO:Creating metrics dataframe
2024-09-07 21:45:05,146:INFO:Initializing Extreme Gradient Boosting
2024-09-07 21:45:05,147:INFO:Total runtime is 2.515301684538523 minutes
2024-09-07 21:45:05,147:INFO:SubProcess create_model() called ==================================
2024-09-07 21:45:05,147:INFO:Initializing create_model()
2024-09-07 21:45:05,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E04688FC70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 21:45:05,147:INFO:Checking exceptions
2024-09-07 21:45:05,147:INFO:Importing libraries
2024-09-07 21:45:05,148:INFO:Copying training dataset
2024-09-07 21:45:06,159:INFO:Defining folds
2024-09-07 21:45:06,160:INFO:Declaring metric variables
2024-09-07 21:45:06,160:INFO:Importing untrained model
2024-09-07 21:45:06,161:INFO:Extreme Gradient Boosting Imported successfully
2024-09-07 21:45:06,161:INFO:Starting cross validation
2024-09-07 21:45:06,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 21:46:39,976:INFO:Calculating mean and std
2024-09-07 21:46:39,976:INFO:Creating metrics dataframe
2024-09-07 21:46:39,976:INFO:Uploading results into container
2024-09-07 21:46:39,976:INFO:Uploading model into container now
2024-09-07 21:46:39,976:INFO:_master_model_container: 2
2024-09-07 21:46:39,976:INFO:_display_container: 2
2024-09-07 21:46:39,976:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-07 21:46:39,976:INFO:create_model() successfully completed......................................
2024-09-07 21:46:40,055:INFO:SubProcess create_model() end ==================================
2024-09-07 21:46:40,055:INFO:Creating metrics dataframe
2024-09-07 21:46:40,055:INFO:Initializing Random Forest Classifier
2024-09-07 21:46:40,055:INFO:Total runtime is 4.097091714541117 minutes
2024-09-07 21:46:40,055:INFO:SubProcess create_model() called ==================================
2024-09-07 21:46:40,055:INFO:Initializing create_model()
2024-09-07 21:46:40,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E04688FC70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 21:46:40,055:INFO:Checking exceptions
2024-09-07 21:46:40,055:INFO:Importing libraries
2024-09-07 21:46:40,055:INFO:Copying training dataset
2024-09-07 21:46:40,722:INFO:Defining folds
2024-09-07 21:46:40,722:INFO:Declaring metric variables
2024-09-07 21:46:40,722:INFO:Importing untrained model
2024-09-07 21:46:40,723:INFO:Random Forest Classifier Imported successfully
2024-09-07 21:46:40,723:INFO:Starting cross validation
2024-09-07 21:46:40,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 21:48:23,094:INFO:Calculating mean and std
2024-09-07 21:48:23,094:INFO:Creating metrics dataframe
2024-09-07 21:48:23,094:INFO:Uploading results into container
2024-09-07 21:48:23,094:INFO:Uploading model into container now
2024-09-07 21:48:23,094:INFO:_master_model_container: 3
2024-09-07 21:48:23,094:INFO:_display_container: 2
2024-09-07 21:48:23,094:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-07 21:48:23,094:INFO:create_model() successfully completed......................................
2024-09-07 21:48:23,179:INFO:SubProcess create_model() end ==================================
2024-09-07 21:48:23,179:INFO:Creating metrics dataframe
2024-09-07 21:48:23,179:INFO:Initializing Logistic Regression
2024-09-07 21:48:23,179:INFO:Total runtime is 5.815835599104563 minutes
2024-09-07 21:48:23,179:INFO:SubProcess create_model() called ==================================
2024-09-07 21:48:23,179:INFO:Initializing create_model()
2024-09-07 21:48:23,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E04688FC70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 21:48:23,179:INFO:Checking exceptions
2024-09-07 21:48:23,179:INFO:Importing libraries
2024-09-07 21:48:23,179:INFO:Copying training dataset
2024-09-07 21:48:23,890:INFO:Defining folds
2024-09-07 21:48:23,890:INFO:Declaring metric variables
2024-09-07 21:48:23,890:INFO:Importing untrained model
2024-09-07 21:48:23,890:INFO:Logistic Regression Imported successfully
2024-09-07 21:48:23,890:INFO:Starting cross validation
2024-09-07 21:48:23,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 21:51:36,258:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:38,461:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:39,835:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:40,319:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:42,174:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:45,298:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:45,980:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:46,346:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:46,805:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:46,960:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 21:51:46,992:INFO:Calculating mean and std
2024-09-07 21:51:46,992:INFO:Creating metrics dataframe
2024-09-07 21:51:46,992:INFO:Uploading results into container
2024-09-07 21:51:46,992:INFO:Uploading model into container now
2024-09-07 21:51:46,992:INFO:_master_model_container: 4
2024-09-07 21:51:46,992:INFO:_display_container: 2
2024-09-07 21:51:46,992:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-07 21:51:46,992:INFO:create_model() successfully completed......................................
2024-09-07 21:51:47,067:INFO:SubProcess create_model() end ==================================
2024-09-07 21:51:47,067:INFO:Creating metrics dataframe
2024-09-07 21:51:47,067:INFO:Initializing create_model()
2024-09-07 21:51:47,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 21:51:47,067:INFO:Checking exceptions
2024-09-07 21:51:47,067:INFO:Importing libraries
2024-09-07 21:51:47,067:INFO:Copying training dataset
2024-09-07 21:51:47,694:INFO:Defining folds
2024-09-07 21:51:47,694:INFO:Declaring metric variables
2024-09-07 21:51:47,694:INFO:Importing untrained model
2024-09-07 21:51:47,694:INFO:Declaring custom model
2024-09-07 21:51:47,694:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 21:51:47,710:INFO:Cross validation set to False
2024-09-07 21:51:47,710:INFO:Fitting Model
2024-09-07 21:51:52,396:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130484 seconds.
2024-09-07 21:51:52,396:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 21:51:52,408:INFO:[LightGBM] [Info] Total Bins 102580
2024-09-07 21:51:52,412:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 426
2024-09-07 21:51:52,415:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 21:51:52,415:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 21:51:52,415:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 21:52:02,603:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 21:52:02,603:INFO:create_model() successfully completed......................................
2024-09-07 21:52:02,683:INFO:Initializing create_model()
2024-09-07 21:52:02,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 21:52:02,683:INFO:Checking exceptions
2024-09-07 21:52:02,683:INFO:Importing libraries
2024-09-07 21:52:02,683:INFO:Copying training dataset
2024-09-07 21:52:03,312:INFO:Defining folds
2024-09-07 21:52:03,312:INFO:Declaring metric variables
2024-09-07 21:52:03,312:INFO:Importing untrained model
2024-09-07 21:52:03,312:INFO:Declaring custom model
2024-09-07 21:52:03,312:INFO:Extreme Gradient Boosting Imported successfully
2024-09-07 21:52:03,312:INFO:Cross validation set to False
2024-09-07 21:52:03,312:INFO:Fitting Model
2024-09-07 21:52:18,288:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-07 21:52:18,288:INFO:create_model() successfully completed......................................
2024-09-07 21:52:18,408:INFO:Initializing create_model()
2024-09-07 21:52:18,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 21:52:18,408:INFO:Checking exceptions
2024-09-07 21:52:18,409:INFO:Importing libraries
2024-09-07 21:52:18,409:INFO:Copying training dataset
2024-09-07 21:52:19,085:INFO:Defining folds
2024-09-07 21:52:19,085:INFO:Declaring metric variables
2024-09-07 21:52:19,086:INFO:Importing untrained model
2024-09-07 21:52:19,086:INFO:Declaring custom model
2024-09-07 21:52:19,087:INFO:Random Forest Classifier Imported successfully
2024-09-07 21:52:19,089:INFO:Cross validation set to False
2024-09-07 21:52:19,089:INFO:Fitting Model
2024-09-07 21:52:32,485:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-07 21:52:32,485:INFO:create_model() successfully completed......................................
2024-09-07 21:52:32,574:INFO:_master_model_container: 4
2024-09-07 21:52:32,574:INFO:_display_container: 2
2024-09-07 21:52:32,574:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)]
2024-09-07 21:52:32,574:INFO:compare_models() successfully completed......................................
2024-09-07 21:52:32,574:INFO:Initializing tune_model()
2024-09-07 21:52:32,574:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [3, 5, 7], 'min_child_weight': [5, 10, 20], 'subsample': [0.6, 0.7, 0.8], 'colsample_bytree': [0.6, 0.7, 0.8]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>)
2024-09-07 21:52:32,574:INFO:Checking exceptions
2024-09-07 21:52:32,574:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-07 21:52:32,931:INFO:Copying training dataset
2024-09-07 21:52:33,331:INFO:Checking base model
2024-09-07 21:52:33,331:INFO:Base model : Extreme Gradient Boosting
2024-09-07 21:52:33,331:INFO:Declaring metric variables
2024-09-07 21:52:33,331:INFO:Defining Hyperparameters
2024-09-07 21:52:33,400:INFO:custom_grid: {'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__min_child_weight': CategoricalDistribution(values=[5, 10, 20]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.6, 0.7, 0.8]), 'actual_estimator__colsample_bytree': CategoricalDistribution(values=[0.6, 0.7, 0.8])}
2024-09-07 21:52:33,400:INFO:Tuning with n_jobs=-1
2024-09-07 21:52:33,400:INFO:Initializing skopt.BayesSearchCV
2024-09-07 22:01:12,276:INFO:best_params: OrderedDict([('actual_estimator__colsample_bytree', 0.8), ('actual_estimator__max_depth', 5), ('actual_estimator__min_child_weight', 20), ('actual_estimator__subsample', 0.7)])
2024-09-07 22:01:12,283:INFO:Hyperparameter search completed
2024-09-07 22:01:12,283:INFO:SubProcess create_model() called ==================================
2024-09-07 22:01:12,283:INFO:Initializing create_model()
2024-09-07 22:01:12,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E05113E4A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 20, 'subsample': 0.7})
2024-09-07 22:01:12,283:INFO:Checking exceptions
2024-09-07 22:01:12,283:INFO:Importing libraries
2024-09-07 22:01:12,283:INFO:Copying training dataset
2024-09-07 22:01:12,947:INFO:Defining folds
2024-09-07 22:01:12,947:INFO:Declaring metric variables
2024-09-07 22:01:12,947:INFO:Importing untrained model
2024-09-07 22:01:12,947:INFO:Declaring custom model
2024-09-07 22:01:12,947:INFO:Extreme Gradient Boosting Imported successfully
2024-09-07 22:01:12,947:INFO:Starting cross validation
2024-09-07 22:01:12,947:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 22:02:00,550:INFO:Calculating mean and std
2024-09-07 22:02:00,551:INFO:Creating metrics dataframe
2024-09-07 22:02:00,553:INFO:Finalizing model
2024-09-07 22:02:12,743:INFO:Uploading results into container
2024-09-07 22:02:12,743:INFO:Uploading model into container now
2024-09-07 22:02:12,743:INFO:_master_model_container: 5
2024-09-07 22:02:12,743:INFO:_display_container: 3
2024-09-07 22:02:12,743:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=20, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-07 22:02:12,743:INFO:create_model() successfully completed......................................
2024-09-07 22:02:12,878:INFO:SubProcess create_model() end ==================================
2024-09-07 22:02:12,878:INFO:choose_better activated
2024-09-07 22:02:12,878:INFO:SubProcess create_model() called ==================================
2024-09-07 22:02:12,884:INFO:Initializing create_model()
2024-09-07 22:02:12,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:02:12,884:INFO:Checking exceptions
2024-09-07 22:02:12,885:INFO:Importing libraries
2024-09-07 22:02:12,885:INFO:Copying training dataset
2024-09-07 22:02:13,500:INFO:Defining folds
2024-09-07 22:02:13,500:INFO:Declaring metric variables
2024-09-07 22:02:13,500:INFO:Importing untrained model
2024-09-07 22:02:13,500:INFO:Declaring custom model
2024-09-07 22:02:13,500:INFO:Extreme Gradient Boosting Imported successfully
2024-09-07 22:02:13,500:INFO:Starting cross validation
2024-09-07 22:02:13,500:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 22:03:11,443:INFO:Calculating mean and std
2024-09-07 22:03:11,443:INFO:Creating metrics dataframe
2024-09-07 22:03:11,445:INFO:Finalizing model
2024-09-07 22:03:26,140:INFO:Uploading results into container
2024-09-07 22:03:26,140:INFO:Uploading model into container now
2024-09-07 22:03:26,140:INFO:_master_model_container: 6
2024-09-07 22:03:26,140:INFO:_display_container: 4
2024-09-07 22:03:26,140:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-07 22:03:26,140:INFO:create_model() successfully completed......................................
2024-09-07 22:03:26,250:INFO:SubProcess create_model() end ==================================
2024-09-07 22:03:26,250:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...) result for Accuracy is 0.826
2024-09-07 22:03:26,250:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=20, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...) result for Accuracy is 0.8286
2024-09-07 22:03:26,250:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=20, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...) is best model
2024-09-07 22:03:26,250:INFO:choose_better completed
2024-09-07 22:03:26,266:INFO:_master_model_container: 6
2024-09-07 22:03:26,266:INFO:_display_container: 3
2024-09-07 22:03:26,266:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=20, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-07 22:03:26,266:INFO:tune_model() successfully completed......................................
2024-09-07 22:03:26,357:INFO:Initializing predict_model()
2024-09-07 22:03:26,357:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=20, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E05C463A30>)
2024-09-07 22:03:26,357:INFO:Checking exceptions
2024-09-07 22:03:26,357:INFO:Preloading libraries
2024-09-07 22:03:26,357:INFO:Set up data.
2024-09-07 22:03:26,631:INFO:Set up index.
2024-09-07 22:03:27,255:INFO:Initializing get_config()
2024-09-07 22:03:27,255:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, variable=X_train)
2024-09-07 22:03:27,255:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-07 22:03:27,676:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  feature_7  ...  feature_419  feature_420  feature_421  feature_422  feature_423  feature_424  feature_425  feature_426
71710  -0.903637   2.736559   0.372071   0.304834  -0.307305  -0.216109   1.112682   0.908807  ...    -0.082721     0.049159    -0.814324    -1.269576    -0.978704    -0.657480     0.665040     0.918771
41786   1.373649  -0.522903   0.083904   0.304834   1.787297   0.066573  -1.226048  -1.505896  ...    -0.082721     0.049159     1.938017    -0.543544    -0.447987    -0.785362     0.023022    -0.833264
53345  -0.903637  -0.522903   0.083904   0.304834  -0.307305  -1.127987   1.112682   0.908807  ...    -0.082721     0.049159    -0.814324    -1.269576    -0.978704    -0.657480     0.665040     0.918771
11745   0.055220  -0.522903   0.049743   0.304834  -0.307305  -0.854424  -0.056683   0.975882  ...    13.379660     1.386740    -1.298134     0.330275     0.189874     0.765493     0.279644    -0.979924
23494  -0.903637  -0.522903   0.134044   0.304834  -0.307305   3.249027  -0.056683   1.042958  ...    -0.082721     0.049159     1.938017    -0.543544    -0.447987    -0.785362     0.023022    -0.833264
...          ...        ...        ...        ...        ...        ...        ...        ...  ...          ...          ...          ...          ...          ...          ...          ...          ...
45374  -0.903637  -0.522903   0.278403   0.304834  -0.307305   1.516459   1.112682   0.908807  ...    -0.082721     0.049159     0.338756     1.927194    -0.693992     2.376801    -1.369871    -0.430422
38857   1.373649  -0.522903  -0.540365  -3.280477   1.787297  -2.039865  -0.056683   0.707582  ...    -0.082721     0.049159    -1.298134     0.330275     0.189874     0.765493     0.279644    -0.979924
31149  -0.903637   0.291962   0.428822   0.304834  -0.307305  -0.033734  -0.056683   0.975882  ...    -0.082721     0.049159     1.587176     1.716656    -2.215057     1.016606    -2.545979     2.249198
55353  -0.903637  -0.522903   0.134044   0.304834  -0.307305  -0.216109  -0.056683   0.975882  ...    -0.082721     0.049159     0.219701    -0.464959     0.917071    -0.748160     0.294235    -0.368505
1638    0.055220  -0.522903   0.428822   0.304834  -0.307305  -0.854424  -0.056683   0.908807  ...    -0.082721     0.049159    -0.814324    -1.269576    -0.978704    -0.657480     0.665040     0.918771

[53562 rows x 427 columns]
2024-09-07 22:03:27,676:INFO:get_config() successfully completed......................................
2024-09-07 22:03:27,676:INFO:Initializing predict_model()
2024-09-07 22:03:27,676:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=20, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E045DCD510>)
2024-09-07 22:03:27,676:INFO:Checking exceptions
2024-09-07 22:03:27,676:INFO:Preloading libraries
2024-09-07 22:03:27,676:INFO:Set up data.
2024-09-07 22:03:27,891:INFO:Set up index.
2024-09-07 22:03:28,717:INFO:Initializing get_config()
2024-09-07 22:03:28,717:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, variable=y_train)
2024-09-07 22:03:28,717:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-07 22:03:28,881:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-07 22:03:28,881:INFO:get_config() successfully completed......................................
2024-09-07 22:03:28,881:INFO:Initializing get_config()
2024-09-07 22:03:28,881:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, variable=y_test)
2024-09-07 22:03:28,882:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-07 22:03:28,993:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-07 22:03:28,993:INFO:get_config() successfully completed......................................
2024-09-07 22:03:28,993:INFO:Initializing finalize_model()
2024-09-07 22:03:28,993:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=20, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-07 22:03:28,993:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=20, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-07 22:03:29,455:INFO:Initializing create_model()
2024-09-07 22:03:29,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=20, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:03:29,455:INFO:Checking exceptions
2024-09-07 22:03:29,456:INFO:Importing libraries
2024-09-07 22:03:29,456:INFO:Copying training dataset
2024-09-07 22:03:29,531:INFO:Defining folds
2024-09-07 22:03:29,531:INFO:Declaring metric variables
2024-09-07 22:03:29,532:INFO:Importing untrained model
2024-09-07 22:03:29,532:INFO:Declaring custom model
2024-09-07 22:03:29,534:INFO:Extreme Gradient Boosting Imported successfully
2024-09-07 22:03:29,537:INFO:Cross validation set to False
2024-09-07 22:03:29,537:INFO:Fitting Model
2024-09-07 22:03:45,498:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=5, max_leaves=None,
                               min_child_weight=20, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='multi:softprob', ...))],
         verbose=False)
2024-09-07 22:03:45,498:INFO:create_model() successfully completed......................................
2024-09-07 22:03:45,623:INFO:_master_model_container: 6
2024-09-07 22:03:45,623:INFO:_display_container: 4
2024-09-07 22:03:45,639:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=5, max_leaves=None,
                               min_child_weight=20, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='multi:softprob', ...))],
         verbose=False)
2024-09-07 22:03:45,639:INFO:finalize_model() successfully completed......................................
2024-09-07 22:03:45,733:INFO:Initializing predict_model()
2024-09-07 22:03:45,738:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E043231450>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=5, max_leaves=None,
                               min_child_weight=20, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='multi:softprob', ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E045DCD510>)
2024-09-07 22:03:45,738:INFO:Checking exceptions
2024-09-07 22:03:45,738:INFO:Preloading libraries
2024-09-07 22:03:45,738:INFO:Set up data.
2024-09-07 22:03:46,144:INFO:Set up index.
2024-09-07 22:03:47,075:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 22:03:48,509:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

2024-09-07 22:03:49,618:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 22:03:49,745:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Displaced is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:03:49,745:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Educational special needs is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:03:49,761:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Debtor is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:03:49,761:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:03:49,761:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Scholarship holder is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:03:49,761:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable International is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:04:47,504:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\joblib\memory.py:999: DeprecationWarning: bytes_limit argument has been deprecated. It will be removed in version 1.5. Please pass its value directly to Memory.reduce_size.
  warnings.warn(

2024-09-07 22:04:47,536:INFO:PyCaret ClassificationExperiment
2024-09-07 22:04:47,536:INFO:Logging name: clf-default-name
2024-09-07 22:04:47,536:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 22:04:47,536:INFO:version 3.3.2
2024-09-07 22:04:47,536:INFO:Initializing setup()
2024-09-07 22:04:47,536:INFO:self.USI: 58b9
2024-09-07 22:04:47,536:INFO:self._variable_keys: {'fix_imbalance', 'idx', 'is_multiclass', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'exp_id', 'exp_name_log', 'target_param', 'y_train', 'X', 'fold_groups_param', 'n_jobs_param', 'data', '_ml_usecase', 'seed', 'USI', 'html_param', 'pipeline', 'X_train', 'X_test', '_available_plots', 'fold_generator', 'logging_param', 'fold_shuffle_param', 'memory', 'gpu_param', 'y'}
2024-09-07 22:04:47,536:INFO:Checking environment
2024-09-07 22:04:47,536:INFO:python_version: 3.10.11
2024-09-07 22:04:47,536:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 22:04:47,536:INFO:machine: AMD64
2024-09-07 22:04:47,536:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 22:04:47,536:INFO:Memory: svmem(total=17128263680, available=4973260800, percent=71.0, used=12155002880, free=4973260800)
2024-09-07 22:04:47,536:INFO:Physical Core: 6
2024-09-07 22:04:47,536:INFO:Logical Core: 12
2024-09-07 22:04:47,536:INFO:Checking libraries
2024-09-07 22:04:47,536:INFO:System:
2024-09-07 22:04:47,536:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 22:04:47,536:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 22:04:47,536:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 22:04:47,536:INFO:PyCaret required dependencies:
2024-09-07 22:04:47,536:INFO:                 pip: 24.2
2024-09-07 22:04:47,536:INFO:          setuptools: 72.1.0
2024-09-07 22:04:47,536:INFO:             pycaret: 3.3.2
2024-09-07 22:04:47,536:INFO:             IPython: 8.27.0
2024-09-07 22:04:47,536:INFO:          ipywidgets: 8.1.5
2024-09-07 22:04:47,536:INFO:                tqdm: 4.66.5
2024-09-07 22:04:47,536:INFO:               numpy: 1.26.4
2024-09-07 22:04:47,536:INFO:              pandas: 2.2.2
2024-09-07 22:04:47,536:INFO:              jinja2: 3.1.4
2024-09-07 22:04:47,536:INFO:               scipy: 1.11.4
2024-09-07 22:04:47,536:INFO:              joblib: 1.3.2
2024-09-07 22:04:47,536:INFO:             sklearn: 1.4.2
2024-09-07 22:04:47,536:INFO:                pyod: 2.0.1
2024-09-07 22:04:47,536:INFO:            imblearn: 0.12.3
2024-09-07 22:04:47,536:INFO:   category_encoders: 2.6.3
2024-09-07 22:04:47,536:INFO:            lightgbm: 4.5.0
2024-09-07 22:04:47,536:INFO:               numba: 0.60.0
2024-09-07 22:04:47,536:INFO:            requests: 2.32.3
2024-09-07 22:04:47,536:INFO:          matplotlib: 3.7.5
2024-09-07 22:04:47,536:INFO:          scikitplot: 0.3.7
2024-09-07 22:04:47,536:INFO:         yellowbrick: 1.5
2024-09-07 22:04:47,536:INFO:              plotly: 5.24.0
2024-09-07 22:04:47,536:INFO:    plotly-resampler: Not installed
2024-09-07 22:04:47,536:INFO:             kaleido: 0.2.1
2024-09-07 22:04:47,536:INFO:           schemdraw: 0.15
2024-09-07 22:04:47,536:INFO:         statsmodels: 0.14.2
2024-09-07 22:04:47,536:INFO:              sktime: 0.26.0
2024-09-07 22:04:47,536:INFO:               tbats: 1.1.3
2024-09-07 22:04:47,536:INFO:            pmdarima: 2.0.4
2024-09-07 22:04:47,536:INFO:              psutil: 6.0.0
2024-09-07 22:04:47,536:INFO:          markupsafe: 2.1.5
2024-09-07 22:04:47,536:INFO:             pickle5: Not installed
2024-09-07 22:04:47,536:INFO:         cloudpickle: 3.0.0
2024-09-07 22:04:47,536:INFO:         deprecation: 2.1.0
2024-09-07 22:04:47,536:INFO:              xxhash: 3.5.0
2024-09-07 22:04:47,536:INFO:           wurlitzer: Not installed
2024-09-07 22:04:47,536:INFO:PyCaret optional dependencies:
2024-09-07 22:04:47,536:INFO:                shap: Not installed
2024-09-07 22:04:47,536:INFO:           interpret: Not installed
2024-09-07 22:04:47,536:INFO:                umap: Not installed
2024-09-07 22:04:47,536:INFO:     ydata_profiling: Not installed
2024-09-07 22:04:47,536:INFO:  explainerdashboard: Not installed
2024-09-07 22:04:47,536:INFO:             autoviz: Not installed
2024-09-07 22:04:47,536:INFO:           fairlearn: Not installed
2024-09-07 22:04:47,536:INFO:          deepchecks: Not installed
2024-09-07 22:04:47,536:INFO:             xgboost: 2.1.1
2024-09-07 22:04:47,536:INFO:            catboost: Not installed
2024-09-07 22:04:47,536:INFO:              kmodes: Not installed
2024-09-07 22:04:47,536:INFO:             mlxtend: Not installed
2024-09-07 22:04:47,536:INFO:       statsforecast: Not installed
2024-09-07 22:04:47,536:INFO:        tune_sklearn: Not installed
2024-09-07 22:04:47,536:INFO:                 ray: Not installed
2024-09-07 22:04:47,536:INFO:            hyperopt: 0.2.7
2024-09-07 22:04:47,536:INFO:              optuna: 4.0.0
2024-09-07 22:04:47,536:INFO:               skopt: 0.10.2
2024-09-07 22:04:47,536:INFO:              mlflow: Not installed
2024-09-07 22:04:47,536:INFO:              gradio: Not installed
2024-09-07 22:04:47,536:INFO:             fastapi: Not installed
2024-09-07 22:04:47,536:INFO:             uvicorn: Not installed
2024-09-07 22:04:47,536:INFO:              m2cgen: Not installed
2024-09-07 22:04:47,536:INFO:           evidently: Not installed
2024-09-07 22:04:47,536:INFO:               fugue: Not installed
2024-09-07 22:04:47,536:INFO:           streamlit: Not installed
2024-09-07 22:04:47,536:INFO:             prophet: Not installed
2024-09-07 22:04:47,536:INFO:None
2024-09-07 22:04:47,536:INFO:Set up data.
2024-09-07 22:04:48,095:INFO:Set up folding strategy.
2024-09-07 22:04:48,095:INFO:Set up train/test split.
2024-09-07 22:04:48,617:INFO:Set up index.
2024-09-07 22:04:48,617:INFO:Assigning column types.
2024-09-07 22:04:49,096:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-07 22:04:49,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 22:04:49,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 22:04:49,186:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:04:49,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:04:49,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 22:04:49,237:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 22:04:49,268:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:04:49,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:04:49,268:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-07 22:04:49,316:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 22:04:49,349:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:04:49,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:04:49,392:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 22:04:49,423:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:04:49,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:04:49,423:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-07 22:04:49,502:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:04:49,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:04:49,587:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:04:49,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:04:49,596:INFO:Preparing preprocessing pipeline...
2024-09-07 22:04:49,658:INFO:Set up simple imputation.
2024-09-07 22:04:49,658:INFO:Set up imbalanced handling.
2024-09-07 22:04:50,355:INFO:Finished creating preprocessing pipeline.
2024-09-07 22:04:50,355:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-07 22:04:50,355:INFO:Creating final display dataframe.
2024-09-07 22:04:52,526:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 428)
4        Transformed data shape      (99147, 428)
5   Transformed train set shape      (76191, 428)
6    Transformed test set shape      (22956, 428)
7              Numeric features               427
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              58b9
2024-09-07 22:04:52,614:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:04:52,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:04:52,692:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:04:52,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:04:52,692:INFO:setup() successfully completed in 5.19s...............
2024-09-07 22:04:52,692:INFO:Initializing compare_models()
2024-09-07 22:04:52,692:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, include=['lightgbm', 'xgboost', 'rf', 'lr'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, 'include': ['lightgbm', 'xgboost', 'rf', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-07 22:04:52,692:INFO:Checking exceptions
2024-09-07 22:04:53,037:INFO:Preparing display monitor
2024-09-07 22:04:53,037:INFO:Initializing Light Gradient Boosting Machine
2024-09-07 22:04:53,037:INFO:Total runtime is 0.0 minutes
2024-09-07 22:04:53,037:INFO:SubProcess create_model() called ==================================
2024-09-07 22:04:53,037:INFO:Initializing create_model()
2024-09-07 22:04:53,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0511ADDB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:04:53,037:INFO:Checking exceptions
2024-09-07 22:04:53,037:INFO:Importing libraries
2024-09-07 22:04:53,037:INFO:Copying training dataset
2024-09-07 22:04:53,621:INFO:Defining folds
2024-09-07 22:04:53,621:INFO:Declaring metric variables
2024-09-07 22:04:53,621:INFO:Importing untrained model
2024-09-07 22:04:53,621:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 22:04:53,621:INFO:Starting cross validation
2024-09-07 22:04:53,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 22:07:23,286:INFO:Calculating mean and std
2024-09-07 22:07:23,288:INFO:Creating metrics dataframe
2024-09-07 22:07:23,291:INFO:Uploading results into container
2024-09-07 22:07:23,292:INFO:Uploading model into container now
2024-09-07 22:07:23,292:INFO:_master_model_container: 1
2024-09-07 22:07:23,292:INFO:_display_container: 2
2024-09-07 22:07:23,292:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 22:07:23,293:INFO:create_model() successfully completed......................................
2024-09-07 22:07:23,477:INFO:SubProcess create_model() end ==================================
2024-09-07 22:07:23,478:INFO:Creating metrics dataframe
2024-09-07 22:07:23,482:INFO:Initializing Extreme Gradient Boosting
2024-09-07 22:07:23,482:INFO:Total runtime is 2.507419228553772 minutes
2024-09-07 22:07:23,483:INFO:SubProcess create_model() called ==================================
2024-09-07 22:07:23,484:INFO:Initializing create_model()
2024-09-07 22:07:23,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0511ADDB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:07:23,484:INFO:Checking exceptions
2024-09-07 22:07:23,484:INFO:Importing libraries
2024-09-07 22:07:23,484:INFO:Copying training dataset
2024-09-07 22:07:24,379:INFO:Defining folds
2024-09-07 22:07:24,379:INFO:Declaring metric variables
2024-09-07 22:07:24,379:INFO:Importing untrained model
2024-09-07 22:07:24,379:INFO:Extreme Gradient Boosting Imported successfully
2024-09-07 22:07:24,379:INFO:Starting cross validation
2024-09-07 22:07:24,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 22:08:58,045:INFO:Calculating mean and std
2024-09-07 22:08:58,047:INFO:Creating metrics dataframe
2024-09-07 22:08:58,050:INFO:Uploading results into container
2024-09-07 22:08:58,050:INFO:Uploading model into container now
2024-09-07 22:08:58,051:INFO:_master_model_container: 2
2024-09-07 22:08:58,051:INFO:_display_container: 2
2024-09-07 22:08:58,052:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-07 22:08:58,052:INFO:create_model() successfully completed......................................
2024-09-07 22:08:58,141:INFO:SubProcess create_model() end ==================================
2024-09-07 22:08:58,141:INFO:Creating metrics dataframe
2024-09-07 22:08:58,144:INFO:Initializing Random Forest Classifier
2024-09-07 22:08:58,144:INFO:Total runtime is 4.0851054906845095 minutes
2024-09-07 22:08:58,144:INFO:SubProcess create_model() called ==================================
2024-09-07 22:08:58,144:INFO:Initializing create_model()
2024-09-07 22:08:58,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0511ADDB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:08:58,145:INFO:Checking exceptions
2024-09-07 22:08:58,145:INFO:Importing libraries
2024-09-07 22:08:58,145:INFO:Copying training dataset
2024-09-07 22:08:58,759:INFO:Defining folds
2024-09-07 22:08:58,760:INFO:Declaring metric variables
2024-09-07 22:08:58,760:INFO:Importing untrained model
2024-09-07 22:08:58,760:INFO:Random Forest Classifier Imported successfully
2024-09-07 22:08:58,761:INFO:Starting cross validation
2024-09-07 22:08:58,764:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 22:10:42,835:INFO:Calculating mean and std
2024-09-07 22:10:42,836:INFO:Creating metrics dataframe
2024-09-07 22:10:42,838:INFO:Uploading results into container
2024-09-07 22:10:42,838:INFO:Uploading model into container now
2024-09-07 22:10:42,839:INFO:_master_model_container: 3
2024-09-07 22:10:42,839:INFO:_display_container: 2
2024-09-07 22:10:42,839:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-07 22:10:42,839:INFO:create_model() successfully completed......................................
2024-09-07 22:10:42,924:INFO:SubProcess create_model() end ==================================
2024-09-07 22:10:42,925:INFO:Creating metrics dataframe
2024-09-07 22:10:42,928:INFO:Initializing Logistic Regression
2024-09-07 22:10:42,929:INFO:Total runtime is 5.831505080064138 minutes
2024-09-07 22:10:42,929:INFO:SubProcess create_model() called ==================================
2024-09-07 22:10:42,929:INFO:Initializing create_model()
2024-09-07 22:10:42,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0511ADDB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:10:42,929:INFO:Checking exceptions
2024-09-07 22:10:42,929:INFO:Importing libraries
2024-09-07 22:10:42,929:INFO:Copying training dataset
2024-09-07 22:10:43,611:INFO:Defining folds
2024-09-07 22:10:43,611:INFO:Declaring metric variables
2024-09-07 22:10:43,612:INFO:Importing untrained model
2024-09-07 22:10:43,612:INFO:Logistic Regression Imported successfully
2024-09-07 22:10:43,612:INFO:Starting cross validation
2024-09-07 22:10:43,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 22:13:47,270:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:48,527:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:49,055:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:50,859:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:51,837:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:55,361:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:55,761:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:57,339:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:57,426:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:57,729:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-07 22:13:57,757:INFO:Calculating mean and std
2024-09-07 22:13:57,758:INFO:Creating metrics dataframe
2024-09-07 22:13:57,760:INFO:Uploading results into container
2024-09-07 22:13:57,760:INFO:Uploading model into container now
2024-09-07 22:13:57,761:INFO:_master_model_container: 4
2024-09-07 22:13:57,761:INFO:_display_container: 2
2024-09-07 22:13:57,761:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-07 22:13:57,761:INFO:create_model() successfully completed......................................
2024-09-07 22:13:57,834:INFO:SubProcess create_model() end ==================================
2024-09-07 22:13:57,834:INFO:Creating metrics dataframe
2024-09-07 22:13:57,839:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-09-07 22:13:57,842:INFO:Initializing create_model()
2024-09-07 22:13:57,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:13:57,842:INFO:Checking exceptions
2024-09-07 22:13:57,844:INFO:Importing libraries
2024-09-07 22:13:57,844:INFO:Copying training dataset
2024-09-07 22:13:58,472:INFO:Defining folds
2024-09-07 22:13:58,472:INFO:Declaring metric variables
2024-09-07 22:13:58,472:INFO:Importing untrained model
2024-09-07 22:13:58,472:INFO:Declaring custom model
2024-09-07 22:13:58,473:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 22:13:58,476:INFO:Cross validation set to False
2024-09-07 22:13:58,476:INFO:Fitting Model
2024-09-07 22:14:03,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136122 seconds.
2024-09-07 22:14:03,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-07 22:14:03,264:INFO:[LightGBM] [Info] Total Bins 102580
2024-09-07 22:14:03,268:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 426
2024-09-07 22:14:03,271:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 22:14:03,272:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 22:14:03,272:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-07 22:14:12,368:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 22:14:12,368:INFO:create_model() successfully completed......................................
2024-09-07 22:14:12,461:INFO:Initializing create_model()
2024-09-07 22:14:12,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:14:12,461:INFO:Checking exceptions
2024-09-07 22:14:12,462:INFO:Importing libraries
2024-09-07 22:14:12,462:INFO:Copying training dataset
2024-09-07 22:14:13,105:INFO:Defining folds
2024-09-07 22:14:13,105:INFO:Declaring metric variables
2024-09-07 22:14:13,106:INFO:Importing untrained model
2024-09-07 22:14:13,106:INFO:Declaring custom model
2024-09-07 22:14:13,108:INFO:Extreme Gradient Boosting Imported successfully
2024-09-07 22:14:13,110:INFO:Cross validation set to False
2024-09-07 22:14:13,110:INFO:Fitting Model
2024-09-07 22:14:28,234:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-09-07 22:14:28,236:INFO:create_model() successfully completed......................................
2024-09-07 22:14:28,349:INFO:Initializing create_model()
2024-09-07 22:14:28,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:14:28,349:INFO:Checking exceptions
2024-09-07 22:14:28,350:INFO:Importing libraries
2024-09-07 22:14:28,350:INFO:Copying training dataset
2024-09-07 22:14:29,006:INFO:Defining folds
2024-09-07 22:14:29,006:INFO:Declaring metric variables
2024-09-07 22:14:29,007:INFO:Importing untrained model
2024-09-07 22:14:29,007:INFO:Declaring custom model
2024-09-07 22:14:29,007:INFO:Random Forest Classifier Imported successfully
2024-09-07 22:14:29,012:INFO:Cross validation set to False
2024-09-07 22:14:29,012:INFO:Fitting Model
2024-09-07 22:14:42,764:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-07 22:14:42,765:INFO:create_model() successfully completed......................................
2024-09-07 22:14:42,835:INFO:_master_model_container: 4
2024-09-07 22:14:42,835:INFO:_display_container: 2
2024-09-07 22:14:42,838:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)]
2024-09-07 22:14:42,838:INFO:compare_models() successfully completed......................................
2024-09-07 22:14:42,937:INFO:Initializing tune_model()
2024-09-07 22:14:42,937:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [10, 20, 30], 'min_samples_split': [5, 10, 20], 'min_samples_leaf': [2, 4, 6], 'bootstrap': [True]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>)
2024-09-07 22:14:42,937:INFO:Checking exceptions
2024-09-07 22:14:42,937:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-07 22:14:43,168:INFO:Copying training dataset
2024-09-07 22:14:43,633:INFO:Checking base model
2024-09-07 22:14:43,633:INFO:Base model : Random Forest Classifier
2024-09-07 22:14:43,634:INFO:Declaring metric variables
2024-09-07 22:14:43,634:INFO:Defining Hyperparameters
2024-09-07 22:14:43,717:INFO:custom_grid: {'actual_estimator__max_depth': CategoricalDistribution(values=[10, 20, 30]), 'actual_estimator__min_samples_split': CategoricalDistribution(values=[5, 10, 20]), 'actual_estimator__min_samples_leaf': CategoricalDistribution(values=[2, 4, 6]), 'actual_estimator__bootstrap': CategoricalDistribution(values=[True])}
2024-09-07 22:14:43,717:INFO:Tuning with n_jobs=-1
2024-09-07 22:14:43,720:INFO:Initializing skopt.BayesSearchCV
2024-09-07 22:21:02,765:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', True), ('actual_estimator__max_depth', 30), ('actual_estimator__min_samples_leaf', 4), ('actual_estimator__min_samples_split', 20)])
2024-09-07 22:21:02,766:INFO:Hyperparameter search completed
2024-09-07 22:21:02,766:INFO:SubProcess create_model() called ==================================
2024-09-07 22:21:02,766:INFO:Initializing create_model()
2024-09-07 22:21:02,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0511AF0A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': True, 'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 20})
2024-09-07 22:21:02,766:INFO:Checking exceptions
2024-09-07 22:21:02,767:INFO:Importing libraries
2024-09-07 22:21:02,767:INFO:Copying training dataset
2024-09-07 22:21:03,512:INFO:Defining folds
2024-09-07 22:21:03,512:INFO:Declaring metric variables
2024-09-07 22:21:03,512:INFO:Importing untrained model
2024-09-07 22:21:03,512:INFO:Declaring custom model
2024-09-07 22:21:03,514:INFO:Random Forest Classifier Imported successfully
2024-09-07 22:21:03,514:INFO:Starting cross validation
2024-09-07 22:21:03,517:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 22:21:43,162:INFO:Calculating mean and std
2024-09-07 22:21:43,163:INFO:Creating metrics dataframe
2024-09-07 22:21:43,164:INFO:Finalizing model
2024-09-07 22:21:54,462:INFO:Uploading results into container
2024-09-07 22:21:54,462:INFO:Uploading model into container now
2024-09-07 22:21:54,463:INFO:_master_model_container: 5
2024-09-07 22:21:54,463:INFO:_display_container: 3
2024-09-07 22:21:54,463:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=30, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=4,
                       min_samples_split=20, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-07 22:21:54,463:INFO:create_model() successfully completed......................................
2024-09-07 22:21:54,541:INFO:SubProcess create_model() end ==================================
2024-09-07 22:21:54,542:INFO:choose_better activated
2024-09-07 22:21:54,542:INFO:SubProcess create_model() called ==================================
2024-09-07 22:21:54,543:INFO:Initializing create_model()
2024-09-07 22:21:54,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:21:54,543:INFO:Checking exceptions
2024-09-07 22:21:54,543:INFO:Importing libraries
2024-09-07 22:21:54,543:INFO:Copying training dataset
2024-09-07 22:21:55,194:INFO:Defining folds
2024-09-07 22:21:55,194:INFO:Declaring metric variables
2024-09-07 22:21:55,195:INFO:Importing untrained model
2024-09-07 22:21:55,195:INFO:Declaring custom model
2024-09-07 22:21:55,195:INFO:Random Forest Classifier Imported successfully
2024-09-07 22:21:55,196:INFO:Starting cross validation
2024-09-07 22:21:55,199:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 22:22:40,491:INFO:Calculating mean and std
2024-09-07 22:22:40,492:INFO:Creating metrics dataframe
2024-09-07 22:22:40,495:INFO:Finalizing model
2024-09-07 22:22:53,227:INFO:Uploading results into container
2024-09-07 22:22:53,228:INFO:Uploading model into container now
2024-09-07 22:22:53,229:INFO:_master_model_container: 6
2024-09-07 22:22:53,229:INFO:_display_container: 4
2024-09-07 22:22:53,230:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-07 22:22:53,230:INFO:create_model() successfully completed......................................
2024-09-07 22:22:53,301:INFO:SubProcess create_model() end ==================================
2024-09-07 22:22:53,302:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.8198
2024-09-07 22:22:53,303:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=30, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=4,
                       min_samples_split=20, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.8213
2024-09-07 22:22:53,303:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=30, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=4,
                       min_samples_split=20, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2024-09-07 22:22:53,303:INFO:choose_better completed
2024-09-07 22:22:53,312:INFO:_master_model_container: 6
2024-09-07 22:22:53,312:INFO:_display_container: 3
2024-09-07 22:22:53,312:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=30, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=4,
                       min_samples_split=20, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-07 22:22:53,313:INFO:tune_model() successfully completed......................................
2024-09-07 22:22:53,424:INFO:Initializing predict_model()
2024-09-07 22:22:53,424:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=30, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=4,
                       min_samples_split=20, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E05106F1C0>)
2024-09-07 22:22:53,424:INFO:Checking exceptions
2024-09-07 22:22:53,424:INFO:Preloading libraries
2024-09-07 22:22:53,424:INFO:Set up data.
2024-09-07 22:22:53,826:INFO:Set up index.
2024-09-07 22:22:54,401:INFO:Initializing get_config()
2024-09-07 22:22:54,401:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, variable=X_train)
2024-09-07 22:22:54,401:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-07 22:22:54,402:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2024-09-07 22:22:54,832:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  feature_7  ...  feature_419  feature_420  feature_421  feature_422  feature_423  feature_424  feature_425  feature_426
71710  -0.903637   2.736559   0.372071   0.304834  -0.307305  -0.216109   1.112682   0.908807  ...    -0.082721     0.049159    -0.814324    -1.269576    -0.978704    -0.657480     0.665040     0.918771
41786   1.373649  -0.522903   0.083904   0.304834   1.787297   0.066573  -1.226048  -1.505896  ...    -0.082721     0.049159     1.938017    -0.543544    -0.447987    -0.785362     0.023022    -0.833264
53345  -0.903637  -0.522903   0.083904   0.304834  -0.307305  -1.127987   1.112682   0.908807  ...    -0.082721     0.049159    -0.814324    -1.269576    -0.978704    -0.657480     0.665040     0.918771
11745   0.055220  -0.522903   0.049743   0.304834  -0.307305  -0.854424  -0.056683   0.975882  ...    13.379660     1.386740    -1.298134     0.330275     0.189874     0.765493     0.279644    -0.979924
23494  -0.903637  -0.522903   0.134044   0.304834  -0.307305   3.249027  -0.056683   1.042958  ...    -0.082721     0.049159     1.938017    -0.543544    -0.447987    -0.785362     0.023022    -0.833264
...          ...        ...        ...        ...        ...        ...        ...        ...  ...          ...          ...          ...          ...          ...          ...          ...          ...
45374  -0.903637  -0.522903   0.278403   0.304834  -0.307305   1.516459   1.112682   0.908807  ...    -0.082721     0.049159     0.338756     1.927194    -0.693992     2.376801    -1.369871    -0.430422
38857   1.373649  -0.522903  -0.540365  -3.280477   1.787297  -2.039865  -0.056683   0.707582  ...    -0.082721     0.049159    -1.298134     0.330275     0.189874     0.765493     0.279644    -0.979924
31149  -0.903637   0.291962   0.428822   0.304834  -0.307305  -0.033734  -0.056683   0.975882  ...    -0.082721     0.049159     1.587176     1.716656    -2.215057     1.016606    -2.545979     2.249198
55353  -0.903637  -0.522903   0.134044   0.304834  -0.307305  -0.216109  -0.056683   0.975882  ...    -0.082721     0.049159     0.219701    -0.464959     0.917071    -0.748160     0.294235    -0.368505
1638    0.055220  -0.522903   0.428822   0.304834  -0.307305  -0.854424  -0.056683   0.908807  ...    -0.082721     0.049159    -0.814324    -1.269576    -0.978704    -0.657480     0.665040     0.918771

[53562 rows x 427 columns]
2024-09-07 22:22:54,832:INFO:get_config() successfully completed......................................
2024-09-07 22:22:54,832:INFO:Initializing predict_model()
2024-09-07 22:22:54,833:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=30, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=4,
                       min_samples_split=20, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0511D2DD0>)
2024-09-07 22:22:54,833:INFO:Checking exceptions
2024-09-07 22:22:54,833:INFO:Preloading libraries
2024-09-07 22:22:54,833:INFO:Set up data.
2024-09-07 22:22:55,059:INFO:Set up index.
2024-09-07 22:22:55,969:INFO:Initializing get_config()
2024-09-07 22:22:55,969:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, variable=y_train)
2024-09-07 22:22:55,969:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-07 22:22:55,969:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2024-09-07 22:22:56,177:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-07 22:22:56,177:INFO:get_config() successfully completed......................................
2024-09-07 22:22:56,177:INFO:Initializing get_config()
2024-09-07 22:22:56,177:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, variable=y_test)
2024-09-07 22:22:56,177:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-07 22:22:56,177:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2024-09-07 22:22:56,301:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-07 22:22:56,301:INFO:get_config() successfully completed......................................
2024-09-07 22:22:56,305:INFO:Initializing finalize_model()
2024-09-07 22:22:56,305:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=30, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=4,
                       min_samples_split=20, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-07 22:22:56,306:INFO:Finalizing RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=30, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=4,
                       min_samples_split=20, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-07 22:22:56,767:INFO:Initializing create_model()
2024-09-07 22:22:56,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=30, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=4,
                       min_samples_split=20, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:22:56,768:INFO:Checking exceptions
2024-09-07 22:22:56,768:INFO:Importing libraries
2024-09-07 22:22:56,768:INFO:Copying training dataset
2024-09-07 22:22:56,842:INFO:Defining folds
2024-09-07 22:22:56,842:INFO:Declaring metric variables
2024-09-07 22:22:56,842:INFO:Importing untrained model
2024-09-07 22:22:56,843:INFO:Declaring custom model
2024-09-07 22:22:56,843:INFO:Random Forest Classifier Imported successfully
2024-09-07 22:22:56,846:INFO:Cross validation set to False
2024-09-07 22:22:56,846:INFO:Fitting Model
2024-09-07 22:23:14,672:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=30, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=4,
                                        min_samples_split=20,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-09-07 22:23:14,673:INFO:create_model() successfully completed......................................
2024-09-07 22:23:14,750:INFO:_master_model_container: 6
2024-09-07 22:23:14,750:INFO:_display_container: 4
2024-09-07 22:23:14,761:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=30, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=4,
                                        min_samples_split=20,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-09-07 22:23:14,761:INFO:finalize_model() successfully completed......................................
2024-09-07 22:23:14,853:INFO:Initializing predict_model()
2024-09-07 22:23:14,853:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0511AFFD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=30, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=4,
                                        min_samples_split=20,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0511D2E60>)
2024-09-07 22:23:14,853:INFO:Checking exceptions
2024-09-07 22:23:14,853:INFO:Preloading libraries
2024-09-07 22:23:14,854:INFO:Set up data.
2024-09-07 22:23:15,675:INFO:Set up index.
2024-09-07 22:23:16,728:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 22:23:18,209:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

2024-09-07 22:23:19,286:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 22:23:19,563:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\joblib\memory.py:999: DeprecationWarning: bytes_limit argument has been deprecated. It will be removed in version 1.5. Please pass its value directly to Memory.reduce_size.
  warnings.warn(

2024-09-07 22:23:19,602:INFO:PyCaret ClassificationExperiment
2024-09-07 22:23:19,602:INFO:Logging name: clf-default-name
2024-09-07 22:23:19,602:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 22:23:19,602:INFO:version 3.3.2
2024-09-07 22:23:19,602:INFO:Initializing setup()
2024-09-07 22:23:19,602:INFO:self.USI: 55f2
2024-09-07 22:23:19,602:INFO:self._variable_keys: {'fix_imbalance', 'idx', 'is_multiclass', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'exp_id', 'exp_name_log', 'target_param', 'y_train', 'X', 'fold_groups_param', 'n_jobs_param', 'data', '_ml_usecase', 'seed', 'USI', 'html_param', 'pipeline', 'X_train', 'X_test', '_available_plots', 'fold_generator', 'logging_param', 'fold_shuffle_param', 'memory', 'gpu_param', 'y'}
2024-09-07 22:23:19,602:INFO:Checking environment
2024-09-07 22:23:19,602:INFO:python_version: 3.10.11
2024-09-07 22:23:19,602:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 22:23:19,602:INFO:machine: AMD64
2024-09-07 22:23:19,603:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 22:23:19,603:INFO:Memory: svmem(total=17128263680, available=7141101568, percent=58.3, used=9987162112, free=7141101568)
2024-09-07 22:23:19,603:INFO:Physical Core: 6
2024-09-07 22:23:19,603:INFO:Logical Core: 12
2024-09-07 22:23:19,603:INFO:Checking libraries
2024-09-07 22:23:19,603:INFO:System:
2024-09-07 22:23:19,603:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 22:23:19,603:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 22:23:19,603:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 22:23:19,603:INFO:PyCaret required dependencies:
2024-09-07 22:23:19,603:INFO:                 pip: 24.2
2024-09-07 22:23:19,603:INFO:          setuptools: 72.1.0
2024-09-07 22:23:19,603:INFO:             pycaret: 3.3.2
2024-09-07 22:23:19,603:INFO:             IPython: 8.27.0
2024-09-07 22:23:19,603:INFO:          ipywidgets: 8.1.5
2024-09-07 22:23:19,603:INFO:                tqdm: 4.66.5
2024-09-07 22:23:19,603:INFO:               numpy: 1.26.4
2024-09-07 22:23:19,603:INFO:              pandas: 2.2.2
2024-09-07 22:23:19,603:INFO:              jinja2: 3.1.4
2024-09-07 22:23:19,603:INFO:               scipy: 1.11.4
2024-09-07 22:23:19,603:INFO:              joblib: 1.3.2
2024-09-07 22:23:19,604:INFO:             sklearn: 1.4.2
2024-09-07 22:23:19,604:INFO:                pyod: 2.0.1
2024-09-07 22:23:19,604:INFO:            imblearn: 0.12.3
2024-09-07 22:23:19,604:INFO:   category_encoders: 2.6.3
2024-09-07 22:23:19,604:INFO:            lightgbm: 4.5.0
2024-09-07 22:23:19,604:INFO:               numba: 0.60.0
2024-09-07 22:23:19,604:INFO:            requests: 2.32.3
2024-09-07 22:23:19,604:INFO:          matplotlib: 3.7.5
2024-09-07 22:23:19,604:INFO:          scikitplot: 0.3.7
2024-09-07 22:23:19,604:INFO:         yellowbrick: 1.5
2024-09-07 22:23:19,604:INFO:              plotly: 5.24.0
2024-09-07 22:23:19,604:INFO:    plotly-resampler: Not installed
2024-09-07 22:23:19,604:INFO:             kaleido: 0.2.1
2024-09-07 22:23:19,604:INFO:           schemdraw: 0.15
2024-09-07 22:23:19,604:INFO:         statsmodels: 0.14.2
2024-09-07 22:23:19,604:INFO:              sktime: 0.26.0
2024-09-07 22:23:19,604:INFO:               tbats: 1.1.3
2024-09-07 22:23:19,604:INFO:            pmdarima: 2.0.4
2024-09-07 22:23:19,604:INFO:              psutil: 6.0.0
2024-09-07 22:23:19,604:INFO:          markupsafe: 2.1.5
2024-09-07 22:23:19,604:INFO:             pickle5: Not installed
2024-09-07 22:23:19,604:INFO:         cloudpickle: 3.0.0
2024-09-07 22:23:19,604:INFO:         deprecation: 2.1.0
2024-09-07 22:23:19,605:INFO:              xxhash: 3.5.0
2024-09-07 22:23:19,605:INFO:           wurlitzer: Not installed
2024-09-07 22:23:19,605:INFO:PyCaret optional dependencies:
2024-09-07 22:23:19,605:INFO:                shap: Not installed
2024-09-07 22:23:19,605:INFO:           interpret: Not installed
2024-09-07 22:23:19,605:INFO:                umap: Not installed
2024-09-07 22:23:19,605:INFO:     ydata_profiling: Not installed
2024-09-07 22:23:19,605:INFO:  explainerdashboard: Not installed
2024-09-07 22:23:19,605:INFO:             autoviz: Not installed
2024-09-07 22:23:19,605:INFO:           fairlearn: Not installed
2024-09-07 22:23:19,605:INFO:          deepchecks: Not installed
2024-09-07 22:23:19,605:INFO:             xgboost: 2.1.1
2024-09-07 22:23:19,605:INFO:            catboost: Not installed
2024-09-07 22:23:19,605:INFO:              kmodes: Not installed
2024-09-07 22:23:19,605:INFO:             mlxtend: Not installed
2024-09-07 22:23:19,605:INFO:       statsforecast: Not installed
2024-09-07 22:23:19,605:INFO:        tune_sklearn: Not installed
2024-09-07 22:23:19,605:INFO:                 ray: Not installed
2024-09-07 22:23:19,605:INFO:            hyperopt: 0.2.7
2024-09-07 22:23:19,605:INFO:              optuna: 4.0.0
2024-09-07 22:23:19,606:INFO:               skopt: 0.10.2
2024-09-07 22:23:19,606:INFO:              mlflow: Not installed
2024-09-07 22:23:19,606:INFO:              gradio: Not installed
2024-09-07 22:23:19,606:INFO:             fastapi: Not installed
2024-09-07 22:23:19,606:INFO:             uvicorn: Not installed
2024-09-07 22:23:19,606:INFO:              m2cgen: Not installed
2024-09-07 22:23:19,606:INFO:           evidently: Not installed
2024-09-07 22:23:19,606:INFO:               fugue: Not installed
2024-09-07 22:23:19,606:INFO:           streamlit: Not installed
2024-09-07 22:23:19,606:INFO:             prophet: Not installed
2024-09-07 22:23:19,606:INFO:None
2024-09-07 22:23:19,606:INFO:Set up data.
2024-09-07 22:23:19,655:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 22:23:20,669:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

2024-09-07 22:23:22,022:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 22:23:22,164:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Displaced is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:23:22,166:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Educational special needs is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:23:22,168:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Debtor is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:23:22,170:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:23:22,172:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Scholarship holder is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:23:22,174:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable International is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-09-07 22:24:21,117:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\joblib\memory.py:999: DeprecationWarning: bytes_limit argument has been deprecated. It will be removed in version 1.5. Please pass its value directly to Memory.reduce_size.
  warnings.warn(

2024-09-07 22:24:21,156:INFO:PyCaret ClassificationExperiment
2024-09-07 22:24:21,156:INFO:Logging name: clf-default-name
2024-09-07 22:24:21,156:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 22:24:21,156:INFO:version 3.3.2
2024-09-07 22:24:21,156:INFO:Initializing setup()
2024-09-07 22:24:21,156:INFO:self.USI: e587
2024-09-07 22:24:21,156:INFO:self._variable_keys: {'fix_imbalance', 'idx', 'is_multiclass', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'exp_id', 'exp_name_log', 'target_param', 'y_train', 'X', 'fold_groups_param', 'n_jobs_param', 'data', '_ml_usecase', 'seed', 'USI', 'html_param', 'pipeline', 'X_train', 'X_test', '_available_plots', 'fold_generator', 'logging_param', 'fold_shuffle_param', 'memory', 'gpu_param', 'y'}
2024-09-07 22:24:21,156:INFO:Checking environment
2024-09-07 22:24:21,156:INFO:python_version: 3.10.11
2024-09-07 22:24:21,156:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 22:24:21,156:INFO:machine: AMD64
2024-09-07 22:24:21,156:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 22:24:21,156:INFO:Memory: svmem(total=17128263680, available=6121644032, percent=64.3, used=11006619648, free=6121644032)
2024-09-07 22:24:21,156:INFO:Physical Core: 6
2024-09-07 22:24:21,156:INFO:Logical Core: 12
2024-09-07 22:24:21,156:INFO:Checking libraries
2024-09-07 22:24:21,156:INFO:System:
2024-09-07 22:24:21,156:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 22:24:21,156:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 22:24:21,156:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 22:24:21,156:INFO:PyCaret required dependencies:
2024-09-07 22:24:21,156:INFO:                 pip: 24.2
2024-09-07 22:24:21,156:INFO:          setuptools: 72.1.0
2024-09-07 22:24:21,157:INFO:             pycaret: 3.3.2
2024-09-07 22:24:21,157:INFO:             IPython: 8.27.0
2024-09-07 22:24:21,157:INFO:          ipywidgets: 8.1.5
2024-09-07 22:24:21,157:INFO:                tqdm: 4.66.5
2024-09-07 22:24:21,157:INFO:               numpy: 1.26.4
2024-09-07 22:24:21,157:INFO:              pandas: 2.2.2
2024-09-07 22:24:21,157:INFO:              jinja2: 3.1.4
2024-09-07 22:24:21,157:INFO:               scipy: 1.11.4
2024-09-07 22:24:21,157:INFO:              joblib: 1.3.2
2024-09-07 22:24:21,157:INFO:             sklearn: 1.4.2
2024-09-07 22:24:21,157:INFO:                pyod: 2.0.1
2024-09-07 22:24:21,157:INFO:            imblearn: 0.12.3
2024-09-07 22:24:21,157:INFO:   category_encoders: 2.6.3
2024-09-07 22:24:21,157:INFO:            lightgbm: 4.5.0
2024-09-07 22:24:21,157:INFO:               numba: 0.60.0
2024-09-07 22:24:21,157:INFO:            requests: 2.32.3
2024-09-07 22:24:21,157:INFO:          matplotlib: 3.7.5
2024-09-07 22:24:21,157:INFO:          scikitplot: 0.3.7
2024-09-07 22:24:21,157:INFO:         yellowbrick: 1.5
2024-09-07 22:24:21,157:INFO:              plotly: 5.24.0
2024-09-07 22:24:21,157:INFO:    plotly-resampler: Not installed
2024-09-07 22:24:21,157:INFO:             kaleido: 0.2.1
2024-09-07 22:24:21,157:INFO:           schemdraw: 0.15
2024-09-07 22:24:21,157:INFO:         statsmodels: 0.14.2
2024-09-07 22:24:21,157:INFO:              sktime: 0.26.0
2024-09-07 22:24:21,157:INFO:               tbats: 1.1.3
2024-09-07 22:24:21,157:INFO:            pmdarima: 2.0.4
2024-09-07 22:24:21,157:INFO:              psutil: 6.0.0
2024-09-07 22:24:21,157:INFO:          markupsafe: 2.1.5
2024-09-07 22:24:21,157:INFO:             pickle5: Not installed
2024-09-07 22:24:21,157:INFO:         cloudpickle: 3.0.0
2024-09-07 22:24:21,157:INFO:         deprecation: 2.1.0
2024-09-07 22:24:21,159:INFO:              xxhash: 3.5.0
2024-09-07 22:24:21,159:INFO:           wurlitzer: Not installed
2024-09-07 22:24:21,159:INFO:PyCaret optional dependencies:
2024-09-07 22:24:21,159:INFO:                shap: Not installed
2024-09-07 22:24:21,159:INFO:           interpret: Not installed
2024-09-07 22:24:21,159:INFO:                umap: Not installed
2024-09-07 22:24:21,159:INFO:     ydata_profiling: Not installed
2024-09-07 22:24:21,159:INFO:  explainerdashboard: Not installed
2024-09-07 22:24:21,159:INFO:             autoviz: Not installed
2024-09-07 22:24:21,159:INFO:           fairlearn: Not installed
2024-09-07 22:24:21,159:INFO:          deepchecks: Not installed
2024-09-07 22:24:21,159:INFO:             xgboost: 2.1.1
2024-09-07 22:24:21,159:INFO:            catboost: Not installed
2024-09-07 22:24:21,159:INFO:              kmodes: Not installed
2024-09-07 22:24:21,159:INFO:             mlxtend: Not installed
2024-09-07 22:24:21,159:INFO:       statsforecast: Not installed
2024-09-07 22:24:21,159:INFO:        tune_sklearn: Not installed
2024-09-07 22:24:21,159:INFO:                 ray: Not installed
2024-09-07 22:24:21,159:INFO:            hyperopt: 0.2.7
2024-09-07 22:24:21,159:INFO:              optuna: 4.0.0
2024-09-07 22:24:21,159:INFO:               skopt: 0.10.2
2024-09-07 22:24:21,159:INFO:              mlflow: Not installed
2024-09-07 22:24:21,160:INFO:              gradio: Not installed
2024-09-07 22:24:21,160:INFO:             fastapi: Not installed
2024-09-07 22:24:21,160:INFO:             uvicorn: Not installed
2024-09-07 22:24:21,160:INFO:              m2cgen: Not installed
2024-09-07 22:24:21,160:INFO:           evidently: Not installed
2024-09-07 22:24:21,160:INFO:               fugue: Not installed
2024-09-07 22:24:21,160:INFO:           streamlit: Not installed
2024-09-07 22:24:21,160:INFO:             prophet: Not installed
2024-09-07 22:24:21,160:INFO:None
2024-09-07 22:24:21,160:INFO:Set up data.
2024-09-07 22:24:21,656:INFO:Set up folding strategy.
2024-09-07 22:24:21,656:INFO:Set up train/test split.
2024-09-07 22:24:22,176:INFO:Set up index.
2024-09-07 22:24:22,184:INFO:Assigning column types.
2024-09-07 22:24:22,684:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-07 22:24:22,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 22:24:22,734:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 22:24:22,765:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:24:22,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:24:22,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 22:24:22,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 22:24:22,849:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:24:22,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:24:22,852:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-07 22:24:22,901:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 22:24:22,932:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:24:22,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:24:22,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 22:24:23,016:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:24:23,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:24:23,019:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-07 22:24:23,102:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:24:23,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:24:23,186:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:24:23,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:24:23,191:INFO:Preparing preprocessing pipeline...
2024-09-07 22:24:23,266:INFO:Set up simple imputation.
2024-09-07 22:24:23,266:INFO:Set up imbalanced handling.
2024-09-07 22:24:23,974:INFO:Finished creating preprocessing pipeline.
2024-09-07 22:24:23,984:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-07 22:24:23,984:INFO:Creating final display dataframe.
2024-09-07 22:24:26,309:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 428)
4        Transformed data shape      (99147, 428)
5   Transformed train set shape      (76191, 428)
6    Transformed test set shape      (22956, 428)
7              Numeric features               427
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              e587
2024-09-07 22:24:26,404:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:24:26,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:24:26,494:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 22:24:26,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 22:24:26,499:INFO:setup() successfully completed in 5.38s...............
2024-09-07 22:24:26,499:INFO:Initializing compare_models()
2024-09-07 22:24:26,499:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0439C6EF0>, include=['lightgbm', 'xgboost', 'rf', 'lr'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E0439C6EF0>, 'include': ['lightgbm', 'xgboost', 'rf', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-07 22:24:26,499:INFO:Checking exceptions
2024-09-07 22:24:26,862:INFO:Preparing display monitor
2024-09-07 22:24:26,864:INFO:Initializing Light Gradient Boosting Machine
2024-09-07 22:24:26,864:INFO:Total runtime is 0.0 minutes
2024-09-07 22:24:26,864:INFO:SubProcess create_model() called ==================================
2024-09-07 22:24:26,864:INFO:Initializing create_model()
2024-09-07 22:24:26,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E0439C6EF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0469A2050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 22:24:26,864:INFO:Checking exceptions
2024-09-07 22:24:26,865:INFO:Importing libraries
2024-09-07 22:24:26,865:INFO:Copying training dataset
2024-09-07 22:24:27,453:INFO:Defining folds
2024-09-07 22:24:27,453:INFO:Declaring metric variables
2024-09-07 22:24:27,454:INFO:Importing untrained model
2024-09-07 22:24:27,454:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 22:24:27,454:INFO:Starting cross validation
2024-09-07 22:24:27,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 23:21:08,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:21:08,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:21:08,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:21:08,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:22:07,054:INFO:PyCaret ClassificationExperiment
2024-09-07 23:22:07,054:INFO:Logging name: clf-default-name
2024-09-07 23:22:07,054:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 23:22:07,054:INFO:version 3.3.2
2024-09-07 23:22:07,054:INFO:Initializing setup()
2024-09-07 23:22:07,054:INFO:self.USI: cf92
2024-09-07 23:22:07,054:INFO:self._variable_keys: {'y_test', '_available_plots', '_ml_usecase', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'X', 'memory', 'USI', 'gpu_n_jobs_param', 'X_test', 'y', 'idx', 'is_multiclass', 'fold_groups_param', 'logging_param', 'exp_id', 'fold_generator', 'exp_name_log', 'y_train', 'target_param', 'n_jobs_param', 'gpu_param', 'X_train', 'fix_imbalance', 'data', 'pipeline', 'seed'}
2024-09-07 23:22:07,054:INFO:Checking environment
2024-09-07 23:22:07,054:INFO:python_version: 3.10.11
2024-09-07 23:22:07,054:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 23:22:07,054:INFO:machine: AMD64
2024-09-07 23:22:07,061:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 23:22:07,061:INFO:Memory: svmem(total=17128263680, available=9371541504, percent=45.3, used=7756722176, free=9371541504)
2024-09-07 23:22:07,061:INFO:Physical Core: 6
2024-09-07 23:22:07,061:INFO:Logical Core: 12
2024-09-07 23:22:07,061:INFO:Checking libraries
2024-09-07 23:22:07,061:INFO:System:
2024-09-07 23:22:07,061:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 23:22:07,061:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 23:22:07,061:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 23:22:07,061:INFO:PyCaret required dependencies:
2024-09-07 23:22:07,087:INFO:                 pip: 24.2
2024-09-07 23:22:07,088:INFO:          setuptools: 72.1.0
2024-09-07 23:22:07,088:INFO:             pycaret: 3.3.2
2024-09-07 23:22:07,088:INFO:             IPython: 8.27.0
2024-09-07 23:22:07,088:INFO:          ipywidgets: 8.1.5
2024-09-07 23:22:07,088:INFO:                tqdm: 4.66.5
2024-09-07 23:22:07,088:INFO:               numpy: 1.26.4
2024-09-07 23:22:07,088:INFO:              pandas: 2.2.2
2024-09-07 23:22:07,088:INFO:              jinja2: 3.1.4
2024-09-07 23:22:07,088:INFO:               scipy: 1.11.4
2024-09-07 23:22:07,088:INFO:              joblib: 1.3.2
2024-09-07 23:22:07,088:INFO:             sklearn: 1.4.2
2024-09-07 23:22:07,088:INFO:                pyod: 2.0.1
2024-09-07 23:22:07,088:INFO:            imblearn: 0.12.3
2024-09-07 23:22:07,088:INFO:   category_encoders: 2.6.3
2024-09-07 23:22:07,088:INFO:            lightgbm: 4.5.0
2024-09-07 23:22:07,088:INFO:               numba: 0.60.0
2024-09-07 23:22:07,088:INFO:            requests: 2.32.3
2024-09-07 23:22:07,088:INFO:          matplotlib: 3.7.5
2024-09-07 23:22:07,088:INFO:          scikitplot: 0.3.7
2024-09-07 23:22:07,088:INFO:         yellowbrick: 1.5
2024-09-07 23:22:07,088:INFO:              plotly: 5.24.0
2024-09-07 23:22:07,088:INFO:    plotly-resampler: Not installed
2024-09-07 23:22:07,088:INFO:             kaleido: 0.2.1
2024-09-07 23:22:07,088:INFO:           schemdraw: 0.15
2024-09-07 23:22:07,088:INFO:         statsmodels: 0.14.2
2024-09-07 23:22:07,088:INFO:              sktime: 0.26.0
2024-09-07 23:22:07,088:INFO:               tbats: 1.1.3
2024-09-07 23:22:07,088:INFO:            pmdarima: 2.0.4
2024-09-07 23:22:07,088:INFO:              psutil: 6.0.0
2024-09-07 23:22:07,088:INFO:          markupsafe: 2.1.5
2024-09-07 23:22:07,088:INFO:             pickle5: Not installed
2024-09-07 23:22:07,088:INFO:         cloudpickle: 3.0.0
2024-09-07 23:22:07,089:INFO:         deprecation: 2.1.0
2024-09-07 23:22:07,089:INFO:              xxhash: 3.5.0
2024-09-07 23:22:07,089:INFO:           wurlitzer: Not installed
2024-09-07 23:22:07,089:INFO:PyCaret optional dependencies:
2024-09-07 23:22:07,102:INFO:                shap: Not installed
2024-09-07 23:22:07,102:INFO:           interpret: Not installed
2024-09-07 23:22:07,102:INFO:                umap: Not installed
2024-09-07 23:22:07,102:INFO:     ydata_profiling: Not installed
2024-09-07 23:22:07,102:INFO:  explainerdashboard: Not installed
2024-09-07 23:22:07,102:INFO:             autoviz: Not installed
2024-09-07 23:22:07,102:INFO:           fairlearn: Not installed
2024-09-07 23:22:07,102:INFO:          deepchecks: Not installed
2024-09-07 23:22:07,102:INFO:             xgboost: 2.1.1
2024-09-07 23:22:07,102:INFO:            catboost: Not installed
2024-09-07 23:22:07,102:INFO:              kmodes: Not installed
2024-09-07 23:22:07,103:INFO:             mlxtend: Not installed
2024-09-07 23:22:07,103:INFO:       statsforecast: Not installed
2024-09-07 23:22:07,103:INFO:        tune_sklearn: Not installed
2024-09-07 23:22:07,103:INFO:                 ray: Not installed
2024-09-07 23:22:07,103:INFO:            hyperopt: 0.2.7
2024-09-07 23:22:07,103:INFO:              optuna: 4.0.0
2024-09-07 23:22:07,103:INFO:               skopt: 0.10.2
2024-09-07 23:22:07,103:INFO:              mlflow: Not installed
2024-09-07 23:22:07,103:INFO:              gradio: Not installed
2024-09-07 23:22:07,103:INFO:             fastapi: Not installed
2024-09-07 23:22:07,103:INFO:             uvicorn: Not installed
2024-09-07 23:22:07,103:INFO:              m2cgen: Not installed
2024-09-07 23:22:07,103:INFO:           evidently: Not installed
2024-09-07 23:22:07,103:INFO:               fugue: Not installed
2024-09-07 23:22:07,103:INFO:           streamlit: Not installed
2024-09-07 23:22:07,103:INFO:             prophet: Not installed
2024-09-07 23:22:07,103:INFO:None
2024-09-07 23:22:07,103:INFO:Set up data.
2024-09-07 23:22:07,583:INFO:Set up folding strategy.
2024-09-07 23:22:07,583:INFO:Set up train/test split.
2024-09-07 23:22:08,195:INFO:Set up index.
2024-09-07 23:22:08,214:INFO:Assigning column types.
2024-09-07 23:22:08,826:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-07 23:22:08,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 23:22:08,877:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:22:08,913:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:22:08,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:22:08,965:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 23:22:08,966:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:22:08,996:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:22:08,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:22:08,999:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-07 23:22:09,047:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:22:09,077:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:22:09,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:22:09,128:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:22:09,158:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:22:09,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:22:09,160:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-07 23:22:09,239:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:22:09,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:22:09,319:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:22:09,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:22:09,324:INFO:Preparing preprocessing pipeline...
2024-09-07 23:22:09,430:INFO:Set up simple imputation.
2024-09-07 23:22:09,430:INFO:Set up imbalanced handling.
2024-09-07 23:22:10,266:INFO:Finished creating preprocessing pipeline.
2024-09-07 23:22:10,277:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-07 23:22:10,277:INFO:Creating final display dataframe.
2024-09-07 23:22:12,953:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 428)
4        Transformed data shape      (99147, 428)
5   Transformed train set shape      (76191, 428)
6    Transformed test set shape      (22956, 428)
7              Numeric features               427
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              cf92
2024-09-07 23:22:13,038:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:22:13,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:22:13,121:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:22:13,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:22:13,125:INFO:setup() successfully completed in 6.11s...............
2024-09-07 23:22:13,125:INFO:Initializing compare_models()
2024-09-07 23:22:13,126:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022F4475CF40>, include=['lightgbm', 'xgboost', 'rf', 'lr'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022F4475CF40>, 'include': ['lightgbm', 'xgboost', 'rf', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-07 23:22:13,126:INFO:Checking exceptions
2024-09-07 23:22:13,600:INFO:Preparing display monitor
2024-09-07 23:22:13,603:INFO:Initializing Light Gradient Boosting Machine
2024-09-07 23:22:13,604:INFO:Total runtime is 1.666545867919922e-05 minutes
2024-09-07 23:22:13,604:INFO:SubProcess create_model() called ==================================
2024-09-07 23:22:13,604:INFO:Initializing create_model()
2024-09-07 23:22:13,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022F4475CF40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022F52892C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 23:22:13,604:INFO:Checking exceptions
2024-09-07 23:22:13,604:INFO:Importing libraries
2024-09-07 23:22:13,604:INFO:Copying training dataset
2024-09-07 23:22:14,395:INFO:Defining folds
2024-09-07 23:22:14,395:INFO:Declaring metric variables
2024-09-07 23:22:14,396:INFO:Importing untrained model
2024-09-07 23:22:14,396:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 23:22:14,397:INFO:Starting cross validation
2024-09-07 23:22:14,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 23:24:11,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:24:11,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:24:11,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:24:11,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:25:46,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:25:46,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:25:46,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:25:46,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:26:47,014:INFO:PyCaret ClassificationExperiment
2024-09-07 23:26:47,014:INFO:Logging name: clf-default-name
2024-09-07 23:26:47,014:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 23:26:47,014:INFO:version 3.3.2
2024-09-07 23:26:47,014:INFO:Initializing setup()
2024-09-07 23:26:47,014:INFO:self.USI: 0ed5
2024-09-07 23:26:47,014:INFO:self._variable_keys: {'y_test', 'data', 'fold_generator', 'target_param', '_available_plots', 'is_multiclass', 'html_param', 'seed', 'exp_name_log', 'X', 'gpu_n_jobs_param', 'X_train', '_ml_usecase', 'logging_param', 'fold_groups_param', 'exp_id', 'log_plots_param', 'y', 'pipeline', 'X_test', 'n_jobs_param', 'fold_shuffle_param', 'fix_imbalance', 'memory', 'idx', 'USI', 'gpu_param', 'y_train'}
2024-09-07 23:26:47,014:INFO:Checking environment
2024-09-07 23:26:47,014:INFO:python_version: 3.10.11
2024-09-07 23:26:47,014:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 23:26:47,015:INFO:machine: AMD64
2024-09-07 23:26:47,022:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 23:26:47,022:INFO:Memory: svmem(total=17128263680, available=9729462272, percent=43.2, used=7398801408, free=9729462272)
2024-09-07 23:26:47,022:INFO:Physical Core: 6
2024-09-07 23:26:47,022:INFO:Logical Core: 12
2024-09-07 23:26:47,022:INFO:Checking libraries
2024-09-07 23:26:47,022:INFO:System:
2024-09-07 23:26:47,022:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 23:26:47,022:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 23:26:47,022:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 23:26:47,022:INFO:PyCaret required dependencies:
2024-09-07 23:26:47,044:INFO:                 pip: 24.2
2024-09-07 23:26:47,044:INFO:          setuptools: 72.1.0
2024-09-07 23:26:47,044:INFO:             pycaret: 3.3.2
2024-09-07 23:26:47,044:INFO:             IPython: 8.27.0
2024-09-07 23:26:47,044:INFO:          ipywidgets: 8.1.5
2024-09-07 23:26:47,044:INFO:                tqdm: 4.66.5
2024-09-07 23:26:47,044:INFO:               numpy: 1.26.4
2024-09-07 23:26:47,044:INFO:              pandas: 2.2.2
2024-09-07 23:26:47,044:INFO:              jinja2: 3.1.4
2024-09-07 23:26:47,044:INFO:               scipy: 1.11.4
2024-09-07 23:26:47,044:INFO:              joblib: 1.3.2
2024-09-07 23:26:47,044:INFO:             sklearn: 1.4.2
2024-09-07 23:26:47,044:INFO:                pyod: 2.0.1
2024-09-07 23:26:47,044:INFO:            imblearn: 0.12.3
2024-09-07 23:26:47,044:INFO:   category_encoders: 2.6.3
2024-09-07 23:26:47,044:INFO:            lightgbm: 4.5.0
2024-09-07 23:26:47,044:INFO:               numba: 0.60.0
2024-09-07 23:26:47,044:INFO:            requests: 2.32.3
2024-09-07 23:26:47,044:INFO:          matplotlib: 3.7.5
2024-09-07 23:26:47,044:INFO:          scikitplot: 0.3.7
2024-09-07 23:26:47,044:INFO:         yellowbrick: 1.5
2024-09-07 23:26:47,045:INFO:              plotly: 5.24.0
2024-09-07 23:26:47,045:INFO:    plotly-resampler: Not installed
2024-09-07 23:26:47,045:INFO:             kaleido: 0.2.1
2024-09-07 23:26:47,045:INFO:           schemdraw: 0.15
2024-09-07 23:26:47,045:INFO:         statsmodels: 0.14.2
2024-09-07 23:26:47,045:INFO:              sktime: 0.26.0
2024-09-07 23:26:47,045:INFO:               tbats: 1.1.3
2024-09-07 23:26:47,045:INFO:            pmdarima: 2.0.4
2024-09-07 23:26:47,045:INFO:              psutil: 6.0.0
2024-09-07 23:26:47,045:INFO:          markupsafe: 2.1.5
2024-09-07 23:26:47,045:INFO:             pickle5: Not installed
2024-09-07 23:26:47,045:INFO:         cloudpickle: 3.0.0
2024-09-07 23:26:47,045:INFO:         deprecation: 2.1.0
2024-09-07 23:26:47,045:INFO:              xxhash: 3.5.0
2024-09-07 23:26:47,045:INFO:           wurlitzer: Not installed
2024-09-07 23:26:47,045:INFO:PyCaret optional dependencies:
2024-09-07 23:26:47,059:INFO:                shap: Not installed
2024-09-07 23:26:47,059:INFO:           interpret: Not installed
2024-09-07 23:26:47,059:INFO:                umap: Not installed
2024-09-07 23:26:47,059:INFO:     ydata_profiling: Not installed
2024-09-07 23:26:47,059:INFO:  explainerdashboard: Not installed
2024-09-07 23:26:47,059:INFO:             autoviz: Not installed
2024-09-07 23:26:47,059:INFO:           fairlearn: Not installed
2024-09-07 23:26:47,059:INFO:          deepchecks: Not installed
2024-09-07 23:26:47,059:INFO:             xgboost: 2.1.1
2024-09-07 23:26:47,059:INFO:            catboost: Not installed
2024-09-07 23:26:47,059:INFO:              kmodes: Not installed
2024-09-07 23:26:47,059:INFO:             mlxtend: Not installed
2024-09-07 23:26:47,059:INFO:       statsforecast: Not installed
2024-09-07 23:26:47,059:INFO:        tune_sklearn: Not installed
2024-09-07 23:26:47,059:INFO:                 ray: Not installed
2024-09-07 23:26:47,059:INFO:            hyperopt: 0.2.7
2024-09-07 23:26:47,060:INFO:              optuna: 4.0.0
2024-09-07 23:26:47,060:INFO:               skopt: 0.10.2
2024-09-07 23:26:47,060:INFO:              mlflow: Not installed
2024-09-07 23:26:47,060:INFO:              gradio: Not installed
2024-09-07 23:26:47,060:INFO:             fastapi: Not installed
2024-09-07 23:26:47,060:INFO:             uvicorn: Not installed
2024-09-07 23:26:47,060:INFO:              m2cgen: Not installed
2024-09-07 23:26:47,060:INFO:           evidently: Not installed
2024-09-07 23:26:47,060:INFO:               fugue: Not installed
2024-09-07 23:26:47,060:INFO:           streamlit: Not installed
2024-09-07 23:26:47,060:INFO:             prophet: Not installed
2024-09-07 23:26:47,060:INFO:None
2024-09-07 23:26:47,060:INFO:Set up data.
2024-09-07 23:26:47,542:INFO:Set up folding strategy.
2024-09-07 23:26:47,542:INFO:Set up train/test split.
2024-09-07 23:27:13,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:27:13,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:27:13,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:27:13,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:28:12,696:INFO:PyCaret ClassificationExperiment
2024-09-07 23:28:12,696:INFO:Logging name: clf-default-name
2024-09-07 23:28:12,696:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 23:28:12,696:INFO:version 3.3.2
2024-09-07 23:28:12,696:INFO:Initializing setup()
2024-09-07 23:28:12,697:INFO:self.USI: 339d
2024-09-07 23:28:12,697:INFO:self._variable_keys: {'y', 'exp_id', 'memory', 'X_test', 'X_train', 'pipeline', 'y_test', 'fold_generator', 'log_plots_param', '_ml_usecase', 'exp_name_log', 'seed', 'data', 'n_jobs_param', 'idx', 'USI', 'fold_groups_param', 'gpu_param', 'gpu_n_jobs_param', 'logging_param', 'is_multiclass', 'fix_imbalance', 'X', '_available_plots', 'y_train', 'target_param', 'html_param', 'fold_shuffle_param'}
2024-09-07 23:28:12,697:INFO:Checking environment
2024-09-07 23:28:12,697:INFO:python_version: 3.10.11
2024-09-07 23:28:12,697:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 23:28:12,697:INFO:machine: AMD64
2024-09-07 23:28:12,703:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 23:28:12,704:INFO:Memory: svmem(total=17128263680, available=9813630976, percent=42.7, used=7314632704, free=9813630976)
2024-09-07 23:28:12,704:INFO:Physical Core: 6
2024-09-07 23:28:12,704:INFO:Logical Core: 12
2024-09-07 23:28:12,704:INFO:Checking libraries
2024-09-07 23:28:12,704:INFO:System:
2024-09-07 23:28:12,704:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 23:28:12,704:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 23:28:12,704:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 23:28:12,704:INFO:PyCaret required dependencies:
2024-09-07 23:28:12,726:INFO:                 pip: 24.2
2024-09-07 23:28:12,726:INFO:          setuptools: 72.1.0
2024-09-07 23:28:12,726:INFO:             pycaret: 3.3.2
2024-09-07 23:28:12,726:INFO:             IPython: 8.27.0
2024-09-07 23:28:12,726:INFO:          ipywidgets: 8.1.5
2024-09-07 23:28:12,726:INFO:                tqdm: 4.66.5
2024-09-07 23:28:12,726:INFO:               numpy: 1.26.4
2024-09-07 23:28:12,726:INFO:              pandas: 2.2.2
2024-09-07 23:28:12,727:INFO:              jinja2: 3.1.4
2024-09-07 23:28:12,727:INFO:               scipy: 1.11.4
2024-09-07 23:28:12,727:INFO:              joblib: 1.3.2
2024-09-07 23:28:12,727:INFO:             sklearn: 1.4.2
2024-09-07 23:28:12,727:INFO:                pyod: 2.0.1
2024-09-07 23:28:12,727:INFO:            imblearn: 0.12.3
2024-09-07 23:28:12,727:INFO:   category_encoders: 2.6.3
2024-09-07 23:28:12,727:INFO:            lightgbm: 4.5.0
2024-09-07 23:28:12,727:INFO:               numba: 0.60.0
2024-09-07 23:28:12,727:INFO:            requests: 2.32.3
2024-09-07 23:28:12,727:INFO:          matplotlib: 3.7.5
2024-09-07 23:28:12,727:INFO:          scikitplot: 0.3.7
2024-09-07 23:28:12,727:INFO:         yellowbrick: 1.5
2024-09-07 23:28:12,727:INFO:              plotly: 5.24.0
2024-09-07 23:28:12,727:INFO:    plotly-resampler: Not installed
2024-09-07 23:28:12,727:INFO:             kaleido: 0.2.1
2024-09-07 23:28:12,727:INFO:           schemdraw: 0.15
2024-09-07 23:28:12,727:INFO:         statsmodels: 0.14.2
2024-09-07 23:28:12,727:INFO:              sktime: 0.26.0
2024-09-07 23:28:12,727:INFO:               tbats: 1.1.3
2024-09-07 23:28:12,727:INFO:            pmdarima: 2.0.4
2024-09-07 23:28:12,727:INFO:              psutil: 6.0.0
2024-09-07 23:28:12,727:INFO:          markupsafe: 2.1.5
2024-09-07 23:28:12,727:INFO:             pickle5: Not installed
2024-09-07 23:28:12,727:INFO:         cloudpickle: 3.0.0
2024-09-07 23:28:12,727:INFO:         deprecation: 2.1.0
2024-09-07 23:28:12,727:INFO:              xxhash: 3.5.0
2024-09-07 23:28:12,727:INFO:           wurlitzer: Not installed
2024-09-07 23:28:12,727:INFO:PyCaret optional dependencies:
2024-09-07 23:28:12,741:INFO:                shap: Not installed
2024-09-07 23:28:12,741:INFO:           interpret: Not installed
2024-09-07 23:28:12,741:INFO:                umap: Not installed
2024-09-07 23:28:12,741:INFO:     ydata_profiling: Not installed
2024-09-07 23:28:12,741:INFO:  explainerdashboard: Not installed
2024-09-07 23:28:12,741:INFO:             autoviz: Not installed
2024-09-07 23:28:12,741:INFO:           fairlearn: Not installed
2024-09-07 23:28:12,741:INFO:          deepchecks: Not installed
2024-09-07 23:28:12,741:INFO:             xgboost: 2.1.1
2024-09-07 23:28:12,741:INFO:            catboost: Not installed
2024-09-07 23:28:12,741:INFO:              kmodes: Not installed
2024-09-07 23:28:12,741:INFO:             mlxtend: Not installed
2024-09-07 23:28:12,741:INFO:       statsforecast: Not installed
2024-09-07 23:28:12,741:INFO:        tune_sklearn: Not installed
2024-09-07 23:28:12,741:INFO:                 ray: Not installed
2024-09-07 23:28:12,741:INFO:            hyperopt: 0.2.7
2024-09-07 23:28:12,741:INFO:              optuna: 4.0.0
2024-09-07 23:28:12,741:INFO:               skopt: 0.10.2
2024-09-07 23:28:12,741:INFO:              mlflow: Not installed
2024-09-07 23:28:12,741:INFO:              gradio: Not installed
2024-09-07 23:28:12,741:INFO:             fastapi: Not installed
2024-09-07 23:28:12,741:INFO:             uvicorn: Not installed
2024-09-07 23:28:12,741:INFO:              m2cgen: Not installed
2024-09-07 23:28:12,741:INFO:           evidently: Not installed
2024-09-07 23:28:12,741:INFO:               fugue: Not installed
2024-09-07 23:28:12,742:INFO:           streamlit: Not installed
2024-09-07 23:28:12,742:INFO:             prophet: Not installed
2024-09-07 23:28:12,742:INFO:None
2024-09-07 23:28:12,742:INFO:Set up data.
2024-09-07 23:28:13,207:INFO:Set up folding strategy.
2024-09-07 23:28:13,208:INFO:Set up train/test split.
2024-09-07 23:28:13,813:INFO:Set up index.
2024-09-07 23:28:13,831:INFO:Assigning column types.
2024-09-07 23:28:14,428:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-07 23:28:14,476:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 23:28:14,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:28:14,514:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:28:14,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:28:14,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 23:28:14,566:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:28:14,604:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:28:14,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:28:14,609:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-07 23:28:14,657:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:28:14,687:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:28:14,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:28:14,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:28:14,770:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:28:14,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:28:14,773:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-07 23:28:14,851:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:28:14,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:28:14,933:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:28:14,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:28:14,937:INFO:Preparing preprocessing pipeline...
2024-09-07 23:28:15,039:INFO:Set up simple imputation.
2024-09-07 23:28:15,039:INFO:Set up imbalanced handling.
2024-09-07 23:28:15,846:INFO:Finished creating preprocessing pipeline.
2024-09-07 23:28:15,856:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-07 23:28:15,856:INFO:Creating final display dataframe.
2024-09-07 23:28:18,439:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 428)
4        Transformed data shape      (99147, 428)
5   Transformed train set shape      (76191, 428)
6    Transformed test set shape      (22956, 428)
7              Numeric features               427
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              339d
2024-09-07 23:28:18,521:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:28:18,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:28:18,602:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:28:18,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:28:18,607:INFO:setup() successfully completed in 5.95s...............
2024-09-07 23:28:18,607:INFO:Initializing compare_models()
2024-09-07 23:28:18,607:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002208C26A170>, include=['lightgbm', 'xgboost', 'rf', 'lr'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002208C26A170>, 'include': ['lightgbm', 'xgboost', 'rf', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-07 23:28:18,607:INFO:Checking exceptions
2024-09-07 23:28:19,063:INFO:Preparing display monitor
2024-09-07 23:28:19,066:INFO:Initializing Light Gradient Boosting Machine
2024-09-07 23:28:19,066:INFO:Total runtime is 0.0 minutes
2024-09-07 23:28:19,067:INFO:SubProcess create_model() called ==================================
2024-09-07 23:28:19,067:INFO:Initializing create_model()
2024-09-07 23:28:19,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002208C26A170>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002208C3CE200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 23:28:19,067:INFO:Checking exceptions
2024-09-07 23:28:19,067:INFO:Importing libraries
2024-09-07 23:28:19,067:INFO:Copying training dataset
2024-09-07 23:28:19,780:INFO:Defining folds
2024-09-07 23:28:19,780:INFO:Declaring metric variables
2024-09-07 23:28:19,780:INFO:Importing untrained model
2024-09-07 23:28:19,781:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 23:28:19,781:INFO:Starting cross validation
2024-09-07 23:28:19,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 23:31:30,589:INFO:Calculating mean and std
2024-09-07 23:31:30,589:INFO:Creating metrics dataframe
2024-09-07 23:31:30,589:INFO:Uploading results into container
2024-09-07 23:31:30,589:INFO:Uploading model into container now
2024-09-07 23:31:30,589:INFO:_master_model_container: 1
2024-09-07 23:31:30,589:INFO:_display_container: 2
2024-09-07 23:31:30,589:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-07 23:31:30,589:INFO:create_model() successfully completed......................................
2024-09-07 23:31:30,694:INFO:SubProcess create_model() end ==================================
2024-09-07 23:31:30,694:INFO:Creating metrics dataframe
2024-09-07 23:31:30,694:INFO:Initializing Extreme Gradient Boosting
2024-09-07 23:31:30,694:INFO:Total runtime is 3.193795931339264 minutes
2024-09-07 23:31:30,694:INFO:SubProcess create_model() called ==================================
2024-09-07 23:31:30,694:INFO:Initializing create_model()
2024-09-07 23:31:30,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002208C26A170>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002208C3CE200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 23:31:30,709:INFO:Checking exceptions
2024-09-07 23:31:30,709:INFO:Importing libraries
2024-09-07 23:31:30,709:INFO:Copying training dataset
2024-09-07 23:31:31,582:INFO:Defining folds
2024-09-07 23:31:31,582:INFO:Declaring metric variables
2024-09-07 23:31:31,582:INFO:Importing untrained model
2024-09-07 23:31:31,582:INFO:Extreme Gradient Boosting Imported successfully
2024-09-07 23:31:31,582:INFO:Starting cross validation
2024-09-07 23:31:31,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 23:32:04,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:32:04,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:32:04,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:32:04,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:32:43,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:32:43,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:32:43,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:32:43,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:33:20,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:33:20,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:33:20,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:33:20,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:34:21,358:INFO:PyCaret ClassificationExperiment
2024-09-07 23:34:21,358:INFO:Logging name: clf-default-name
2024-09-07 23:34:21,358:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 23:34:21,358:INFO:version 3.3.2
2024-09-07 23:34:21,358:INFO:Initializing setup()
2024-09-07 23:34:21,358:INFO:self.USI: 6efc
2024-09-07 23:34:21,358:INFO:self._variable_keys: {'log_plots_param', 'y_train', 'X', 'is_multiclass', 'USI', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'fold_groups_param', 'logging_param', 'memory', 'fix_imbalance', 'gpu_n_jobs_param', 'exp_name_log', '_available_plots', 'pipeline', 'seed', 'target_param', 'n_jobs_param', 'fold_shuffle_param', 'X_test', 'gpu_param', 'y', 'X_train', 'fold_generator', 'data', 'y_test'}
2024-09-07 23:34:21,358:INFO:Checking environment
2024-09-07 23:34:21,358:INFO:python_version: 3.10.11
2024-09-07 23:34:21,358:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 23:34:21,358:INFO:machine: AMD64
2024-09-07 23:34:21,373:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 23:34:21,373:INFO:Memory: svmem(total=17128263680, available=8973295616, percent=47.6, used=8154968064, free=8973295616)
2024-09-07 23:34:21,373:INFO:Physical Core: 6
2024-09-07 23:34:21,373:INFO:Logical Core: 12
2024-09-07 23:34:21,373:INFO:Checking libraries
2024-09-07 23:34:21,373:INFO:System:
2024-09-07 23:34:21,373:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 23:34:21,373:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 23:34:21,373:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 23:34:21,373:INFO:PyCaret required dependencies:
2024-09-07 23:34:21,389:INFO:                 pip: 24.2
2024-09-07 23:34:21,389:INFO:          setuptools: 72.1.0
2024-09-07 23:34:21,389:INFO:             pycaret: 3.3.2
2024-09-07 23:34:21,389:INFO:             IPython: 8.27.0
2024-09-07 23:34:21,389:INFO:          ipywidgets: 8.1.5
2024-09-07 23:34:21,389:INFO:                tqdm: 4.66.5
2024-09-07 23:34:21,389:INFO:               numpy: 1.26.4
2024-09-07 23:34:21,389:INFO:              pandas: 2.2.2
2024-09-07 23:34:21,389:INFO:              jinja2: 3.1.4
2024-09-07 23:34:21,389:INFO:               scipy: 1.11.4
2024-09-07 23:34:21,389:INFO:              joblib: 1.3.2
2024-09-07 23:34:21,389:INFO:             sklearn: 1.4.2
2024-09-07 23:34:21,389:INFO:                pyod: 2.0.1
2024-09-07 23:34:21,389:INFO:            imblearn: 0.12.3
2024-09-07 23:34:21,389:INFO:   category_encoders: 2.6.3
2024-09-07 23:34:21,389:INFO:            lightgbm: 4.5.0
2024-09-07 23:34:21,389:INFO:               numba: 0.60.0
2024-09-07 23:34:21,389:INFO:            requests: 2.32.3
2024-09-07 23:34:21,389:INFO:          matplotlib: 3.7.5
2024-09-07 23:34:21,389:INFO:          scikitplot: 0.3.7
2024-09-07 23:34:21,389:INFO:         yellowbrick: 1.5
2024-09-07 23:34:21,389:INFO:              plotly: 5.24.0
2024-09-07 23:34:21,389:INFO:    plotly-resampler: Not installed
2024-09-07 23:34:21,389:INFO:             kaleido: 0.2.1
2024-09-07 23:34:21,389:INFO:           schemdraw: 0.15
2024-09-07 23:34:21,389:INFO:         statsmodels: 0.14.2
2024-09-07 23:34:21,389:INFO:              sktime: 0.26.0
2024-09-07 23:34:21,389:INFO:               tbats: 1.1.3
2024-09-07 23:34:21,389:INFO:            pmdarima: 2.0.4
2024-09-07 23:34:21,389:INFO:              psutil: 6.0.0
2024-09-07 23:34:21,389:INFO:          markupsafe: 2.1.5
2024-09-07 23:34:21,389:INFO:             pickle5: Not installed
2024-09-07 23:34:21,389:INFO:         cloudpickle: 3.0.0
2024-09-07 23:34:21,389:INFO:         deprecation: 2.1.0
2024-09-07 23:34:21,389:INFO:              xxhash: 3.5.0
2024-09-07 23:34:21,389:INFO:           wurlitzer: Not installed
2024-09-07 23:34:21,389:INFO:PyCaret optional dependencies:
2024-09-07 23:34:21,405:INFO:                shap: Not installed
2024-09-07 23:34:21,405:INFO:           interpret: Not installed
2024-09-07 23:34:21,405:INFO:                umap: Not installed
2024-09-07 23:34:21,405:INFO:     ydata_profiling: Not installed
2024-09-07 23:34:21,405:INFO:  explainerdashboard: Not installed
2024-09-07 23:34:21,405:INFO:             autoviz: Not installed
2024-09-07 23:34:21,405:INFO:           fairlearn: Not installed
2024-09-07 23:34:21,405:INFO:          deepchecks: Not installed
2024-09-07 23:34:21,405:INFO:             xgboost: 2.1.1
2024-09-07 23:34:21,405:INFO:            catboost: Not installed
2024-09-07 23:34:21,405:INFO:              kmodes: Not installed
2024-09-07 23:34:21,405:INFO:             mlxtend: Not installed
2024-09-07 23:34:21,405:INFO:       statsforecast: Not installed
2024-09-07 23:34:21,405:INFO:        tune_sklearn: Not installed
2024-09-07 23:34:21,405:INFO:                 ray: Not installed
2024-09-07 23:34:21,405:INFO:            hyperopt: 0.2.7
2024-09-07 23:34:21,405:INFO:              optuna: 4.0.0
2024-09-07 23:34:21,405:INFO:               skopt: 0.10.2
2024-09-07 23:34:21,405:INFO:              mlflow: Not installed
2024-09-07 23:34:21,405:INFO:              gradio: Not installed
2024-09-07 23:34:21,405:INFO:             fastapi: Not installed
2024-09-07 23:34:21,405:INFO:             uvicorn: Not installed
2024-09-07 23:34:21,405:INFO:              m2cgen: Not installed
2024-09-07 23:34:21,405:INFO:           evidently: Not installed
2024-09-07 23:34:21,405:INFO:               fugue: Not installed
2024-09-07 23:34:21,405:INFO:           streamlit: Not installed
2024-09-07 23:34:21,405:INFO:             prophet: Not installed
2024-09-07 23:34:21,405:INFO:None
2024-09-07 23:34:21,405:INFO:Set up data.
2024-09-07 23:34:21,870:INFO:Set up folding strategy.
2024-09-07 23:34:21,870:INFO:Set up train/test split.
2024-09-07 23:34:22,490:INFO:Set up index.
2024-09-07 23:34:22,505:INFO:Assigning column types.
2024-09-07 23:34:23,120:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-07 23:34:23,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 23:34:23,179:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:34:23,209:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:34:23,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:34:23,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 23:34:23,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:34:23,287:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:34:23,287:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:34:23,287:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-07 23:34:23,339:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:34:23,370:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:34:23,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:34:23,423:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:34:23,454:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:34:23,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:34:23,454:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-07 23:34:23,537:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:34:23,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:34:23,631:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:34:23,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:34:23,631:INFO:Preparing preprocessing pipeline...
2024-09-07 23:34:23,723:INFO:Set up simple imputation.
2024-09-07 23:34:23,723:INFO:Set up imbalanced handling.
2024-09-07 23:34:24,527:INFO:Finished creating preprocessing pipeline.
2024-09-07 23:34:24,539:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-07 23:34:24,540:INFO:Creating final display dataframe.
2024-09-07 23:34:27,136:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 428)
4        Transformed data shape      (99147, 428)
5   Transformed train set shape      (76191, 428)
6    Transformed test set shape      (22956, 428)
7              Numeric features               427
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              6efc
2024-09-07 23:34:27,218:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:34:27,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:34:27,305:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:34:27,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:34:27,305:INFO:setup() successfully completed in 5.98s...............
2024-09-07 23:34:27,305:INFO:Initializing compare_models()
2024-09-07 23:34:27,305:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205DDFC0F70>, include=['lightgbm', 'xgboost', 'rf', 'lr'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000205DDFC0F70>, 'include': ['lightgbm', 'xgboost', 'rf', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-07 23:34:27,305:INFO:Checking exceptions
2024-09-07 23:34:27,770:INFO:Preparing display monitor
2024-09-07 23:34:27,777:INFO:Initializing Light Gradient Boosting Machine
2024-09-07 23:34:27,777:INFO:Total runtime is 0.0 minutes
2024-09-07 23:34:27,777:INFO:SubProcess create_model() called ==================================
2024-09-07 23:34:27,777:INFO:Initializing create_model()
2024-09-07 23:34:27,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205DDFC0F70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205E13C22C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 23:34:27,777:INFO:Checking exceptions
2024-09-07 23:34:27,777:INFO:Importing libraries
2024-09-07 23:34:27,777:INFO:Copying training dataset
2024-09-07 23:34:28,524:INFO:Defining folds
2024-09-07 23:34:28,524:INFO:Declaring metric variables
2024-09-07 23:34:28,525:INFO:Importing untrained model
2024-09-07 23:34:28,525:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 23:34:28,525:INFO:Starting cross validation
2024-09-07 23:34:28,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 23:35:39,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:35:39,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:35:39,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:35:39,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:36:39,081:INFO:PyCaret ClassificationExperiment
2024-09-07 23:36:39,081:INFO:Logging name: clf-default-name
2024-09-07 23:36:39,081:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 23:36:39,081:INFO:version 3.3.2
2024-09-07 23:36:39,081:INFO:Initializing setup()
2024-09-07 23:36:39,081:INFO:self.USI: 508e
2024-09-07 23:36:39,081:INFO:self._variable_keys: {'gpu_param', 'X_train', 'exp_name_log', 'target_param', '_ml_usecase', 'log_plots_param', 'n_jobs_param', 'is_multiclass', 'exp_id', '_available_plots', 'logging_param', 'seed', 'y_train', 'fold_shuffle_param', 'fix_imbalance', 'X', 'fold_generator', 'fold_groups_param', 'X_test', 'idx', 'html_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'y', 'USI', 'y_test', 'data'}
2024-09-07 23:36:39,081:INFO:Checking environment
2024-09-07 23:36:39,081:INFO:python_version: 3.10.11
2024-09-07 23:36:39,081:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 23:36:39,081:INFO:machine: AMD64
2024-09-07 23:36:39,089:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 23:36:39,089:INFO:Memory: svmem(total=17128263680, available=9700716544, percent=43.4, used=7427547136, free=9700716544)
2024-09-07 23:36:39,089:INFO:Physical Core: 6
2024-09-07 23:36:39,089:INFO:Logical Core: 12
2024-09-07 23:36:39,089:INFO:Checking libraries
2024-09-07 23:36:39,089:INFO:System:
2024-09-07 23:36:39,089:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 23:36:39,089:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 23:36:39,089:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 23:36:39,089:INFO:PyCaret required dependencies:
2024-09-07 23:36:39,116:INFO:                 pip: 24.2
2024-09-07 23:36:39,116:INFO:          setuptools: 72.1.0
2024-09-07 23:36:39,116:INFO:             pycaret: 3.3.2
2024-09-07 23:36:39,116:INFO:             IPython: 8.27.0
2024-09-07 23:36:39,116:INFO:          ipywidgets: 8.1.5
2024-09-07 23:36:39,116:INFO:                tqdm: 4.66.5
2024-09-07 23:36:39,116:INFO:               numpy: 1.26.4
2024-09-07 23:36:39,116:INFO:              pandas: 2.2.2
2024-09-07 23:36:39,116:INFO:              jinja2: 3.1.4
2024-09-07 23:36:39,116:INFO:               scipy: 1.11.4
2024-09-07 23:36:39,116:INFO:              joblib: 1.3.2
2024-09-07 23:36:39,116:INFO:             sklearn: 1.4.2
2024-09-07 23:36:39,116:INFO:                pyod: 2.0.1
2024-09-07 23:36:39,116:INFO:            imblearn: 0.12.3
2024-09-07 23:36:39,116:INFO:   category_encoders: 2.6.3
2024-09-07 23:36:39,116:INFO:            lightgbm: 4.5.0
2024-09-07 23:36:39,116:INFO:               numba: 0.60.0
2024-09-07 23:36:39,116:INFO:            requests: 2.32.3
2024-09-07 23:36:39,116:INFO:          matplotlib: 3.7.5
2024-09-07 23:36:39,116:INFO:          scikitplot: 0.3.7
2024-09-07 23:36:39,116:INFO:         yellowbrick: 1.5
2024-09-07 23:36:39,116:INFO:              plotly: 5.24.0
2024-09-07 23:36:39,116:INFO:    plotly-resampler: Not installed
2024-09-07 23:36:39,116:INFO:             kaleido: 0.2.1
2024-09-07 23:36:39,116:INFO:           schemdraw: 0.15
2024-09-07 23:36:39,116:INFO:         statsmodels: 0.14.2
2024-09-07 23:36:39,116:INFO:              sktime: 0.26.0
2024-09-07 23:36:39,116:INFO:               tbats: 1.1.3
2024-09-07 23:36:39,116:INFO:            pmdarima: 2.0.4
2024-09-07 23:36:39,116:INFO:              psutil: 6.0.0
2024-09-07 23:36:39,116:INFO:          markupsafe: 2.1.5
2024-09-07 23:36:39,116:INFO:             pickle5: Not installed
2024-09-07 23:36:39,116:INFO:         cloudpickle: 3.0.0
2024-09-07 23:36:39,116:INFO:         deprecation: 2.1.0
2024-09-07 23:36:39,116:INFO:              xxhash: 3.5.0
2024-09-07 23:36:39,116:INFO:           wurlitzer: Not installed
2024-09-07 23:36:39,116:INFO:PyCaret optional dependencies:
2024-09-07 23:36:39,130:INFO:                shap: Not installed
2024-09-07 23:36:39,130:INFO:           interpret: Not installed
2024-09-07 23:36:39,130:INFO:                umap: Not installed
2024-09-07 23:36:39,130:INFO:     ydata_profiling: Not installed
2024-09-07 23:36:39,130:INFO:  explainerdashboard: Not installed
2024-09-07 23:36:39,130:INFO:             autoviz: Not installed
2024-09-07 23:36:39,130:INFO:           fairlearn: Not installed
2024-09-07 23:36:39,130:INFO:          deepchecks: Not installed
2024-09-07 23:36:39,130:INFO:             xgboost: 2.1.1
2024-09-07 23:36:39,130:INFO:            catboost: Not installed
2024-09-07 23:36:39,130:INFO:              kmodes: Not installed
2024-09-07 23:36:39,130:INFO:             mlxtend: Not installed
2024-09-07 23:36:39,130:INFO:       statsforecast: Not installed
2024-09-07 23:36:39,130:INFO:        tune_sklearn: Not installed
2024-09-07 23:36:39,130:INFO:                 ray: Not installed
2024-09-07 23:36:39,130:INFO:            hyperopt: 0.2.7
2024-09-07 23:36:39,130:INFO:              optuna: 4.0.0
2024-09-07 23:36:39,130:INFO:               skopt: 0.10.2
2024-09-07 23:36:39,130:INFO:              mlflow: Not installed
2024-09-07 23:36:39,130:INFO:              gradio: Not installed
2024-09-07 23:36:39,130:INFO:             fastapi: Not installed
2024-09-07 23:36:39,130:INFO:             uvicorn: Not installed
2024-09-07 23:36:39,130:INFO:              m2cgen: Not installed
2024-09-07 23:36:39,130:INFO:           evidently: Not installed
2024-09-07 23:36:39,130:INFO:               fugue: Not installed
2024-09-07 23:36:39,130:INFO:           streamlit: Not installed
2024-09-07 23:36:39,130:INFO:             prophet: Not installed
2024-09-07 23:36:39,130:INFO:None
2024-09-07 23:36:39,130:INFO:Set up data.
2024-09-07 23:40:11,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:40:11,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:40:11,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:40:11,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:40:31,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:40:31,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:40:31,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:40:31,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:41:08,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:41:08,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:41:08,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:41:08,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:41:58,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:41:58,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:41:58,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:41:58,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:42:57,785:INFO:PyCaret ClassificationExperiment
2024-09-07 23:42:57,785:INFO:Logging name: clf-default-name
2024-09-07 23:42:57,786:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-07 23:42:57,786:INFO:version 3.3.2
2024-09-07 23:42:57,786:INFO:Initializing setup()
2024-09-07 23:42:57,786:INFO:self.USI: 3710
2024-09-07 23:42:57,786:INFO:self._variable_keys: {'gpu_n_jobs_param', 'logging_param', 'log_plots_param', 'y', '_ml_usecase', 'gpu_param', 'pipeline', 'y_train', '_available_plots', 'target_param', 'html_param', 'idx', 'y_test', 'X_train', 'fold_shuffle_param', 'exp_name_log', 'fold_groups_param', 'seed', 'X_test', 'X', 'n_jobs_param', 'exp_id', 'fold_generator', 'memory', 'data', 'USI', 'is_multiclass', 'fix_imbalance'}
2024-09-07 23:42:57,786:INFO:Checking environment
2024-09-07 23:42:57,786:INFO:python_version: 3.10.11
2024-09-07 23:42:57,786:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-07 23:42:57,786:INFO:machine: AMD64
2024-09-07 23:42:57,793:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-07 23:42:57,793:INFO:Memory: svmem(total=17128263680, available=9362653184, percent=45.3, used=7765610496, free=9362653184)
2024-09-07 23:42:57,793:INFO:Physical Core: 6
2024-09-07 23:42:57,793:INFO:Logical Core: 12
2024-09-07 23:42:57,793:INFO:Checking libraries
2024-09-07 23:42:57,794:INFO:System:
2024-09-07 23:42:57,794:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-07 23:42:57,794:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-07 23:42:57,794:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-07 23:42:57,794:INFO:PyCaret required dependencies:
2024-09-07 23:42:57,817:INFO:                 pip: 24.2
2024-09-07 23:42:57,817:INFO:          setuptools: 72.1.0
2024-09-07 23:42:57,817:INFO:             pycaret: 3.3.2
2024-09-07 23:42:57,817:INFO:             IPython: 8.27.0
2024-09-07 23:42:57,817:INFO:          ipywidgets: 8.1.5
2024-09-07 23:42:57,817:INFO:                tqdm: 4.66.5
2024-09-07 23:42:57,817:INFO:               numpy: 1.26.4
2024-09-07 23:42:57,817:INFO:              pandas: 2.2.2
2024-09-07 23:42:57,817:INFO:              jinja2: 3.1.4
2024-09-07 23:42:57,817:INFO:               scipy: 1.11.4
2024-09-07 23:42:57,817:INFO:              joblib: 1.3.2
2024-09-07 23:42:57,817:INFO:             sklearn: 1.4.2
2024-09-07 23:42:57,817:INFO:                pyod: 2.0.1
2024-09-07 23:42:57,817:INFO:            imblearn: 0.12.3
2024-09-07 23:42:57,817:INFO:   category_encoders: 2.6.3
2024-09-07 23:42:57,817:INFO:            lightgbm: 4.5.0
2024-09-07 23:42:57,817:INFO:               numba: 0.60.0
2024-09-07 23:42:57,817:INFO:            requests: 2.32.3
2024-09-07 23:42:57,818:INFO:          matplotlib: 3.7.5
2024-09-07 23:42:57,818:INFO:          scikitplot: 0.3.7
2024-09-07 23:42:57,818:INFO:         yellowbrick: 1.5
2024-09-07 23:42:57,818:INFO:              plotly: 5.24.0
2024-09-07 23:42:57,818:INFO:    plotly-resampler: Not installed
2024-09-07 23:42:57,818:INFO:             kaleido: 0.2.1
2024-09-07 23:42:57,818:INFO:           schemdraw: 0.15
2024-09-07 23:42:57,818:INFO:         statsmodels: 0.14.2
2024-09-07 23:42:57,818:INFO:              sktime: 0.26.0
2024-09-07 23:42:57,818:INFO:               tbats: 1.1.3
2024-09-07 23:42:57,818:INFO:            pmdarima: 2.0.4
2024-09-07 23:42:57,818:INFO:              psutil: 6.0.0
2024-09-07 23:42:57,818:INFO:          markupsafe: 2.1.5
2024-09-07 23:42:57,818:INFO:             pickle5: Not installed
2024-09-07 23:42:57,818:INFO:         cloudpickle: 3.0.0
2024-09-07 23:42:57,818:INFO:         deprecation: 2.1.0
2024-09-07 23:42:57,818:INFO:              xxhash: 3.5.0
2024-09-07 23:42:57,818:INFO:           wurlitzer: Not installed
2024-09-07 23:42:57,818:INFO:PyCaret optional dependencies:
2024-09-07 23:42:57,831:INFO:                shap: Not installed
2024-09-07 23:42:57,831:INFO:           interpret: Not installed
2024-09-07 23:42:57,831:INFO:                umap: Not installed
2024-09-07 23:42:57,831:INFO:     ydata_profiling: Not installed
2024-09-07 23:42:57,831:INFO:  explainerdashboard: Not installed
2024-09-07 23:42:57,831:INFO:             autoviz: Not installed
2024-09-07 23:42:57,831:INFO:           fairlearn: Not installed
2024-09-07 23:42:57,831:INFO:          deepchecks: Not installed
2024-09-07 23:42:57,832:INFO:             xgboost: 2.1.1
2024-09-07 23:42:57,832:INFO:            catboost: Not installed
2024-09-07 23:42:57,832:INFO:              kmodes: Not installed
2024-09-07 23:42:57,832:INFO:             mlxtend: Not installed
2024-09-07 23:42:57,832:INFO:       statsforecast: Not installed
2024-09-07 23:42:57,832:INFO:        tune_sklearn: Not installed
2024-09-07 23:42:57,832:INFO:                 ray: Not installed
2024-09-07 23:42:57,832:INFO:            hyperopt: 0.2.7
2024-09-07 23:42:57,832:INFO:              optuna: 4.0.0
2024-09-07 23:42:57,832:INFO:               skopt: 0.10.2
2024-09-07 23:42:57,832:INFO:              mlflow: Not installed
2024-09-07 23:42:57,832:INFO:              gradio: Not installed
2024-09-07 23:42:57,832:INFO:             fastapi: Not installed
2024-09-07 23:42:57,832:INFO:             uvicorn: Not installed
2024-09-07 23:42:57,832:INFO:              m2cgen: Not installed
2024-09-07 23:42:57,832:INFO:           evidently: Not installed
2024-09-07 23:42:57,832:INFO:               fugue: Not installed
2024-09-07 23:42:57,832:INFO:           streamlit: Not installed
2024-09-07 23:42:57,832:INFO:             prophet: Not installed
2024-09-07 23:42:57,832:INFO:None
2024-09-07 23:42:57,832:INFO:Set up data.
2024-09-07 23:42:58,328:INFO:Set up folding strategy.
2024-09-07 23:42:58,329:INFO:Set up train/test split.
2024-09-07 23:42:58,967:INFO:Set up index.
2024-09-07 23:42:58,988:INFO:Assigning column types.
2024-09-07 23:42:59,631:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-07 23:42:59,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 23:42:59,700:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:42:59,736:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:42:59,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:42:59,791:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-07 23:42:59,792:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:42:59,822:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:42:59,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:42:59,825:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-07 23:42:59,874:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:42:59,904:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:42:59,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:42:59,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-07 23:42:59,987:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:42:59,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:42:59,990:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-07 23:43:00,069:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:43:00,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:43:00,151:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:43:00,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:43:00,156:INFO:Preparing preprocessing pipeline...
2024-09-07 23:43:00,259:INFO:Set up simple imputation.
2024-09-07 23:43:00,259:INFO:Set up imbalanced handling.
2024-09-07 23:43:01,077:INFO:Finished creating preprocessing pipeline.
2024-09-07 23:43:01,089:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-07 23:43:01,089:INFO:Creating final display dataframe.
2024-09-07 23:43:03,810:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 428)
4        Transformed data shape      (99147, 428)
5   Transformed train set shape      (76191, 428)
6    Transformed test set shape      (22956, 428)
7              Numeric features               427
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              3710
2024-09-07 23:43:03,894:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:43:03,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:43:03,978:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-07 23:43:03,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-07 23:43:03,981:INFO:setup() successfully completed in 6.24s...............
2024-09-07 23:43:03,981:INFO:Initializing compare_models()
2024-09-07 23:43:03,981:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D28E331090>, include=['lightgbm', 'xgboost', 'rf', 'lr'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D28E331090>, 'include': ['lightgbm', 'xgboost', 'rf', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-07 23:43:03,982:INFO:Checking exceptions
2024-09-07 23:43:04,470:INFO:Preparing display monitor
2024-09-07 23:43:04,474:INFO:Initializing Light Gradient Boosting Machine
2024-09-07 23:43:04,474:INFO:Total runtime is 0.0 minutes
2024-09-07 23:43:04,475:INFO:SubProcess create_model() called ==================================
2024-09-07 23:43:04,475:INFO:Initializing create_model()
2024-09-07 23:43:04,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D28E331090>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D2917AEC80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-07 23:43:04,475:INFO:Checking exceptions
2024-09-07 23:43:04,475:INFO:Importing libraries
2024-09-07 23:43:04,475:INFO:Copying training dataset
2024-09-07 23:43:05,248:INFO:Defining folds
2024-09-07 23:43:05,249:INFO:Declaring metric variables
2024-09-07 23:43:05,249:INFO:Importing untrained model
2024-09-07 23:43:05,249:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-07 23:43:05,250:INFO:Starting cross validation
2024-09-07 23:43:05,252:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-07 23:43:20,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:43:20,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:43:20,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:43:20,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:45:10,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:45:10,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:45:10,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:45:10,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:45:10,399:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:45:11,839:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

2024-09-07 23:45:27,615:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:46:20,887:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:46:20,887:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:46:20,887:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:46:20,887:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:46:21,284:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:46:22,601:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

2024-09-07 23:46:23,770:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:46:52,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:46:52,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:46:52,295:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:46:52,295:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:46:52,648:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:46:54,154:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

2024-09-07 23:46:55,609:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:47:02,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:47:02,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:47:02,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:47:02,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:47:03,078:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:47:04,553:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

2024-09-07 23:47:21,300:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:49:09,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:49:09,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:49:09,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:49:09,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:49:09,575:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:49:11,196:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

2024-09-07 23:49:25,917:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:49:26,012:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:49:27,645:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

2024-09-07 23:49:29,125:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:49:41,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:49:41,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:49:41,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:49:41,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-07 23:49:42,136:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\multiprocessing\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=12>
  _warn(f"unclosed running multiprocessing pool {self!r}",

2024-09-07 23:49:43,657:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\kaggle\api_client.py:165: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.
  response_data.getheaders())

