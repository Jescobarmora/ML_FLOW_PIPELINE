2024-09-05 18:26:00,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 18:26:00,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 18:26:00,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 18:26:00,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 18:27:54,467:INFO:PyCaret ClassificationExperiment
2024-09-05 18:27:54,467:INFO:Logging name: clf-default-name
2024-09-05 18:27:54,467:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-05 18:27:54,467:INFO:version 3.3.2
2024-09-05 18:27:54,468:INFO:Initializing setup()
2024-09-05 18:27:54,468:INFO:self.USI: 6cee
2024-09-05 18:27:54,468:INFO:self._variable_keys: {'_ml_usecase', 'fold_shuffle_param', 'y_train', 'data', 'pipeline', 'X_test', 'fold_groups_param', 'exp_id', 'gpu_n_jobs_param', 'seed', 'fix_imbalance', 'idx', 'is_multiclass', 'exp_name_log', 'log_plots_param', 'USI', 'target_param', 'y_test', 'fold_generator', '_available_plots', 'X', 'gpu_param', 'html_param', 'logging_param', 'n_jobs_param', 'y', 'X_train', 'memory'}
2024-09-05 18:27:54,468:INFO:Checking environment
2024-09-05 18:27:54,468:INFO:python_version: 3.10.11
2024-09-05 18:27:54,468:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-05 18:27:54,468:INFO:machine: AMD64
2024-09-05 18:27:54,468:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-05 18:27:54,468:INFO:Memory: svmem(total=17128263680, available=6480961536, percent=62.2, used=10647302144, free=6480961536)
2024-09-05 18:27:54,468:INFO:Physical Core: 6
2024-09-05 18:27:54,468:INFO:Logical Core: 12
2024-09-05 18:27:54,468:INFO:Checking libraries
2024-09-05 18:27:54,468:INFO:System:
2024-09-05 18:27:54,468:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-05 18:27:54,468:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-05 18:27:54,468:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-05 18:27:54,468:INFO:PyCaret required dependencies:
2024-09-05 18:27:54,498:INFO:                 pip: 24.2
2024-09-05 18:27:54,498:INFO:          setuptools: 72.1.0
2024-09-05 18:27:54,498:INFO:             pycaret: 3.3.2
2024-09-05 18:27:54,498:INFO:             IPython: 8.27.0
2024-09-05 18:27:54,498:INFO:          ipywidgets: 8.1.5
2024-09-05 18:27:54,498:INFO:                tqdm: 4.66.5
2024-09-05 18:27:54,498:INFO:               numpy: 1.26.4
2024-09-05 18:27:54,499:INFO:              pandas: 2.2.2
2024-09-05 18:27:54,499:INFO:              jinja2: 3.1.4
2024-09-05 18:27:54,499:INFO:               scipy: 1.11.4
2024-09-05 18:27:54,499:INFO:              joblib: 1.3.2
2024-09-05 18:27:54,499:INFO:             sklearn: 1.4.2
2024-09-05 18:27:54,499:INFO:                pyod: 2.0.1
2024-09-05 18:27:54,499:INFO:            imblearn: 0.12.3
2024-09-05 18:27:54,499:INFO:   category_encoders: 2.6.3
2024-09-05 18:27:54,499:INFO:            lightgbm: 4.5.0
2024-09-05 18:27:54,499:INFO:               numba: 0.60.0
2024-09-05 18:27:54,499:INFO:            requests: 2.32.3
2024-09-05 18:27:54,499:INFO:          matplotlib: 3.7.5
2024-09-05 18:27:54,499:INFO:          scikitplot: 0.3.7
2024-09-05 18:27:54,499:INFO:         yellowbrick: 1.5
2024-09-05 18:27:54,499:INFO:              plotly: 5.24.0
2024-09-05 18:27:54,499:INFO:    plotly-resampler: Not installed
2024-09-05 18:27:54,499:INFO:             kaleido: 0.2.1
2024-09-05 18:27:54,499:INFO:           schemdraw: 0.15
2024-09-05 18:27:54,499:INFO:         statsmodels: 0.14.2
2024-09-05 18:27:54,499:INFO:              sktime: 0.26.0
2024-09-05 18:27:54,499:INFO:               tbats: 1.1.3
2024-09-05 18:27:54,499:INFO:            pmdarima: 2.0.4
2024-09-05 18:27:54,499:INFO:              psutil: 6.0.0
2024-09-05 18:27:54,499:INFO:          markupsafe: 2.1.5
2024-09-05 18:27:54,500:INFO:             pickle5: Not installed
2024-09-05 18:27:54,500:INFO:         cloudpickle: 3.0.0
2024-09-05 18:27:54,500:INFO:         deprecation: 2.1.0
2024-09-05 18:27:54,500:INFO:              xxhash: 3.5.0
2024-09-05 18:27:54,500:INFO:           wurlitzer: Not installed
2024-09-05 18:27:54,500:INFO:PyCaret optional dependencies:
2024-09-05 18:27:54,501:INFO:                shap: Not installed
2024-09-05 18:27:54,501:INFO:           interpret: Not installed
2024-09-05 18:27:54,501:INFO:                umap: Not installed
2024-09-05 18:27:54,501:INFO:     ydata_profiling: Not installed
2024-09-05 18:27:54,501:INFO:  explainerdashboard: Not installed
2024-09-05 18:27:54,501:INFO:             autoviz: Not installed
2024-09-05 18:27:54,501:INFO:           fairlearn: Not installed
2024-09-05 18:27:54,501:INFO:          deepchecks: Not installed
2024-09-05 18:27:54,501:INFO:             xgboost: 2.1.1
2024-09-05 18:27:54,501:INFO:            catboost: Not installed
2024-09-05 18:27:54,501:INFO:              kmodes: Not installed
2024-09-05 18:27:54,501:INFO:             mlxtend: Not installed
2024-09-05 18:27:54,501:INFO:       statsforecast: Not installed
2024-09-05 18:27:54,501:INFO:        tune_sklearn: Not installed
2024-09-05 18:27:54,501:INFO:                 ray: Not installed
2024-09-05 18:27:54,501:INFO:            hyperopt: 0.2.7
2024-09-05 18:27:54,501:INFO:              optuna: 4.0.0
2024-09-05 18:27:54,501:INFO:               skopt: 0.10.2
2024-09-05 18:27:54,501:INFO:              mlflow: Not installed
2024-09-05 18:27:54,501:INFO:              gradio: Not installed
2024-09-05 18:27:54,501:INFO:             fastapi: Not installed
2024-09-05 18:27:54,501:INFO:             uvicorn: Not installed
2024-09-05 18:27:54,501:INFO:              m2cgen: Not installed
2024-09-05 18:27:54,501:INFO:           evidently: Not installed
2024-09-05 18:27:54,501:INFO:               fugue: Not installed
2024-09-05 18:27:54,501:INFO:           streamlit: Not installed
2024-09-05 18:27:54,501:INFO:             prophet: Not installed
2024-09-05 18:27:54,501:INFO:None
2024-09-05 18:27:54,501:INFO:Set up data.
2024-09-05 18:27:55,087:INFO:Set up folding strategy.
2024-09-05 18:27:55,087:INFO:Set up train/test split.
2024-09-05 18:27:55,788:INFO:Set up index.
2024-09-05 18:27:55,813:INFO:Assigning column types.
2024-09-05 18:27:56,599:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-05 18:27:56,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,661:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,693:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:56,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:56,739:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,771:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:56,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:56,771:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-05 18:27:56,828:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,859:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:56,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:56,906:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 18:27:56,937:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:56,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:56,937:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-05 18:27:57,016:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:57,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:57,109:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:27:57,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:27:57,109:INFO:Preparing preprocessing pipeline...
2024-09-05 18:27:57,234:INFO:Set up simple imputation.
2024-09-05 18:27:57,234:INFO:Set up imbalanced handling.
2024-09-05 18:27:58,961:INFO:Finished creating preprocessing pipeline.
2024-09-05 18:27:58,977:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-05 18:27:58,977:INFO:Creating final display dataframe.
2024-09-05 18:28:09,454:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 535)
4        Transformed data shape      (99147, 535)
5   Transformed train set shape      (76191, 535)
6    Transformed test set shape      (22956, 535)
7              Numeric features               534
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              6cee
2024-09-05 18:28:09,549:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:28:09,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:28:09,619:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 18:28:09,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 18:28:09,634:INFO:setup() successfully completed in 15.17s...............
2024-09-05 18:28:09,652:INFO:Initializing create_model()
2024-09-05 18:28:09,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 18:28:09,652:INFO:Checking exceptions
2024-09-05 18:28:09,670:INFO:Importing libraries
2024-09-05 18:28:09,670:INFO:Copying training dataset
2024-09-05 18:28:10,617:INFO:Defining folds
2024-09-05 18:28:10,617:INFO:Declaring metric variables
2024-09-05 18:28:10,621:INFO:Importing untrained model
2024-09-05 18:28:10,625:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 18:28:10,631:INFO:Starting cross validation
2024-09-05 18:28:10,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 18:31:24,475:INFO:Calculating mean and std
2024-09-05 18:31:24,506:INFO:Creating metrics dataframe
2024-09-05 18:31:24,549:INFO:Finalizing model
2024-09-05 18:31:30,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174011 seconds.
2024-09-05 18:31:30,265:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:31:30,281:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:31:42,244:INFO:Uploading results into container
2024-09-05 18:31:42,246:INFO:Uploading model into container now
2024-09-05 18:31:42,267:INFO:_master_model_container: 1
2024-09-05 18:31:42,267:INFO:_display_container: 2
2024-09-05 18:31:42,268:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 18:31:42,268:INFO:create_model() successfully completed......................................
2024-09-05 18:33:35,434:INFO:Initializing tune_model()
2024-09-05 18:33:35,434:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'min_child_samples': [50, 150, 200]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>)
2024-09-05 18:33:35,434:INFO:Checking exceptions
2024-09-05 18:33:35,435:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-05 18:33:36,039:INFO:Copying training dataset
2024-09-05 18:33:36,549:INFO:Checking base model
2024-09-05 18:33:36,549:INFO:Base model : Light Gradient Boosting Machine
2024-09-05 18:33:36,556:INFO:Declaring metric variables
2024-09-05 18:33:36,556:INFO:Defining Hyperparameters
2024-09-05 18:33:36,639:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[50, 150, 200])}
2024-09-05 18:33:36,639:INFO:Tuning with n_jobs=-1
2024-09-05 18:33:36,641:INFO:Initializing skopt.BayesSearchCV
2024-09-05 18:44:32,902:INFO:best_params: OrderedDict([('actual_estimator__max_depth', 5), ('actual_estimator__min_child_samples', 150), ('actual_estimator__n_estimators', 100)])
2024-09-05 18:44:32,902:INFO:Hyperparameter search completed
2024-09-05 18:44:32,902:INFO:SubProcess create_model() called ==================================
2024-09-05 18:44:32,918:INFO:Initializing create_model()
2024-09-05 18:44:32,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C6BE6D9600>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'max_depth': 5, 'min_child_samples': 150, 'n_estimators': 100})
2024-09-05 18:44:32,918:INFO:Checking exceptions
2024-09-05 18:44:32,918:INFO:Importing libraries
2024-09-05 18:44:32,918:INFO:Copying training dataset
2024-09-05 18:44:33,989:INFO:Defining folds
2024-09-05 18:44:33,989:INFO:Declaring metric variables
2024-09-05 18:44:33,989:INFO:Importing untrained model
2024-09-05 18:44:33,989:INFO:Declaring custom model
2024-09-05 18:44:34,007:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 18:44:34,017:INFO:Starting cross validation
2024-09-05 18:44:34,030:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 18:45:34,994:INFO:Calculating mean and std
2024-09-05 18:45:34,994:INFO:Creating metrics dataframe
2024-09-05 18:45:34,994:INFO:Finalizing model
2024-09-05 18:45:40,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163606 seconds.
2024-09-05 18:45:40,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 18:45:40,371:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 18:45:40,371:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 18:45:40,371:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:45:40,371:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:45:40,386:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:45:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:40,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:42,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:43,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:44,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:45,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:46,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 18:45:47,432:INFO:Uploading results into container
2024-09-05 18:45:47,432:INFO:Uploading model into container now
2024-09-05 18:45:47,448:INFO:_master_model_container: 2
2024-09-05 18:45:47,448:INFO:_display_container: 3
2024-09-05 18:45:47,448:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-09-05 18:45:47,448:INFO:create_model() successfully completed......................................
2024-09-05 18:45:47,661:INFO:SubProcess create_model() end ==================================
2024-09-05 18:45:47,661:INFO:choose_better activated
2024-09-05 18:45:47,661:INFO:SubProcess create_model() called ==================================
2024-09-05 18:45:47,661:INFO:Initializing create_model()
2024-09-05 18:45:47,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 18:45:47,661:INFO:Checking exceptions
2024-09-05 18:45:47,677:INFO:Importing libraries
2024-09-05 18:45:47,677:INFO:Copying training dataset
2024-09-05 18:45:48,569:INFO:Defining folds
2024-09-05 18:45:48,569:INFO:Declaring metric variables
2024-09-05 18:45:48,569:INFO:Importing untrained model
2024-09-05 18:45:48,569:INFO:Declaring custom model
2024-09-05 18:45:48,569:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 18:45:48,569:INFO:Starting cross validation
2024-09-05 18:45:48,569:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 18:47:31,765:INFO:Calculating mean and std
2024-09-05 18:47:31,765:INFO:Creating metrics dataframe
2024-09-05 18:47:31,765:INFO:Finalizing model
2024-09-05 18:47:37,138:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187903 seconds.
2024-09-05 18:47:37,138:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:47:37,153:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 18:47:48,169:INFO:Uploading results into container
2024-09-05 18:47:48,169:INFO:Uploading model into container now
2024-09-05 18:47:48,169:INFO:_master_model_container: 3
2024-09-05 18:47:48,169:INFO:_display_container: 4
2024-09-05 18:47:48,169:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 18:47:48,169:INFO:create_model() successfully completed......................................
2024-09-05 18:47:48,263:INFO:SubProcess create_model() end ==================================
2024-09-05 18:47:48,263:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8294
2024-09-05 18:47:48,263:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8284
2024-09-05 18:47:48,263:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-05 18:47:48,263:INFO:choose_better completed
2024-09-05 18:47:48,263:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-05 18:47:48,279:INFO:_master_model_container: 3
2024-09-05 18:47:48,279:INFO:_display_container: 3
2024-09-05 18:47:48,280:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 18:47:48,280:INFO:tune_model() successfully completed......................................
2024-09-05 18:47:48,393:INFO:Initializing plot_model()
2024-09-05 18:47:48,393:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C6BE8C4B80>, system=True)
2024-09-05 18:47:48,393:INFO:Checking exceptions
2024-09-05 18:47:48,732:INFO:Preloading libraries
2024-09-05 18:47:48,759:INFO:Copying training dataset
2024-09-05 18:47:48,759:INFO:Plot type: confusion_matrix
2024-09-05 18:47:51,451:INFO:Fitting Model
2024-09-05 18:47:51,451:INFO:Scoring test/hold-out set
2024-09-05 18:47:51,796:INFO:Visual Rendered Successfully
2024-09-05 18:47:51,878:INFO:plot_model() successfully completed......................................
2024-09-05 20:50:43,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 20:50:43,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 20:50:43,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 20:50:43,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-05 20:51:49,316:INFO:PyCaret ClassificationExperiment
2024-09-05 20:51:49,316:INFO:Logging name: clf-default-name
2024-09-05 20:51:49,316:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-05 20:51:49,316:INFO:version 3.3.2
2024-09-05 20:51:49,316:INFO:Initializing setup()
2024-09-05 20:51:49,316:INFO:self.USI: 692b
2024-09-05 20:51:49,316:INFO:self._variable_keys: {'USI', 'html_param', 'log_plots_param', '_available_plots', '_ml_usecase', 'seed', 'gpu_n_jobs_param', 'n_jobs_param', 'X', 'X_train', 'y', 'exp_name_log', 'X_test', 'logging_param', 'fold_groups_param', 'memory', 'gpu_param', 'idx', 'fix_imbalance', 'fold_generator', 'exp_id', 'target_param', 'fold_shuffle_param', 'data', 'pipeline', 'y_train', 'is_multiclass', 'y_test'}
2024-09-05 20:51:49,316:INFO:Checking environment
2024-09-05 20:51:49,316:INFO:python_version: 3.10.11
2024-09-05 20:51:49,316:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2024-09-05 20:51:49,316:INFO:machine: AMD64
2024-09-05 20:51:49,317:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-05 20:51:49,317:INFO:Memory: svmem(total=17128263680, available=5885304832, percent=65.6, used=11242958848, free=5885304832)
2024-09-05 20:51:49,317:INFO:Physical Core: 6
2024-09-05 20:51:49,317:INFO:Logical Core: 12
2024-09-05 20:51:49,317:INFO:Checking libraries
2024-09-05 20:51:49,317:INFO:System:
2024-09-05 20:51:49,317:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2024-09-05 20:51:49,317:INFO:executable: C:\Users\jesco\anaconda3\envs\my_env\python.exe
2024-09-05 20:51:49,317:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-05 20:51:49,317:INFO:PyCaret required dependencies:
2024-09-05 20:51:49,352:INFO:                 pip: 24.2
2024-09-05 20:51:49,352:INFO:          setuptools: 72.1.0
2024-09-05 20:51:49,353:INFO:             pycaret: 3.3.2
2024-09-05 20:51:49,353:INFO:             IPython: 8.27.0
2024-09-05 20:51:49,353:INFO:          ipywidgets: 8.1.5
2024-09-05 20:51:49,353:INFO:                tqdm: 4.66.5
2024-09-05 20:51:49,353:INFO:               numpy: 1.26.4
2024-09-05 20:51:49,353:INFO:              pandas: 2.2.2
2024-09-05 20:51:49,353:INFO:              jinja2: 3.1.4
2024-09-05 20:51:49,353:INFO:               scipy: 1.11.4
2024-09-05 20:51:49,353:INFO:              joblib: 1.3.2
2024-09-05 20:51:49,353:INFO:             sklearn: 1.4.2
2024-09-05 20:51:49,353:INFO:                pyod: 2.0.1
2024-09-05 20:51:49,353:INFO:            imblearn: 0.12.3
2024-09-05 20:51:49,353:INFO:   category_encoders: 2.6.3
2024-09-05 20:51:49,353:INFO:            lightgbm: 4.5.0
2024-09-05 20:51:49,353:INFO:               numba: 0.60.0
2024-09-05 20:51:49,353:INFO:            requests: 2.32.3
2024-09-05 20:51:49,353:INFO:          matplotlib: 3.7.5
2024-09-05 20:51:49,353:INFO:          scikitplot: 0.3.7
2024-09-05 20:51:49,353:INFO:         yellowbrick: 1.5
2024-09-05 20:51:49,353:INFO:              plotly: 5.24.0
2024-09-05 20:51:49,353:INFO:    plotly-resampler: Not installed
2024-09-05 20:51:49,353:INFO:             kaleido: 0.2.1
2024-09-05 20:51:49,353:INFO:           schemdraw: 0.15
2024-09-05 20:51:49,354:INFO:         statsmodels: 0.14.2
2024-09-05 20:51:49,354:INFO:              sktime: 0.26.0
2024-09-05 20:51:49,354:INFO:               tbats: 1.1.3
2024-09-05 20:51:49,354:INFO:            pmdarima: 2.0.4
2024-09-05 20:51:49,354:INFO:              psutil: 6.0.0
2024-09-05 20:51:49,354:INFO:          markupsafe: 2.1.5
2024-09-05 20:51:49,354:INFO:             pickle5: Not installed
2024-09-05 20:51:49,354:INFO:         cloudpickle: 3.0.0
2024-09-05 20:51:49,354:INFO:         deprecation: 2.1.0
2024-09-05 20:51:49,354:INFO:              xxhash: 3.5.0
2024-09-05 20:51:49,354:INFO:           wurlitzer: Not installed
2024-09-05 20:51:49,354:INFO:PyCaret optional dependencies:
2024-09-05 20:51:49,372:INFO:                shap: Not installed
2024-09-05 20:51:49,372:INFO:           interpret: Not installed
2024-09-05 20:51:49,372:INFO:                umap: Not installed
2024-09-05 20:51:49,372:INFO:     ydata_profiling: Not installed
2024-09-05 20:51:49,372:INFO:  explainerdashboard: Not installed
2024-09-05 20:51:49,372:INFO:             autoviz: Not installed
2024-09-05 20:51:49,372:INFO:           fairlearn: Not installed
2024-09-05 20:51:49,372:INFO:          deepchecks: Not installed
2024-09-05 20:51:49,372:INFO:             xgboost: 2.1.1
2024-09-05 20:51:49,372:INFO:            catboost: Not installed
2024-09-05 20:51:49,372:INFO:              kmodes: Not installed
2024-09-05 20:51:49,373:INFO:             mlxtend: Not installed
2024-09-05 20:51:49,373:INFO:       statsforecast: Not installed
2024-09-05 20:51:49,373:INFO:        tune_sklearn: Not installed
2024-09-05 20:51:49,373:INFO:                 ray: Not installed
2024-09-05 20:51:49,373:INFO:            hyperopt: 0.2.7
2024-09-05 20:51:49,373:INFO:              optuna: 4.0.0
2024-09-05 20:51:49,373:INFO:               skopt: 0.10.2
2024-09-05 20:51:49,373:INFO:              mlflow: Not installed
2024-09-05 20:51:49,373:INFO:              gradio: Not installed
2024-09-05 20:51:49,373:INFO:             fastapi: Not installed
2024-09-05 20:51:49,374:INFO:             uvicorn: Not installed
2024-09-05 20:51:49,374:INFO:              m2cgen: Not installed
2024-09-05 20:51:49,374:INFO:           evidently: Not installed
2024-09-05 20:51:49,374:INFO:               fugue: Not installed
2024-09-05 20:51:49,374:INFO:           streamlit: Not installed
2024-09-05 20:51:49,374:INFO:             prophet: Not installed
2024-09-05 20:51:49,374:INFO:None
2024-09-05 20:51:49,374:INFO:Set up data.
2024-09-05 20:51:50,049:INFO:Set up folding strategy.
2024-09-05 20:51:50,049:INFO:Set up train/test split.
2024-09-05 20:51:51,051:INFO:Set up index.
2024-09-05 20:51:51,077:INFO:Assigning column types.
2024-09-05 20:51:51,984:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-05 20:51:52,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,096:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,154:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,186:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,190:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-05 20:51:52,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,285:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,340:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-05 20:51:52,380:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,384:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-05 20:51:52,476:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,563:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:52,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:52,569:INFO:Preparing preprocessing pipeline...
2024-09-05 20:51:52,750:INFO:Set up simple imputation.
2024-09-05 20:51:52,750:INFO:Set up imbalanced handling.
2024-09-05 20:51:53,999:INFO:Finished creating preprocessing pipeline.
2024-09-05 20:51:54,017:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jesco\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-09-05 20:51:54,017:INFO:Creating final display dataframe.
2024-09-05 20:51:58,411:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Target
2                   Target type        Multiclass
3           Original data shape      (76518, 535)
4        Transformed data shape      (99147, 535)
5   Transformed train set shape      (76191, 535)
6    Transformed test set shape      (22956, 535)
7              Numeric features               534
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              692b
2024-09-05 20:51:58,510:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:58,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:58,607:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-05 20:51:58,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-05 20:51:58,612:INFO:setup() successfully completed in 9.3s...............
2024-09-05 20:51:58,620:INFO:Initializing compare_models()
2024-09-05 20:51:58,620:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-05 20:51:58,620:INFO:Checking exceptions
2024-09-05 20:51:59,411:INFO:Preparing display monitor
2024-09-05 20:51:59,445:INFO:Initializing Logistic Regression
2024-09-05 20:51:59,445:INFO:Total runtime is 0.0 minutes
2024-09-05 20:51:59,451:INFO:SubProcess create_model() called ==================================
2024-09-05 20:51:59,452:INFO:Initializing create_model()
2024-09-05 20:51:59,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 20:51:59,452:INFO:Checking exceptions
2024-09-05 20:51:59,452:INFO:Importing libraries
2024-09-05 20:51:59,452:INFO:Copying training dataset
2024-09-05 20:52:00,579:INFO:Defining folds
2024-09-05 20:52:00,580:INFO:Declaring metric variables
2024-09-05 20:52:00,584:INFO:Importing untrained model
2024-09-05 20:52:00,589:INFO:Logistic Regression Imported successfully
2024-09-05 20:52:00,598:INFO:Starting cross validation
2024-09-05 20:52:00,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 20:56:35,256:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:56:55,862:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:56:56,902:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:56:57,058:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:02,414:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:09,214:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:10,393:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:17,422:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:27,032:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:30,200:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 20:57:30,275:INFO:Calculating mean and std
2024-09-05 20:57:30,284:INFO:Creating metrics dataframe
2024-09-05 20:57:30,298:INFO:Uploading results into container
2024-09-05 20:57:30,300:INFO:Uploading model into container now
2024-09-05 20:57:30,303:INFO:_master_model_container: 1
2024-09-05 20:57:30,303:INFO:_display_container: 2
2024-09-05 20:57:30,306:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-05 20:57:30,307:INFO:create_model() successfully completed......................................
2024-09-05 20:57:30,518:INFO:SubProcess create_model() end ==================================
2024-09-05 20:57:30,518:INFO:Creating metrics dataframe
2024-09-05 20:57:30,527:INFO:Initializing K Neighbors Classifier
2024-09-05 20:57:30,528:INFO:Total runtime is 5.51804279088974 minutes
2024-09-05 20:57:30,531:INFO:SubProcess create_model() called ==================================
2024-09-05 20:57:30,531:INFO:Initializing create_model()
2024-09-05 20:57:30,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 20:57:30,532:INFO:Checking exceptions
2024-09-05 20:57:30,532:INFO:Importing libraries
2024-09-05 20:57:30,532:INFO:Copying training dataset
2024-09-05 20:57:31,475:INFO:Defining folds
2024-09-05 20:57:31,476:INFO:Declaring metric variables
2024-09-05 20:57:31,480:INFO:Importing untrained model
2024-09-05 20:57:31,485:INFO:K Neighbors Classifier Imported successfully
2024-09-05 20:57:31,492:INFO:Starting cross validation
2024-09-05 20:57:31,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 20:58:46,354:INFO:Calculating mean and std
2024-09-05 20:58:46,356:INFO:Creating metrics dataframe
2024-09-05 20:58:46,359:INFO:Uploading results into container
2024-09-05 20:58:46,359:INFO:Uploading model into container now
2024-09-05 20:58:46,360:INFO:_master_model_container: 2
2024-09-05 20:58:46,360:INFO:_display_container: 2
2024-09-05 20:58:46,360:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-05 20:58:46,361:INFO:create_model() successfully completed......................................
2024-09-05 20:58:46,482:INFO:SubProcess create_model() end ==================================
2024-09-05 20:58:46,483:INFO:Creating metrics dataframe
2024-09-05 20:58:46,492:INFO:Initializing Naive Bayes
2024-09-05 20:58:46,493:INFO:Total runtime is 6.784119780858358 minutes
2024-09-05 20:58:46,497:INFO:SubProcess create_model() called ==================================
2024-09-05 20:58:46,497:INFO:Initializing create_model()
2024-09-05 20:58:46,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 20:58:46,497:INFO:Checking exceptions
2024-09-05 20:58:46,498:INFO:Importing libraries
2024-09-05 20:58:46,498:INFO:Copying training dataset
2024-09-05 20:58:47,426:INFO:Defining folds
2024-09-05 20:58:47,426:INFO:Declaring metric variables
2024-09-05 20:58:47,430:INFO:Importing untrained model
2024-09-05 20:58:47,433:INFO:Naive Bayes Imported successfully
2024-09-05 20:58:47,442:INFO:Starting cross validation
2024-09-05 20:58:47,446:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 20:59:21,690:INFO:Calculating mean and std
2024-09-05 20:59:21,691:INFO:Creating metrics dataframe
2024-09-05 20:59:21,693:INFO:Uploading results into container
2024-09-05 20:59:21,694:INFO:Uploading model into container now
2024-09-05 20:59:21,695:INFO:_master_model_container: 3
2024-09-05 20:59:21,695:INFO:_display_container: 2
2024-09-05 20:59:21,695:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-05 20:59:21,695:INFO:create_model() successfully completed......................................
2024-09-05 20:59:21,813:INFO:SubProcess create_model() end ==================================
2024-09-05 20:59:21,813:INFO:Creating metrics dataframe
2024-09-05 20:59:21,823:INFO:Initializing Decision Tree Classifier
2024-09-05 20:59:21,823:INFO:Total runtime is 7.372954535484315 minutes
2024-09-05 20:59:21,829:INFO:SubProcess create_model() called ==================================
2024-09-05 20:59:21,829:INFO:Initializing create_model()
2024-09-05 20:59:21,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 20:59:21,829:INFO:Checking exceptions
2024-09-05 20:59:21,830:INFO:Importing libraries
2024-09-05 20:59:21,830:INFO:Copying training dataset
2024-09-05 20:59:22,806:INFO:Defining folds
2024-09-05 20:59:22,806:INFO:Declaring metric variables
2024-09-05 20:59:22,811:INFO:Importing untrained model
2024-09-05 20:59:22,817:INFO:Decision Tree Classifier Imported successfully
2024-09-05 20:59:22,827:INFO:Starting cross validation
2024-09-05 20:59:22,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:01:04,362:INFO:Calculating mean and std
2024-09-05 21:01:04,363:INFO:Creating metrics dataframe
2024-09-05 21:01:04,365:INFO:Uploading results into container
2024-09-05 21:01:04,366:INFO:Uploading model into container now
2024-09-05 21:01:04,366:INFO:_master_model_container: 4
2024-09-05 21:01:04,367:INFO:_display_container: 2
2024-09-05 21:01:04,367:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-05 21:01:04,367:INFO:create_model() successfully completed......................................
2024-09-05 21:01:04,463:INFO:SubProcess create_model() end ==================================
2024-09-05 21:01:04,463:INFO:Creating metrics dataframe
2024-09-05 21:01:04,471:INFO:Initializing SVM - Linear Kernel
2024-09-05 21:01:04,471:INFO:Total runtime is 9.083764763673148 minutes
2024-09-05 21:01:04,474:INFO:SubProcess create_model() called ==================================
2024-09-05 21:01:04,474:INFO:Initializing create_model()
2024-09-05 21:01:04,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:01:04,475:INFO:Checking exceptions
2024-09-05 21:01:04,475:INFO:Importing libraries
2024-09-05 21:01:04,475:INFO:Copying training dataset
2024-09-05 21:01:05,365:INFO:Defining folds
2024-09-05 21:01:05,365:INFO:Declaring metric variables
2024-09-05 21:01:05,369:INFO:Importing untrained model
2024-09-05 21:01:05,374:INFO:SVM - Linear Kernel Imported successfully
2024-09-05 21:01:05,384:INFO:Starting cross validation
2024-09-05 21:01:05,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:01:53,773:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:02,546:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:02,625:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:02,661:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:02,883:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:03,355:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:04,915:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:05,078:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:05,663:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:06,430:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:06,472:INFO:Calculating mean and std
2024-09-05 21:02:06,474:INFO:Creating metrics dataframe
2024-09-05 21:02:06,477:INFO:Uploading results into container
2024-09-05 21:02:06,478:INFO:Uploading model into container now
2024-09-05 21:02:06,478:INFO:_master_model_container: 5
2024-09-05 21:02:06,479:INFO:_display_container: 2
2024-09-05 21:02:06,479:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-05 21:02:06,480:INFO:create_model() successfully completed......................................
2024-09-05 21:02:06,587:INFO:SubProcess create_model() end ==================================
2024-09-05 21:02:06,587:INFO:Creating metrics dataframe
2024-09-05 21:02:06,600:INFO:Initializing Ridge Classifier
2024-09-05 21:02:06,600:INFO:Total runtime is 10.119242489337923 minutes
2024-09-05 21:02:06,604:INFO:SubProcess create_model() called ==================================
2024-09-05 21:02:06,605:INFO:Initializing create_model()
2024-09-05 21:02:06,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:02:06,605:INFO:Checking exceptions
2024-09-05 21:02:06,605:INFO:Importing libraries
2024-09-05 21:02:06,605:INFO:Copying training dataset
2024-09-05 21:02:07,553:INFO:Defining folds
2024-09-05 21:02:07,553:INFO:Declaring metric variables
2024-09-05 21:02:07,557:INFO:Importing untrained model
2024-09-05 21:02:07,562:INFO:Ridge Classifier Imported successfully
2024-09-05 21:02:07,571:INFO:Starting cross validation
2024-09-05 21:02:07,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:02:27,233:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:29,750:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:30,764:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:34,998:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:35,968:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:36,307:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:36,429:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:38,279:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:38,351:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:39,391:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:02:39,430:INFO:Calculating mean and std
2024-09-05 21:02:39,432:INFO:Creating metrics dataframe
2024-09-05 21:02:39,434:INFO:Uploading results into container
2024-09-05 21:02:39,435:INFO:Uploading model into container now
2024-09-05 21:02:39,436:INFO:_master_model_container: 6
2024-09-05 21:02:39,436:INFO:_display_container: 2
2024-09-05 21:02:39,437:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-05 21:02:39,437:INFO:create_model() successfully completed......................................
2024-09-05 21:02:39,561:INFO:SubProcess create_model() end ==================================
2024-09-05 21:02:39,561:INFO:Creating metrics dataframe
2024-09-05 21:02:39,573:INFO:Initializing Random Forest Classifier
2024-09-05 21:02:39,573:INFO:Total runtime is 10.668787733713788 minutes
2024-09-05 21:02:39,578:INFO:SubProcess create_model() called ==================================
2024-09-05 21:02:39,578:INFO:Initializing create_model()
2024-09-05 21:02:39,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:02:39,579:INFO:Checking exceptions
2024-09-05 21:02:39,579:INFO:Importing libraries
2024-09-05 21:02:39,579:INFO:Copying training dataset
2024-09-05 21:02:40,528:INFO:Defining folds
2024-09-05 21:02:40,528:INFO:Declaring metric variables
2024-09-05 21:02:40,532:INFO:Importing untrained model
2024-09-05 21:02:40,537:INFO:Random Forest Classifier Imported successfully
2024-09-05 21:02:40,549:INFO:Starting cross validation
2024-09-05 21:02:40,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:05:07,896:INFO:Calculating mean and std
2024-09-05 21:05:07,898:INFO:Creating metrics dataframe
2024-09-05 21:05:07,900:INFO:Uploading results into container
2024-09-05 21:05:07,901:INFO:Uploading model into container now
2024-09-05 21:05:07,902:INFO:_master_model_container: 7
2024-09-05 21:05:07,902:INFO:_display_container: 2
2024-09-05 21:05:07,903:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-05 21:05:07,903:INFO:create_model() successfully completed......................................
2024-09-05 21:05:08,042:INFO:SubProcess create_model() end ==================================
2024-09-05 21:05:08,042:INFO:Creating metrics dataframe
2024-09-05 21:05:08,061:INFO:Initializing Quadratic Discriminant Analysis
2024-09-05 21:05:08,061:INFO:Total runtime is 13.143596621354423 minutes
2024-09-05 21:05:08,067:INFO:SubProcess create_model() called ==================================
2024-09-05 21:05:08,067:INFO:Initializing create_model()
2024-09-05 21:05:08,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:05:08,069:INFO:Checking exceptions
2024-09-05 21:05:08,069:INFO:Importing libraries
2024-09-05 21:05:08,069:INFO:Copying training dataset
2024-09-05 21:05:09,354:INFO:Defining folds
2024-09-05 21:05:09,354:INFO:Declaring metric variables
2024-09-05 21:05:09,360:INFO:Importing untrained model
2024-09-05 21:05:09,367:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-05 21:05:09,379:INFO:Starting cross validation
2024-09-05 21:05:09,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:05:36,790:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:39,707:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:46,436:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:46,747:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:47,817:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:47,886:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:48,065:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:49,794:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:05:51,788:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:05:53,738:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:05:56,497:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:05:58,265:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:05:59,119:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:01,266:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:01,585:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:06:01,662:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-05 21:06:01,689:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:02,235:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:07,191:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:07,199:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:06:07,237:INFO:Calculating mean and std
2024-09-05 21:06:07,240:INFO:Creating metrics dataframe
2024-09-05 21:06:07,246:INFO:Uploading results into container
2024-09-05 21:06:07,249:INFO:Uploading model into container now
2024-09-05 21:06:07,250:INFO:_master_model_container: 8
2024-09-05 21:06:07,251:INFO:_display_container: 2
2024-09-05 21:06:07,251:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-05 21:06:07,251:INFO:create_model() successfully completed......................................
2024-09-05 21:06:07,413:INFO:SubProcess create_model() end ==================================
2024-09-05 21:06:07,413:INFO:Creating metrics dataframe
2024-09-05 21:06:07,430:INFO:Initializing Ada Boost Classifier
2024-09-05 21:06:07,431:INFO:Total runtime is 14.133069785435996 minutes
2024-09-05 21:06:07,435:INFO:SubProcess create_model() called ==================================
2024-09-05 21:06:07,435:INFO:Initializing create_model()
2024-09-05 21:06:07,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:06:07,436:INFO:Checking exceptions
2024-09-05 21:06:07,436:INFO:Importing libraries
2024-09-05 21:06:07,437:INFO:Copying training dataset
2024-09-05 21:06:08,652:INFO:Defining folds
2024-09-05 21:06:08,652:INFO:Declaring metric variables
2024-09-05 21:06:08,657:INFO:Importing untrained model
2024-09-05 21:06:08,661:INFO:Ada Boost Classifier Imported successfully
2024-09-05 21:06:08,672:INFO:Starting cross validation
2024-09-05 21:06:08,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:06:31,914:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:34,571:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:35,019:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:35,352:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:36,260:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:36,594:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:37,869:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:38,346:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:41,985:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:06:44,598:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-05 21:08:35,284:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:37,002:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:37,551:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:44,194:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:47,336:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:49,140:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:08:52,834:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:09:12,403:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:09:16,811:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:09:20,980:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:09:21,020:INFO:Calculating mean and std
2024-09-05 21:09:21,022:INFO:Creating metrics dataframe
2024-09-05 21:09:21,026:INFO:Uploading results into container
2024-09-05 21:09:21,027:INFO:Uploading model into container now
2024-09-05 21:09:21,027:INFO:_master_model_container: 9
2024-09-05 21:09:21,027:INFO:_display_container: 2
2024-09-05 21:09:21,028:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-05 21:09:21,028:INFO:create_model() successfully completed......................................
2024-09-05 21:09:21,139:INFO:SubProcess create_model() end ==================================
2024-09-05 21:09:21,139:INFO:Creating metrics dataframe
2024-09-05 21:09:21,151:INFO:Initializing Gradient Boosting Classifier
2024-09-05 21:09:21,151:INFO:Total runtime is 17.361753463745117 minutes
2024-09-05 21:09:21,156:INFO:SubProcess create_model() called ==================================
2024-09-05 21:09:21,157:INFO:Initializing create_model()
2024-09-05 21:09:21,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:09:21,157:INFO:Checking exceptions
2024-09-05 21:09:21,157:INFO:Importing libraries
2024-09-05 21:09:21,157:INFO:Copying training dataset
2024-09-05 21:09:22,301:INFO:Defining folds
2024-09-05 21:09:22,301:INFO:Declaring metric variables
2024-09-05 21:09:22,307:INFO:Importing untrained model
2024-09-05 21:09:22,313:INFO:Gradient Boosting Classifier Imported successfully
2024-09-05 21:09:22,324:INFO:Starting cross validation
2024-09-05 21:09:22,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:42:59,599:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:07,801:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:27,915:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:35,803:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:44,464:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:43:59,314:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:45:08,024:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:45:08,143:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:45:30,467:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:03,518:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:03,601:INFO:Calculating mean and std
2024-09-05 21:46:03,625:INFO:Creating metrics dataframe
2024-09-05 21:46:03,654:INFO:Uploading results into container
2024-09-05 21:46:03,655:INFO:Uploading model into container now
2024-09-05 21:46:03,662:INFO:_master_model_container: 10
2024-09-05 21:46:03,662:INFO:_display_container: 2
2024-09-05 21:46:03,668:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-05 21:46:03,669:INFO:create_model() successfully completed......................................
2024-09-05 21:46:03,947:INFO:SubProcess create_model() end ==================================
2024-09-05 21:46:03,947:INFO:Creating metrics dataframe
2024-09-05 21:46:03,959:INFO:Initializing Linear Discriminant Analysis
2024-09-05 21:46:03,959:INFO:Total runtime is 54.07522857586543 minutes
2024-09-05 21:46:03,963:INFO:SubProcess create_model() called ==================================
2024-09-05 21:46:03,963:INFO:Initializing create_model()
2024-09-05 21:46:03,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:46:03,964:INFO:Checking exceptions
2024-09-05 21:46:03,964:INFO:Importing libraries
2024-09-05 21:46:03,964:INFO:Copying training dataset
2024-09-05 21:46:05,120:INFO:Defining folds
2024-09-05 21:46:05,120:INFO:Declaring metric variables
2024-09-05 21:46:05,123:INFO:Importing untrained model
2024-09-05 21:46:05,127:INFO:Linear Discriminant Analysis Imported successfully
2024-09-05 21:46:05,134:INFO:Starting cross validation
2024-09-05 21:46:05,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:46:32,490:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:32,531:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:34,507:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:37,366:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:38,959:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:38,963:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:39,121:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:40,500:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:40,817:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:40,970:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-05 21:46:40,989:INFO:Calculating mean and std
2024-09-05 21:46:40,991:INFO:Creating metrics dataframe
2024-09-05 21:46:40,996:INFO:Uploading results into container
2024-09-05 21:46:40,999:INFO:Uploading model into container now
2024-09-05 21:46:41,000:INFO:_master_model_container: 11
2024-09-05 21:46:41,000:INFO:_display_container: 2
2024-09-05 21:46:41,001:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-05 21:46:41,001:INFO:create_model() successfully completed......................................
2024-09-05 21:46:41,113:INFO:SubProcess create_model() end ==================================
2024-09-05 21:46:41,113:INFO:Creating metrics dataframe
2024-09-05 21:46:41,130:INFO:Initializing Extra Trees Classifier
2024-09-05 21:46:41,130:INFO:Total runtime is 54.694747010866806 minutes
2024-09-05 21:46:41,135:INFO:SubProcess create_model() called ==================================
2024-09-05 21:46:41,135:INFO:Initializing create_model()
2024-09-05 21:46:41,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:46:41,136:INFO:Checking exceptions
2024-09-05 21:46:41,136:INFO:Importing libraries
2024-09-05 21:46:41,137:INFO:Copying training dataset
2024-09-05 21:46:41,980:INFO:Defining folds
2024-09-05 21:46:41,981:INFO:Declaring metric variables
2024-09-05 21:46:41,984:INFO:Importing untrained model
2024-09-05 21:46:41,988:INFO:Extra Trees Classifier Imported successfully
2024-09-05 21:46:41,996:INFO:Starting cross validation
2024-09-05 21:46:42,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:48:27,938:INFO:Calculating mean and std
2024-09-05 21:48:27,939:INFO:Creating metrics dataframe
2024-09-05 21:48:27,942:INFO:Uploading results into container
2024-09-05 21:48:27,943:INFO:Uploading model into container now
2024-09-05 21:48:27,944:INFO:_master_model_container: 12
2024-09-05 21:48:27,944:INFO:_display_container: 2
2024-09-05 21:48:27,945:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-05 21:48:27,945:INFO:create_model() successfully completed......................................
2024-09-05 21:48:28,064:INFO:SubProcess create_model() end ==================================
2024-09-05 21:48:28,064:INFO:Creating metrics dataframe
2024-09-05 21:48:28,079:INFO:Initializing Extreme Gradient Boosting
2024-09-05 21:48:28,079:INFO:Total runtime is 56.47722209294638 minutes
2024-09-05 21:48:28,083:INFO:SubProcess create_model() called ==================================
2024-09-05 21:48:28,083:INFO:Initializing create_model()
2024-09-05 21:48:28,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:48:28,084:INFO:Checking exceptions
2024-09-05 21:48:28,084:INFO:Importing libraries
2024-09-05 21:48:28,084:INFO:Copying training dataset
2024-09-05 21:48:29,079:INFO:Defining folds
2024-09-05 21:48:29,079:INFO:Declaring metric variables
2024-09-05 21:48:29,087:INFO:Importing untrained model
2024-09-05 21:48:29,094:INFO:Extreme Gradient Boosting Imported successfully
2024-09-05 21:48:29,107:INFO:Starting cross validation
2024-09-05 21:48:29,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:50:16,785:INFO:Calculating mean and std
2024-09-05 21:50:16,787:INFO:Creating metrics dataframe
2024-09-05 21:50:16,788:INFO:Uploading results into container
2024-09-05 21:50:16,789:INFO:Uploading model into container now
2024-09-05 21:50:16,789:INFO:_master_model_container: 13
2024-09-05 21:50:16,789:INFO:_display_container: 2
2024-09-05 21:50:16,790:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-05 21:50:16,791:INFO:create_model() successfully completed......................................
2024-09-05 21:50:16,885:INFO:SubProcess create_model() end ==================================
2024-09-05 21:50:16,885:INFO:Creating metrics dataframe
2024-09-05 21:50:16,900:INFO:Initializing Light Gradient Boosting Machine
2024-09-05 21:50:16,900:INFO:Total runtime is 58.29090755780538 minutes
2024-09-05 21:50:16,904:INFO:SubProcess create_model() called ==================================
2024-09-05 21:50:16,904:INFO:Initializing create_model()
2024-09-05 21:50:16,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:50:16,905:INFO:Checking exceptions
2024-09-05 21:50:16,905:INFO:Importing libraries
2024-09-05 21:50:16,905:INFO:Copying training dataset
2024-09-05 21:50:17,716:INFO:Defining folds
2024-09-05 21:50:17,716:INFO:Declaring metric variables
2024-09-05 21:50:17,721:INFO:Importing untrained model
2024-09-05 21:50:17,725:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 21:50:17,732:INFO:Starting cross validation
2024-09-05 21:50:17,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:53:34,946:INFO:Calculating mean and std
2024-09-05 21:53:34,948:INFO:Creating metrics dataframe
2024-09-05 21:53:34,951:INFO:Uploading results into container
2024-09-05 21:53:34,952:INFO:Uploading model into container now
2024-09-05 21:53:34,953:INFO:_master_model_container: 14
2024-09-05 21:53:34,953:INFO:_display_container: 2
2024-09-05 21:53:34,954:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 21:53:34,954:INFO:create_model() successfully completed......................................
2024-09-05 21:53:35,131:INFO:SubProcess create_model() end ==================================
2024-09-05 21:53:35,131:INFO:Creating metrics dataframe
2024-09-05 21:53:35,153:INFO:Initializing Dummy Classifier
2024-09-05 21:53:35,153:INFO:Total runtime is 61.595125134785974 minutes
2024-09-05 21:53:35,161:INFO:SubProcess create_model() called ==================================
2024-09-05 21:53:35,161:INFO:Initializing create_model()
2024-09-05 21:53:35,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A770070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:53:35,161:INFO:Checking exceptions
2024-09-05 21:53:35,161:INFO:Importing libraries
2024-09-05 21:53:35,161:INFO:Copying training dataset
2024-09-05 21:53:36,178:INFO:Defining folds
2024-09-05 21:53:36,178:INFO:Declaring metric variables
2024-09-05 21:53:36,183:INFO:Importing untrained model
2024-09-05 21:53:36,188:INFO:Dummy Classifier Imported successfully
2024-09-05 21:53:36,197:INFO:Starting cross validation
2024-09-05 21:53:36,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 21:53:55,693:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:56,231:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:56,233:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:56,897:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:57,164:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:57,772:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:57,974:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:58,335:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:58,603:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:58,670:WARNING:C:\Users\jesco\anaconda3\envs\my_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-05 21:53:58,687:INFO:Calculating mean and std
2024-09-05 21:53:58,688:INFO:Creating metrics dataframe
2024-09-05 21:53:58,690:INFO:Uploading results into container
2024-09-05 21:53:58,690:INFO:Uploading model into container now
2024-09-05 21:53:58,692:INFO:_master_model_container: 15
2024-09-05 21:53:58,692:INFO:_display_container: 2
2024-09-05 21:53:58,692:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-05 21:53:58,692:INFO:create_model() successfully completed......................................
2024-09-05 21:53:58,779:INFO:SubProcess create_model() end ==================================
2024-09-05 21:53:58,779:INFO:Creating metrics dataframe
2024-09-05 21:53:58,803:INFO:Initializing create_model()
2024-09-05 21:53:58,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 21:53:58,804:INFO:Checking exceptions
2024-09-05 21:53:58,807:INFO:Importing libraries
2024-09-05 21:53:58,807:INFO:Copying training dataset
2024-09-05 21:53:59,572:INFO:Defining folds
2024-09-05 21:53:59,572:INFO:Declaring metric variables
2024-09-05 21:53:59,572:INFO:Importing untrained model
2024-09-05 21:53:59,572:INFO:Declaring custom model
2024-09-05 21:53:59,573:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 21:53:59,576:INFO:Cross validation set to False
2024-09-05 21:53:59,576:INFO:Fitting Model
2024-09-05 21:54:04,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174350 seconds.
2024-09-05 21:54:04,894:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 21:54:04,903:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 21:54:04,908:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 21:54:04,912:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 21:54:04,912:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 21:54:04,912:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 21:54:15,335:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 21:54:15,335:INFO:create_model() successfully completed......................................
2024-09-05 21:54:15,468:INFO:_master_model_container: 15
2024-09-05 21:54:15,468:INFO:_display_container: 2
2024-09-05 21:54:15,469:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 21:54:15,469:INFO:compare_models() successfully completed......................................
2024-09-05 22:00:26,204:INFO:Initializing create_model()
2024-09-05 22:00:26,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 22:00:26,204:INFO:Checking exceptions
2024-09-05 22:00:26,220:INFO:Importing libraries
2024-09-05 22:00:26,220:INFO:Copying training dataset
2024-09-05 22:00:27,024:INFO:Defining folds
2024-09-05 22:00:27,024:INFO:Declaring metric variables
2024-09-05 22:00:27,028:INFO:Importing untrained model
2024-09-05 22:00:27,032:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 22:00:27,040:INFO:Starting cross validation
2024-09-05 22:00:27,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 22:03:16,125:INFO:Calculating mean and std
2024-09-05 22:03:16,154:INFO:Creating metrics dataframe
2024-09-05 22:03:16,199:INFO:Finalizing model
2024-09-05 22:03:21,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167547 seconds.
2024-09-05 22:03:21,874:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 22:03:21,884:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 22:03:21,889:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 22:03:21,892:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:03:21,892:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:03:21,892:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:03:34,474:INFO:Uploading results into container
2024-09-05 22:03:34,475:INFO:Uploading model into container now
2024-09-05 22:03:34,513:INFO:_master_model_container: 16
2024-09-05 22:03:34,514:INFO:_display_container: 3
2024-09-05 22:03:34,514:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:03:34,515:INFO:create_model() successfully completed......................................
2024-09-05 22:10:15,075:INFO:Initializing tune_model()
2024-09-05 22:10:15,075:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid={'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'min_child_samples': [50, 150, 200]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>)
2024-09-05 22:10:15,075:INFO:Checking exceptions
2024-09-05 22:10:15,075:INFO:Soft dependency imported: skopt: 0.10.2
2024-09-05 22:10:15,556:INFO:Copying training dataset
2024-09-05 22:10:16,014:INFO:Checking base model
2024-09-05 22:10:16,014:INFO:Base model : Light Gradient Boosting Machine
2024-09-05 22:10:16,018:INFO:Declaring metric variables
2024-09-05 22:10:16,021:INFO:Defining Hyperparameters
2024-09-05 22:10:16,101:INFO:custom_grid: {'actual_estimator__n_estimators': CategoricalDistribution(values=[50, 100, 200]), 'actual_estimator__max_depth': CategoricalDistribution(values=[3, 5, 7]), 'actual_estimator__min_child_samples': CategoricalDistribution(values=[50, 150, 200])}
2024-09-05 22:10:16,101:INFO:Tuning with n_jobs=-1
2024-09-05 22:10:16,104:INFO:Initializing skopt.BayesSearchCV
2024-09-05 22:22:52,399:INFO:best_params: OrderedDict([('actual_estimator__max_depth', 5), ('actual_estimator__min_child_samples', 150), ('actual_estimator__n_estimators', 100)])
2024-09-05 22:22:52,401:INFO:Hyperparameter search completed
2024-09-05 22:22:52,401:INFO:SubProcess create_model() called ==================================
2024-09-05 22:22:52,402:INFO:Initializing create_model()
2024-09-05 22:22:52,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422A77D270>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'max_depth': 5, 'min_child_samples': 150, 'n_estimators': 100})
2024-09-05 22:22:52,402:INFO:Checking exceptions
2024-09-05 22:22:52,403:INFO:Importing libraries
2024-09-05 22:22:52,403:INFO:Copying training dataset
2024-09-05 22:22:53,354:INFO:Defining folds
2024-09-05 22:22:53,355:INFO:Declaring metric variables
2024-09-05 22:22:53,360:INFO:Importing untrained model
2024-09-05 22:22:53,360:INFO:Declaring custom model
2024-09-05 22:22:53,364:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 22:22:53,374:INFO:Starting cross validation
2024-09-05 22:22:53,379:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 22:23:56,607:INFO:Calculating mean and std
2024-09-05 22:23:56,609:INFO:Creating metrics dataframe
2024-09-05 22:23:56,617:INFO:Finalizing model
2024-09-05 22:24:02,861:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187376 seconds.
2024-09-05 22:24:02,861:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 22:24:02,872:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 22:24:02,877:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 22:24:02,880:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:24:02,881:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:24:02,881:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:24:02,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:03,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:04,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:05,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:06,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:07,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:08,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:09,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-05 22:24:10,827:INFO:Uploading results into container
2024-09-05 22:24:10,828:INFO:Uploading model into container now
2024-09-05 22:24:10,829:INFO:_master_model_container: 17
2024-09-05 22:24:10,829:INFO:_display_container: 4
2024-09-05 22:24:10,830:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:24:10,830:INFO:create_model() successfully completed......................................
2024-09-05 22:24:10,969:INFO:SubProcess create_model() end ==================================
2024-09-05 22:24:10,970:INFO:choose_better activated
2024-09-05 22:24:10,973:INFO:SubProcess create_model() called ==================================
2024-09-05 22:24:10,974:INFO:Initializing create_model()
2024-09-05 22:24:10,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 22:24:10,974:INFO:Checking exceptions
2024-09-05 22:24:10,976:INFO:Importing libraries
2024-09-05 22:24:10,976:INFO:Copying training dataset
2024-09-05 22:24:11,831:INFO:Defining folds
2024-09-05 22:24:11,831:INFO:Declaring metric variables
2024-09-05 22:24:11,831:INFO:Importing untrained model
2024-09-05 22:24:11,831:INFO:Declaring custom model
2024-09-05 22:24:11,832:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 22:24:11,833:INFO:Starting cross validation
2024-09-05 22:24:11,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-05 22:25:34,901:INFO:Calculating mean and std
2024-09-05 22:25:34,901:INFO:Creating metrics dataframe
2024-09-05 22:25:34,904:INFO:Finalizing model
2024-09-05 22:25:40,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165781 seconds.
2024-09-05 22:25:40,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 22:25:40,303:INFO:[LightGBM] [Info] Total Bins 128940
2024-09-05 22:25:40,307:INFO:[LightGBM] [Info] Number of data points in the train set: 76191, number of used features: 533
2024-09-05 22:25:40,310:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:25:40,311:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:25:40,311:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:25:51,517:INFO:Uploading results into container
2024-09-05 22:25:51,518:INFO:Uploading model into container now
2024-09-05 22:25:51,519:INFO:_master_model_container: 18
2024-09-05 22:25:51,519:INFO:_display_container: 5
2024-09-05 22:25:51,519:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:25:51,519:INFO:create_model() successfully completed......................................
2024-09-05 22:25:51,617:INFO:SubProcess create_model() end ==================================
2024-09-05 22:25:51,617:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8294
2024-09-05 22:25:51,618:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=5,
               min_child_samples=150, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8284
2024-09-05 22:25:51,618:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-05 22:25:51,618:INFO:choose_better completed
2024-09-05 22:25:51,619:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-05 22:25:51,628:INFO:_master_model_container: 18
2024-09-05 22:25:51,629:INFO:_display_container: 4
2024-09-05 22:25:51,629:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:25:51,629:INFO:tune_model() successfully completed......................................
2024-09-05 22:25:55,351:INFO:Initializing evaluate_model()
2024-09-05 22:25:55,351:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-09-05 22:25:55,704:INFO:Initializing plot_model()
2024-09-05 22:25:55,704:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:25:55,704:INFO:Checking exceptions
2024-09-05 22:25:55,962:INFO:Preloading libraries
2024-09-05 22:25:55,982:INFO:Copying training dataset
2024-09-05 22:25:55,982:INFO:Plot type: pipeline
2024-09-05 22:25:56,166:INFO:Visual Rendered Successfully
2024-09-05 22:25:56,245:INFO:plot_model() successfully completed......................................
2024-09-05 22:25:57,877:INFO:Initializing plot_model()
2024-09-05 22:25:57,877:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:25:57,878:INFO:Checking exceptions
2024-09-05 22:25:58,137:INFO:Preloading libraries
2024-09-05 22:25:58,158:INFO:Copying training dataset
2024-09-05 22:25:58,158:INFO:Plot type: parameter
2024-09-05 22:25:58,163:INFO:Visual Rendered Successfully
2024-09-05 22:25:58,254:INFO:plot_model() successfully completed......................................
2024-09-05 22:25:59,925:INFO:Initializing plot_model()
2024-09-05 22:25:59,925:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:25:59,925:INFO:Checking exceptions
2024-09-05 22:26:00,213:INFO:Preloading libraries
2024-09-05 22:26:00,233:INFO:Copying training dataset
2024-09-05 22:26:00,233:INFO:Plot type: auc
2024-09-05 22:26:02,869:INFO:Fitting Model
2024-09-05 22:26:02,871:INFO:Scoring test/hold-out set
2024-09-05 22:26:03,303:INFO:Visual Rendered Successfully
2024-09-05 22:26:03,395:INFO:plot_model() successfully completed......................................
2024-09-05 22:26:04,841:INFO:Initializing plot_model()
2024-09-05 22:26:04,841:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:26:04,841:INFO:Checking exceptions
2024-09-05 22:26:05,126:INFO:Preloading libraries
2024-09-05 22:26:05,148:INFO:Copying training dataset
2024-09-05 22:26:05,148:INFO:Plot type: confusion_matrix
2024-09-05 22:26:07,616:INFO:Fitting Model
2024-09-05 22:26:07,618:INFO:Scoring test/hold-out set
2024-09-05 22:26:07,945:INFO:Visual Rendered Successfully
2024-09-05 22:26:08,039:INFO:plot_model() successfully completed......................................
2024-09-05 22:27:45,950:INFO:Initializing plot_model()
2024-09-05 22:27:45,951:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:27:45,951:INFO:Checking exceptions
2024-09-05 22:27:46,275:INFO:Preloading libraries
2024-09-05 22:27:46,296:INFO:Copying training dataset
2024-09-05 22:27:46,296:INFO:Plot type: error
2024-09-05 22:27:48,726:INFO:Fitting Model
2024-09-05 22:27:48,727:INFO:Scoring test/hold-out set
2024-09-05 22:27:49,101:INFO:Visual Rendered Successfully
2024-09-05 22:27:49,189:INFO:plot_model() successfully completed......................................
2024-09-05 22:28:20,674:INFO:Initializing plot_model()
2024-09-05 22:28:20,674:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:28:20,675:INFO:Checking exceptions
2024-09-05 22:28:20,940:INFO:Preloading libraries
2024-09-05 22:28:20,962:INFO:Copying training dataset
2024-09-05 22:28:20,963:INFO:Plot type: class_report
2024-09-05 22:28:23,555:INFO:Fitting Model
2024-09-05 22:28:23,556:INFO:Scoring test/hold-out set
2024-09-05 22:28:23,965:INFO:Visual Rendered Successfully
2024-09-05 22:28:24,066:INFO:plot_model() successfully completed......................................
2024-09-05 22:28:29,022:INFO:Initializing plot_model()
2024-09-05 22:28:29,022:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:28:29,022:INFO:Checking exceptions
2024-09-05 22:28:34,051:INFO:Initializing plot_model()
2024-09-05 22:28:34,051:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:28:34,051:INFO:Checking exceptions
2024-09-05 22:28:34,326:INFO:Preloading libraries
2024-09-05 22:28:34,347:INFO:Copying training dataset
2024-09-05 22:28:34,348:INFO:Plot type: learning
2024-09-05 22:28:36,898:INFO:Fitting Model
2024-09-05 22:37:08,892:INFO:Initializing predict_model()
2024-09-05 22:37:08,892:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002422AB3B490>)
2024-09-05 22:37:08,892:INFO:Checking exceptions
2024-09-05 22:37:08,892:INFO:Preloading libraries
2024-09-05 22:37:11,159:INFO:Initializing evaluate_model()
2024-09-05 22:37:11,159:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-09-05 22:37:11,464:INFO:Initializing plot_model()
2024-09-05 22:37:11,464:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:37:11,464:INFO:Checking exceptions
2024-09-05 22:37:11,723:INFO:Preloading libraries
2024-09-05 22:37:11,747:INFO:Copying training dataset
2024-09-05 22:37:11,747:INFO:Plot type: pipeline
2024-09-05 22:37:11,865:INFO:Visual Rendered Successfully
2024-09-05 22:37:11,966:INFO:plot_model() successfully completed......................................
2024-09-05 22:37:11,989:INFO:Initializing evaluate_model()
2024-09-05 22:37:11,989:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-09-05 22:37:12,279:INFO:Initializing plot_model()
2024-09-05 22:37:12,279:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:37:12,279:INFO:Checking exceptions
2024-09-05 22:37:12,556:INFO:Preloading libraries
2024-09-05 22:37:12,580:INFO:Copying training dataset
2024-09-05 22:37:12,580:INFO:Plot type: pipeline
2024-09-05 22:37:12,697:INFO:Visual Rendered Successfully
2024-09-05 22:37:12,800:INFO:plot_model() successfully completed......................................
2024-09-05 22:37:12,824:INFO:Initializing plot_model()
2024-09-05 22:37:12,825:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, system=True)
2024-09-05 22:37:12,825:INFO:Checking exceptions
2024-09-05 22:37:13,116:INFO:Preloading libraries
2024-09-05 22:37:13,137:INFO:Copying training dataset
2024-09-05 22:37:13,137:INFO:Plot type: pipeline
2024-09-05 22:37:13,253:INFO:Visual Rendered Successfully
2024-09-05 22:37:13,351:INFO:plot_model() successfully completed......................................
2024-09-05 22:37:24,549:INFO:Initializing get_config()
2024-09-05 22:37:24,549:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, variable=X_train)
2024-09-05 22:37:24,550:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-05 22:37:24,820:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-05 22:37:24,820:INFO:get_config() successfully completed......................................
2024-09-05 22:37:24,821:INFO:Initializing predict_model()
2024-09-05 22:37:24,821:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024235D5B1C0>)
2024-09-05 22:37:24,821:INFO:Checking exceptions
2024-09-05 22:37:24,821:INFO:Preloading libraries
2024-09-05 22:37:24,823:INFO:Set up data.
2024-09-05 22:37:25,079:INFO:Set up index.
2024-09-05 22:37:32,500:INFO:Initializing get_config()
2024-09-05 22:37:32,500:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, variable=X_train)
2024-09-05 22:37:32,500:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-09-05 22:37:32,777:INFO:Variable:  returned as        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
71710   1.550291  -0.252679  -0.903637   2.736559   0.372071   0.304834   
41786   1.144238  -0.252679   1.373649  -0.522903   0.083904   0.304834   
53345  -0.499730  -0.252679  -0.903637  -0.522903   0.083904   0.304834   
11745  -0.742247  -0.252679   0.055220  -0.522903   0.049743   0.304834   
23494   0.829220  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
...          ...        ...        ...        ...        ...        ...   
45374   0.160893  -0.252679  -0.903637  -0.522903   0.278403   0.304834   
38857  -1.387282   1.998487   1.373649  -0.522903  -0.540365  -3.280477   
31149   0.765373  -0.252679  -0.903637   0.291962   0.428822   0.304834   
55353   0.715438  -0.252679  -0.903637  -0.522903   0.134044   0.304834   
1638   -0.827527  -0.252679   0.055220  -0.522903   0.428822   0.304834   

       feature_6  feature_7  feature_8  feature_9  ...  feature_524  \
71710  -0.307305  -0.216109   -0.06743   1.112682  ...    -0.086278   
41786   1.787297   0.066573   -0.06743  -1.226048  ...    -0.086278   
53345  -0.307305  -1.127987   -0.06743   1.112682  ...    -0.086278   
11745  -0.307305  -0.854424   -0.06743  -0.056683  ...     6.167595   
23494  -0.307305   3.249027   -0.06743  -0.056683  ...    -0.086278   
...          ...        ...        ...        ...  ...          ...   
45374  -0.307305   1.516459   -0.06743   1.112682  ...    -0.086278   
38857   1.787297  -2.039865   -0.06743  -0.056683  ...    -0.086278   
31149  -0.307305  -0.033734   -0.06743  -0.056683  ...    -0.086278   
55353  -0.307305  -0.216109   -0.06743  -0.056683  ...    -0.086278   
1638   -0.307305  -0.854424   -0.06743  -0.056683  ...    -0.086278   

       feature_525  feature_526  feature_527  feature_528  feature_529  \
71710    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
41786    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
53345    -0.129104    -0.082721     0.049159    -0.814324    -1.269576   
11745     5.438956    13.379660     1.386740    -1.298134     0.330275   
23494    -0.129104    -0.082721     0.049159     1.938017    -0.543544   
...            ...          ...          ...          ...          ...   
45374    -0.129104    -0.082721     0.049159     0.338756     1.927194   
38857    -0.129104    -0.082721     0.049159    -1.298134     0.330275   
31149    -0.129104    -0.082721     0.049159     1.587176     1.716656   
55353    -0.129104    -0.082721     0.049159     0.219701    -0.464959   
1638     -0.129104    -0.082721     0.049159    -0.814324    -1.269576   

       feature_530  feature_531  feature_532  feature_533  
71710    -0.978704    -0.657480     0.665040     0.918771  
41786    -0.447987    -0.785362     0.023022    -0.833264  
53345    -0.978704    -0.657480     0.665040     0.918771  
11745     0.189874     0.765493     0.279644    -0.979924  
23494    -0.447987    -0.785362     0.023022    -0.833264  
...            ...          ...          ...          ...  
45374    -0.693992     2.376801    -1.369871    -0.430422  
38857     0.189874     0.765493     0.279644    -0.979924  
31149    -2.215057     1.016606    -2.545979     2.249198  
55353     0.917071    -0.748160     0.294235    -0.368505  
1638     -0.978704    -0.657480     0.665040     0.918771  

[53562 rows x 534 columns]
2024-09-05 22:37:32,777:INFO:get_config() successfully completed......................................
2024-09-05 22:37:32,777:INFO:Initializing predict_model()
2024-09-05 22:37:32,777:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002422A0ABE20>)
2024-09-05 22:37:32,778:INFO:Checking exceptions
2024-09-05 22:37:32,778:INFO:Preloading libraries
2024-09-05 22:37:32,779:INFO:Set up data.
2024-09-05 22:37:33,032:INFO:Set up index.
2024-09-05 22:37:34,570:INFO:Initializing get_config()
2024-09-05 22:37:34,570:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, variable=y_train)
2024-09-05 22:37:34,570:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2024-09-05 22:37:34,761:INFO:Variable:  returned as 71710    2
41786    0
53345    1
11745    1
23494    0
        ..
45374    2
38857    1
31149    2
55353    2
1638     0
Name: Target, Length: 53562, dtype: int8
2024-09-05 22:37:34,762:INFO:get_config() successfully completed......................................
2024-09-05 22:37:34,762:INFO:Initializing get_config()
2024-09-05 22:37:34,762:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, variable=y_test)
2024-09-05 22:37:34,762:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2024-09-05 22:37:34,901:INFO:Variable:  returned as 66785    1
25878    1
21700    0
10338    2
12622    0
        ..
59368    2
69095    2
46808    0
11937    2
4097     1
Name: Target, Length: 22956, dtype: int8
2024-09-05 22:37:34,901:INFO:get_config() successfully completed......................................
2024-09-05 22:37:46,038:INFO:Initializing finalize_model()
2024-09-05 22:37:46,038:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-05 22:37:46,038:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-05 22:37:46,558:INFO:Initializing create_model()
2024-09-05 22:37:46,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-05 22:37:46,558:INFO:Checking exceptions
2024-09-05 22:37:46,559:INFO:Importing libraries
2024-09-05 22:37:46,559:INFO:Copying training dataset
2024-09-05 22:37:46,650:INFO:Defining folds
2024-09-05 22:37:46,650:INFO:Declaring metric variables
2024-09-05 22:37:46,651:INFO:Importing untrained model
2024-09-05 22:37:46,651:INFO:Declaring custom model
2024-09-05 22:37:46,652:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-05 22:37:46,655:INFO:Cross validation set to False
2024-09-05 22:37:46,655:INFO:Fitting Model
2024-09-05 22:37:55,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.278672 seconds.
2024-09-05 22:37:55,332:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-05 22:37:55,344:INFO:[LightGBM] [Info] Total Bins 130277
2024-09-05 22:37:55,348:INFO:[LightGBM] [Info] Number of data points in the train set: 108846, number of used features: 534
2024-09-05 22:37:55,352:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:37:55,352:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:37:55,352:INFO:[LightGBM] [Info] Start training from score -1.098612
2024-09-05 22:38:11,745:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-05 22:38:11,745:INFO:create_model() successfully completed......................................
2024-09-05 22:38:11,875:INFO:_master_model_container: 18
2024-09-05 22:38:11,875:INFO:_display_container: 5
2024-09-05 22:38:11,887:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-05 22:38:11,887:INFO:finalize_model() successfully completed......................................
2024-09-05 22:39:21,622:INFO:Initializing predict_model()
2024-09-05 22:39:21,622:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024227A4B340>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_0', 'feature_1',
                                             'feature_2', 'feature_3',
                                             'feature_4', 'feature_5',
                                             'feature_6', 'feature_7',
                                             'feature_8', 'feature_9',
                                             'feature_10', 'feature_11',
                                             'feature_12', 'feature_13',
                                             'feature_14', 'feature_15',
                                             'feature_16', 'feature_17',
                                             'feature_18', 'featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024235D5B1C0>)
2024-09-05 22:39:21,622:INFO:Checking exceptions
2024-09-05 22:39:21,622:INFO:Preloading libraries
2024-09-05 22:39:21,626:INFO:Set up data.
2024-09-05 22:39:22,161:INFO:Set up index.
